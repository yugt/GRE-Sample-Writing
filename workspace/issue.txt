Issue 2
"No field of study can advance significantly unless outsiders bring their knowledge and
experience to that field of study."
I strongly agree with the assertion that significant advances in knowledge require expertise
from various fields. The world around us presents a seamless web of physical and
anthropogenic forces, which interact in ways that can be understood only in the context of a
variety of disciplines. Two examples that aptly illustrate this point involve the fields of cultural
anthropology and astronomy.
Consider how a cultural anthropologist's knowledge about an ancient civilization is
enhanced not only by the expertise of the archeologist--who unearths the evidence--but
ultimately by the expertise of biochemists, geologists, linguists, and even astronomers. By
analyzing the hair, nails, blood and bones of mummified bodies, biochemists and forensic
scientists can determine the life expectancy, general well-being, and common causes of death
of the population. These experts can also ensure the proper preservation of evidence found at
the archeological site. A geologist can help identify the source and age of the materials used
for tools, weapons, and structures--thereby enabling the anthropologist to extrapolate about
the civilization's economy, trades and work habits, life styles, extent of travel and mobility, and
so forth. Linguists are needed to interpret hieroglyphics and extrapolate from found fragments
of writings. And an astronomer can help explain the layout of an ancient city as well as the
design, structure and position of monuments, tombs, and temples--since ancients often looked
to the stars for guidance in building cities and structures.
An even more striking example of how expertise in diverse fields is needed to advance
knowledge involves the area of astronomy and space exploration. Significant advancements in
our knowledge of the solar system and the universe require increasingly keen tools for
observation and measurement. Telescope technology and the measurement of celestial
distances, masses, volumes, and so forth, are the domain of astrophysicists.
These advances also require increasingly sophisticated means of exploration. Manned and
unmanned exploratory probes are designed by mechanical, electrical, and computer
engineers. And to build and enable these technologies requires the acumen and savvy of
business leaders, managers, and politicians. Even diplomats might play a role--insofar as
major space projects require intemafional cooperative efforts among the world's scientists and
governments. And ultimately it is our philosophers whose expertise helps provide meaning to
what we learn about our universe.
In sum, no area ofinteUectual inquiry operates in a vacuum. Because the sciences are
inextricably related, to advance our knowledge in any one area we must understand the
interplay among them all. Moreover, it is our non-scienfists who make possible the science,
and who bring meaning to what we learn from it.
























Issue 3
"A nation should require all its students to study the same national curriculum until they enter
college rather than allow schools in different parts of the nation to determine which academic
courses to offer."
The speaker would prefer a national curriculum for all children up until college instead of
allowing schools in different regions the freedom to decide on their own curricula. I agree
insofar as some common core curriculum would serve useful purposes for any nation. At the
same time, however, individual states and communities should have some freedom to
augment any such curriculum as they see fit; otherwise, a nation's educational system might
defeat its own purposes in the long tenn.
A national core curriculum would be beneficial to a nation in a number of respects. First of all,
by providing all children with fundamental skills and knowledge, a common core curriculum
would help ensure that our children grow up to become reasonably informed, productive
members of society. In addition, a common core curriculum would provide a predictable
foundation upon which college administrators and faculty could more easily build curricula and
select course materials for freshmen that are neither below nor above their level of educational
experience. Finally, a core curriculum would ensure that all school-children are taught core
values upon which any democratic society depends to thrive, and even survive--values such
as tolerance of others with different viewpoints, and respect for others.
However, a common curriculum that is also an exdusive one would pose certain problems,
which might outweigh the benefits, noted above. First of all, on what basis would certain
course work be included or excluded, and who would be the final decision- maker? In all
likelihood these decisions would be in the hands of federal legislators and regulators, who are
likely to have their own quirky notions of what should and should not be taught to
children--notions that may or may not reflect those of most communities, schools, or parents.
Besides, government officials are notoriously susceptible to influence-peddling by lobbyists
who do not have the best interests of society's children in mind.
Secondly, an official, federally sanctioned curriculum would facilitate the dissemination of
propaganda and other dogma which because of its biased and one-sided nature undermines
the very purpose of true education: to enlighten. I can easily foresee the banning of certain text
books, programs, and websites which provide information and perspectives that the
government might wish to suppress--as some sort of threat to its authority and power.
Although this scenario might seem far-fetched, these sorts of concerns are being raised
already at the state level.
Thirdly, the inflexible nature of a uniform national curriculum would preclude the inclusion of
programs, courses, and materials that are primarily of regional or local significance. For
example, California requires children at certain grade levels to learn about the history of
particular ethnic groups who make up the state's diverse population. A national curriculum
might not allow for this feature, and California's youngsters would be worse off as a result of
their ignorance about the traditions, values, and cultural contributions of all the people whose
citizenship they share.
Finally, it seems to me that imposing a uniform national curriculum would serve to
undermine the authority of parents over their own children, to even a greater extent than
uniform state laws currently do. Admittedly, laws requiring parents to ensure that their children
receive an education that meets certain minimum standards are well-justified, for the reasons
mentioned earlier. However, when such standards are imposed by the state rather than at the
community level parents are left with far less power to participate meaningfully in the
decision-making process. This problem would only be exacerbated were these decisions left
exclusively to federal regulators.
In the final analysis, homogenization of elementary and secondary education would amount
to a double-edged sword. While it would serve as an insurance policy against a future
populated with illiterates and ignoramuses, at the same time it might serve to obliterate cultural
diversity and tradition. The optimal federal approach, in my view, is a balanced one that
imposes a basic curriculum yet leaves the rest up to each state--or better yet, to each
community.
























Issue 4
"The video camera provides such an accurate and convincing record of contemporary life that
it has become a more important form of documentation than written records."
According to the speaker, the video recording is a more important means of document hag
contemporary life than a written record because video recordings are more accurate and
convincing. Although I agree that a video provides a more objective and accurate record of an
event's spatial aspects, there is far more to document ha life than what we see and hear. Thus
the speaker overstates the comparative significance of video as a documentary tool.
For the purpose of documenting temporal, spatial events and experiences, I agree that a
video record is usually more accurate and more convincing than a written record. It is
impossible for anyone, no matter how keen an observer and skilled a journalist, to recount ha
complete and objective detail such events as the winning touchdown at the Super Bowl, a
Ballanchine ballet, the Tournament of Roses Parade, or the scene at the intersection of
Florence and Normandy streets during the 1992 Los Angeles riots. Yet these are important
events in contemporary life the sort of events we might put ha a time capsule for the purpose
of capturing our life and times at the turn of this millennium.
The growing documentary role of video is not limited to seminal events like those described
above. Video surveillance cameras are objective witnesses with perfect memories. Thus they
can play a vital evidentiary role in legal proceedings--such as those involving robbery, drug
trafficking, police misconduct, motor vehicle violations, and even malpractice in a hospital
operating room. Indeed, whenever moving images are central to an event the video camera is
superior to the written word. A written description of a hurricane, tornado, or volcanic eruption
cannot convey its immediate power and awesome nature like a video record. A diary entry
cannot "replay" that wedding reception, dance recital, or surprise birthday party as accurately
or objectively as a video record. And a real estate brochure cannot inform about the lighting,
spaciousness, or general ambiance of a featured property nearly as effectively as a video.
Nonetheless, for certain other purposes written records are advantageous to and more
appropriate than video records. For example, certain legal matters are best left to written
documentation: video is of no practical use ha documenting the terms of a complex contractual
agreement, an incorporation, or the establishment of a trust. And video is of little use when it
comes to documenting a person's subjective state of mind, impressions, or reflections of an
event or experience. Indeed, to the extent that personal interpretation adds dimension and
richness to the record, written documentation is actually more important than video.
Finally, a video record is of no use in documenting statistical or other quantitative information.
Returning to the riot example mentioned earlier, imagine relying on a video to document the
financial loss to store owners, the number of police and firefighters involved, and so forth.
Complete and accurate video documentation of such information would require video cameras
at every street corner and in every aisle of every store.
In sum, the speaker's claim overstates the importance of video records, at least to some
extent. When it comes to capturing, storing, and recalling temporal, spatial events, video
records are inherently more objective, accurate, and complete. However, what we view
through a camera lens provides only one dimension of our life and times; written
documentation will always be needed to quantify, demystify, and provide meaning to the world
around us.
























Issue 5
"It is often necessary, even desirable, for political leaders to withhold information from the
public."
I agree with the speaker that it is sometimes necessary, and even desirable, for political
leaders to withhold information from the public. A contrary view would reveal a naivetd about
the inherent nature of public politics, and about the sorts of compromises on the part of
well-intentioned political leaders necessary in order to further the public's ultmaate interests.
Nevertheless, we must not allow our political leaders undue freedom to with-hold information,
otherwise, we risk sanctioning demagoguery and undermining the philosophical underpinnings
of any democratic society.
One reason for my fundamental agreement with the speaker is that in order to gain the
opportunity for effective public leadership, a would-be leader must fzrst gain and maintain
political power. In the game of politics, complete forthrightness is a sign of vulnerability and
naivete, neither of which earn a politician respect among his or her opponents, and which
those opponents will use to every advantage to defeat the politician. In my observation some
measure of pandering to the electorate is necessary to gain and maintain political leadership.
For example, were all politicians to fully disclose every personal foibles, character flaw, and
detail concerning personal life, few honest politicians would ever by elected. While this view
might seem cynical, personal scandals have in fact proven the undoing of many a political
career; thus I think this view is realistic.
Another reason why I essentially agree with the speaker is that fully disclosing to the public
certain types of information would threaten public safety and perhaps even national security.
For example, if the President were to disclose the government's strategies for thwarting
specific plans of an international terrorist or a drug trafficker, those strategies would surely fail,
and the public's health and safety would be compromised as a result. Withholding information
might also be necessary to avoid public panic. While such cases are rare, they do occur
occasionally. For example, during the first few hours of the new millennium the U.S.
Pentagon's missile defense system experienced a Y2K- related malfunction. This fact was
withheld from the public until later in the day, once the problem had been solved; and
legitimately so, since immediate disclosure would have served no useful purpose and might
even have resulted in mass hysteria.
Having recognized that withholding informarion from the public is often necessary to serve
the interests of that public, legitimate political leadership nevertheless requires forthrightness
with the citizenry as to the leader's motives and agenda. History informs us that would-be
leaders who lack such forthrightness are the same ones who seize and maintain power either
by brute force or by demagoguery--that is, by deceiving and manipulating the citizenry.
Paragons such as Genghis Khan and Hitler, respectively, come immediately to mind. Any
democratic society should of course abhor demagoguery, which operates against the
democratic principle of government by the people. Consider also less egregious examples,
such as President Nixon's withholding of information about his active role in the Watergate
cover-up. His behavior demonstrated a concern for self- interest above the broader interests of
the democratic system that granted his political authority in the first place.
In sum, the game of politics calls for a certain amount of disingenuousness and lack of
forthrightness that we might otherwise characterize as dishonesty. And such behavior is a
necessary means to the final objective of effective political leadership. Nevertheless, in any
democracy a leader who relies chiefly on deception and secrecy to preserve that leadership, to
advance a private agenda, or to conceal selfish motives, betrays the democracy-and ends up
forfeiting the polirical game.
























Issue 6
"Governments must ensure that their major cities receive the financial support they need in
order to thrive, because it is primarily in cities that a nation's cultural traditions are preserved
and generated."
The speaker's claim is actually threefold: (1) ensuring the survival of large cities and, in turn,
that of cultural traditions, is a proper function of government; (2) government support is needed
for our large dries and cultural traditions to survive and thrive; and (3) cultural traditions are
preserved and generated primarily in our large cities. I strongly disagree with all three claims.
First of all, subsidizing cultural traditions is not a proper role of govemment. Admittedly,
certain objectives, such as public health and safety, are so essential to the survival of large
dries and of nations that government has a duty to ensure that they are met. However, these
objectives should not extend tenuously to preserving cultural traditions. Moreover, government
cannot possibly play an evenhanded role as cultural patron. Inadequate resources call for
restrictions, priorities, and choices. It is unconscionable to relegate normative decisions as to
which cities or cultural traditions are more deserving, valuable, or needy to a few legislators,
whose notions about culture might be misguided or unrepresentative of those of the general
populace. Also, legislators are all too likely to make choices in favor of the cultural agendas of
their home towns and states, or of lobbyists with the most money and influence.
Secondly, subsidizing cultural traditions is not a necessary role of government. A lack of
private funding might justify an exception. However, culture--by which I chiefly mean the fine
arts--has always depended primarily on the patronage of private individuals and businesses,
and not on the government. The Medicis, a powerful banking family of Renaissance Italy,
supported artists Michelangelo and Raphael. During the 20th Century the primary source of
cultural support were private foundations established by industrial magnates Carnegie, Mellon,
Rockefeller and Getty. And tomorrow cultural support will come from our new technology and
media moguls----including the likes of Ted Turner and Bill Gates. In short, philanthropy is alive
and well today, and so government need not intervene to ensure that our cultural traditions are
preserved and promoted.
Finally, and perhaps most importantly, the speaker unfairly suggests that large cities serve
as the primary breeding ground and sanctuaries for a nation's cultural traditions. Today a
nation's distinct cultural traditions--its folk art, crafts, traditional songs, customs and
ceremonies--burgeon instead in small towns and rural regions. Admittedly, our cities do serve
as our centers for "high art"; big cities are where we deposit, display, and boast the world's
preeminent art, architecture, and music. But big-city culture has little to do any- more with one
nation's distinct cultural traditions. After all, modern cities are essentially multicultural stew pots;
accordingly, by assisting large cities a government is actually helping to create a global culture
as well to subsidize the traditions of other nations' cultures.
In the final analysis, government cannot philosophically justify assisting large cities for the
purpose of either promoting or preserving the nation's cultural traditions; nor is government
assistance necessary toward these ends. Moreover, assisting large cities would have little
bearing on our distinct cultural traditions, which abide elsewhere.
























Issue 7
"All nations should help support the development of a global university designed to engage
students in the process of solving the world's most persistent social problems."
I agree that it would serve the interests of all nations to establish a global university for the
purpose of solving the world's most persistent social problems. Nevertheless, such a university
poses certain risks which all participating nations must be careful to minimize--or risk defeating
the university's purpose.
One compelling argument in favor of a global university has to do with the fact that its faculty
and students would bring diverse cultural and educational perspectives to the problems they
seek to solve. It seems to me that nations can only benefit from a global university where
students learn ways in which other nations address certain soda] problems-successfully or not.
It might be tempting to think that an overly diversified academic community would impede
communication among students and faculty. However, in my view any such concerns are
unwarranted, especially considering the growing awareness of other peoples and cultures
which the mass media, and especially the Internet, have created. Moreover, many basic
principles used to solve enduring social problems know no national boundaries; thus a useful
insight or discovery can come from a researcher or student from any nation.
Another compelling argument for a global university involves the increasingly global nature
of certain problems. Consider, for instance, the depletion of atmospheric ozone, which has
wanned the Earth to the point that it threatens the very survival of the human species. Also, we
are now learning that dear-cutting the world's rainforests can set into motion a chain of animal
extinction that threatens the delicate balance upon which all animals--including
humans--depend. Also consider that a financial crisis---or a political crisis or natural disaster
in one country can spell trouble for foreign companies, many of which are now multinational in
that they rely on the labor forces, equipment, and raw materials of other nations.
Environmental, economic, and political problems such as these all carry grave social
consequences--increased crime, unemployment, insurrection, hunger, and so forth. Solving
these problems requires global cooperation--which a global university can facilitate.
Notwithstanding the foregoing reasons why a global university would help solve many of our
most pressing social problems, the establishment of such a university poses certain problems
of its own which must be addressed in order that the university can achieve its objectives. First,
participant nations would need to overcome a myriad of administrative and political
impediments. All nations would need to agree on which problems demand the university's
attention and resources, which areas of academic research are worthwhile, as well as
agreeing on policies and procedures for making, enforcing, and amending these decisions.
Query whether a functional global university is politically feasible, given that sovereign nations
naturally wish to advance their own agendas.
A second problem inherent in establishing a global university involves the risk that certain
intellectual and research avenues would become officially sanctioned while others of equal or
greater potential value would be discouraged, or perhaps even proscribed. A telling example of
the inherent danger of setting and enforcing official research priorities involves the Soviet
government's attempts during the 1920s to not only control the direction and the goals of its
scientists' research but also to distort the outcome of that research---ostensibly for the greatest
good of the greatest number of people. Not surprisingly, during this time period no significant
scientific advances occurred under the auspices of the Soviet government. The Soviet lesson
provides an important caveat to administrators of a global university: Significant progress in
solving pressing social problems requires an open mind to all sound ideas, approaches, and
theories---krespective of the ideologies of their proponents.
A final problem with a global university is that the world's preeminent intellectual talent might
be drawn to the sorts of problems to which the university is charged with solving, while
parochial social problem go unsolved. While this is not reason enough not to establish a global
university, it nevertheless is a concern that university administrators and participant nations
must be aware of in allocating resources and intellectual talent.
To sum up, given the increasingly global nature or the world's social problems, and the
escalating costs of addressing these problems, a global university makes good sense. And,
since all nations would have a common interest in seeing this endeavor succeed, my intuition
is that participating nations would be able to overcome whatever procedural and political
obstacles that might stand in the way of success. As long as each nation is careful not to
neglect its own unique social problems, and as long as the university's administrators are
careful to remain open-minded about the legitimacy and potential value of various avenues of
intellectual inquiry and research, a global university might go along way toward solving many
of the world's pressing social problems.
























Issue 8
"Many of the world's lesser-known languages are being lost as fewer and fewer people speak
them. The governments of countries in which these languages are spoken should act to
prevent such languages from becoming extinct."
The speaker asserts that governments of countries where lesser-known languages are
spoken should intervene to prevent these languages from becoming extinct. I agree inso far as
a country's indigenous and distinct languages should not be abandoned and forgot ten
altogether. At some point, however, I think cultural identity should yield to the more practical
considerations of day-to-day life in a global society.
On the one hand, the indigenous language of any geographical region is part-and-parcel of
the cultural heritage of the region's natives. In my observation we humans have a basic
psychological need for individual identity, which we define by way of our membership in distinct
cultural groups. A culture defines itself in various ways--by its unique traditions, rituals, mores,
attitudes and beliefs, but especially language. Therefore, when a people's language becomes
extinct the result is a diminished sense of pride, dignity, and self- worth.
One need look no further than continental Europe to observe how people cling tenaciously
to their distinct languages, despite the fact that there is no practical need for them anymore.
And on the other side of the Atlantic Ocean, the French Canadians stubbornly insist on French
as their official language, for the sole purpose of preserving their distinct cultural heritage.
Even where no distinct language exists, people will invent one to gain a sense of cultural
identity, as the emergence of the distinct Ebonic cant among today's African Americans aptly
illustrates. In short, people resist language assimilation because of a basic human need to be
part of a distinct cultural group.
Another important reason to prevent the extinction of a language is to preserve the distinct
ideas that only that particular language can convey. Certain Native American and Oriental
languages, for instance, contain words symbolizing spiritual and other abstract concepts that
only these cultures embrace. Thus, in some cases to lose a language would be to abandon
cherished beliefs and ideas that can be conveyed only through language.
On the other hand, in today's high-tech world of satellite communications, global mobility,
and especially the Internet, language barriers serve primarily to impede cross-cultural
communication, which in turn impedes international commerce and trade. Moreover, language
barriers naturally breed misunderstanding, a certain distrust and, as a result, discord and even
war among nations. Moreover, in my view the extinction of all but a few major languages is
inexorable--as supported by the fact that the Internet has adopted English as its official
language. Thus by intervening to preserve a dying language a government might be deploying
its resources to fight a losing battle, rather than to combat more pressing social
problems--such as hunger, homelessness, disease and ignorance--that plague nearly every
society today.
In sum, preserving indigenous languages is, admittedly, a worthy goal; maintaining its own
distinct language affords a people a sense of pride, dignity and self-worth. Moreover, by
preserving languages we honor a people's heritage, enhance our understanding of history, and
preserve certain ideas that only some languages properly convey. Nevertheless, the economic
and political drawbacks of language barriers outweigh the benefits of preserving a dying
language. In the final analysis, government should devote its time and resources elsewhere,
and leave it to the people themselves to take whatever steps are needed to preserve their own
distinct languages.
























Issue 9
"Although many people think that the luxuries and conveniences of contemporary life are
entirely harmless, they in fact, prevent people from developing into truly strong and
independent individuals."
Do modern luxuries serve to undermine our true strength and independence as individuals?
The speaker believes so, and I tend to agree. Consider the automobile, for example. Most
people consider the automobile a necessity rather than a luxury; yet it is for this very reason
that the automobile so aptly supports the speaker's point. To the extent that we depend on cars
as crutches, they prevent us from becoming truly independent and strong in character as
individuals.
Consider first the effect of the automobile on our independence as individuals. In some
respects the automobile serves to enhance such independence. For example, cars make it
possible for people in isolated and depressed areas without public transportation to become
more independent by pursing gainful employment outside their communities. And teenagers
discover that owning a car, or even borrowing one on occasion, affords them a needed sense
of independence from their parents.
However, cars have diminished our independence in a number of more significant respects.
We've grown dependent on our cars for commuting to work. We rely on them like crutches for
short trips to the corner store, and for carting our children to and from school. Moreover, the
car has become a means not only to our assorted physical destinations but also to the
attainment of our socioeconomic goals, insofar as the automobile has become a symbol of
status. In fact, in my observation many, if not most, working professionals willingly undermine
their financial security for the sake of being seen driving this year's new SUV or luxury sedan.
In short, we've become slaves to the automobile.
Consider next the overall impact of the automobile on our strength as individuals, by which I
mean strength of character, or mettle. I would be hard-pressed to list one way in which the
automobile enhances one's strength of character. Driving a powerful SUV might afford a
person a feeling and appearance of strength, or machismo. But this feeling has nothing to do
with a person's true character.
In contrast, there is a certain strength of character that comes with eschewing modern
conveniences such as cars, and with the knowledge that one is contributing to a cleaner and
quieter environment, a safer neighborhood, and arguably a more genteel society. Also,
alternative modes of transportation such as bicycling and walking are forms of exercise which
require and promote the virtue of self-discipline. Finally, in my observation people who have
forsaken the automobile spend more time at home, where they are more inclined to prepare
and even grow their own food, and to spend more time with their families. The former
enhances one's independence; the latter enhances the integrity of one's values and the
strength of one's family.
To sum up, the automobile helps illustrate that when a luxury becomes a necessity it can sap
our independence and strength as individuals. Perhaps our society is better off, on balance,
with such "luxuries"; after all, the automobile industry has created countless jobs, raised our
standard of living, and made the world more interesting. However, by becoming slaves to the
automobile we trade off a certain independence and inner strength.
























Issue 10
"Most cultures encourage individuals to sacrifice a large part of their own personalities in order
to be like other people. Thus, most people are afraid to think or behave differently because
they do not want to be excluded."
The speaker claims that most cultures encourage conformity at the expense of individuality,
and as a result most people conform for fear of being excluded. While I find the second prong
of this dual claim well supported overall by empirical evidence, I take exception with the first
prong; aside from the cultures created by certain oppressive political regimes, no culture need
"encourage" its members to conform to prevailing ways of thought and behavior; in fact, all the
evidence shows that cultures attempt to do just the opposite.
As a threshold matter, it is necessary to distinguish between conformity that an oppressive
ruling state imposes on its own culture and conformity in a free democratic society. In the
former case, people are not only encouraged but actually coerced into suppressing individual
personality; and indeed these people are afraid to think and behave differently--but not for fear
of being excluded but rather for fear of punishment and persecution by the state. The modern
Communist and Fascist regimes are fitting examples. With respect to free democratic societies,
it might be tempting to dismiss the speaker's dual claim out of hand. After all, true democratic
states are predicated on individual freedoms---of choice, speech, expression, religion, and so
forth. Ostensibly, these freedoms serve to promote individuality, even non-conformity, in our
personas, our lifestyles, and our opinions and attitudes.
Yet, one look at any democratic society reveals a high degree of conformity among its
members. Every society has its own bundle of values, customs, and mores which most of its
members share. Admittedly, within any culture springs up various subcultures which try to
distinguish themselves by their own distinct values, customs, and mores. In the U.S., for
instance, African-Americans have developed a distinct dialect, known as Ebonics, and a
distinct body language and attitude which affords them a strong sub-cultural identity of their
own. Yet, the undeniable fact is that humans, given the actual freedom to either conform or not
conform, choose to think and behave in ways similar to most people in their social
group---however we define that group.
Nor is there much empirical evidence of any cultural agenda, either overt or covert, to
encourage conformity in thought and behavior among the members of any culture. To the
contrary, the predominant message in most cultures is that people should cultivate their
individuality. Consider, for example, the enduring and nearly ubiquitous icon of the ragged
individualist, who charts his or her own course, bucks the trend, and achieves notoriety
through individual creativity, imagination, invention, or entrepreneurship. Even our systems of
higher education seem to encourage individualism
by promoting and cultivating critical and independent thought among its students.
Yet, all the support for forging one's one unique persona, career, lifestyle, opinions, and
even belief system, turns out to be hype. In the final analysis, most people choose to conform.
And understandably so; after all, it is human nature to distrust, and even shun, others who are
too different from us. Thus to embrace rugged individualism is to risk becoming an outcast, the
natural consequence of which is to lLmit one's socioeconomic and career opportunities. This
prospect suffices to quell our yearning to be different; thus the speaker is correct that most of
us resign ourselves to conformity for fear of being left behind by our peers. Admittedly, few
cultures are without rugged individualists----the exceptional artists, inventors, explorers, social
reformers, and entrepreneurs who embrace their autonomy of thought and behavior, then test
their limits. And paradoxically, it is the achievements of these notable non-conformists that are
responsible for most cultural evolution and progress. Yet such notables are few and far
between in what is otherwise a world of insecure, even fearful, cultural conformists.
To sum up, the speaker is correct that most people choose to conform rather than behave
and think in ways that run contrary to their culture's norms, and that fear of being exduded lies
at the heart of this choice. Yet, no culture need encourage conformity; most humans recognize
that there is safety of numbers, and as a result freely choose conformity over the risks, and
potential rewards, of non-conformity.
























Issue 11
"There are two types of laws: just and unjust. Every individual in a society has a responsibility
to obey just laws and, even more importantly, to disobey and resist unjust laws."
According to this statement, each person has a duty to not only obey just laws but also disobey
unjust ones. In my view this statement is too extreme, in two respects. First, it wrongly
categorizes any law as either just or unjust; and secondly, it recommends an ineffective and
potentially harmful means of legal reform.
First, whether a law is just or unjust is rarely a straightforward issue. The fairness of any law
depends on one's personal value system. This is especially true when it comes to personal
freedoms. Consider, for example, the controversial issue of abortion. Individuals with particular
religious beliefs tend to view laws allowing mothers an abortion choice as unjust, while
individuals with other value systems might view such laws as just.
The fairness of a law also depends on one's personal interest, or stake, in the legal issue at
hand. After all, in a democratic society the chief function of laws is to strike a balance among
competing interests. Consider, for example, a law that regulates the toxic effluents a certain
factory can emit into a nearby river. Such laws are designed chiefly to protect public health. But
complying with the regulation might be costly for the company; the factory might be forced to
lay off employees or shut down altogether, or increase the price of its products to compensate
for the cost of compliance. At stake are the respective interests of the company's owners,
employees, and customers, as well as the opposing interests of the region's residents whose
health and safety are impacted. In short, the fairness of the law is subjective, depending
largely on how one's personal interests are affected by it.
The second fundamental problem with the statement is that disobeying unjust laws often has
the opposite affect of what was intended or hoped for. Most anyone would argue, for instance,
that our federal system of income taxation is unfair in one respect or another. Yet the end result
of widespread disobedience, in this case tax evasion, is to perpetuate the system. Free-riders
only compel the government to maintain tax rates at high levels in order to ensure adequate
revenue for the various programs in its budget.
Yet another fundamental problem with the statement is that by justifying a violation of one
sort of law we find ourselves on a slippery slope toward sanctioning all types of illegal behavior,
including egregious criminal conduct. Returning to the abortion example mentioned above, a
person strongly opposed to the freedom-of-choice position might maintain that the illegal
blocking of access to an abortion clinic amounts to justifiable disobedience. However, it is a
precariously short leap from this sort of civil disobedience to physical confrontations with clinic
workers, then to the infliction of property damage, then to the bombing of the clinic and
potential murder.
In sum, because the inherent function of our laws is to balance competing interests,
reasonable people with different priorities will always disagree about the fairness of specific
laws. Accordingly, radical action such as resistance or disobedience is rarely justified merely
by one's subjective viewpoint or personal interests. And in any event, disobedience is never
justifiable when the legal rights or safety of innocent people are jeopardized as a result.
























Issue 12
"Anyone can make things bigger and more complex. What requires real effort and courage is
to move in the opposite direction---in other words, to make things as simple as possible."
Whether making things simple requires greater effort and courage than making them bigger
and more complex depends on the sort of effort and courage. Indisputably, the many complex
technological marvels that are part-and-parcel of our Lives today are the result of the
extraordinary cumulative efforts of our engineers, entrepreneurs, and others. And, such
achievements always call for the courage to risk failing in a large way. Yet, humans seem
naturally driven to make things bigger and more complex; thus refraining from doing so, or
reversing this natural process, takes considerable effort and courage of a different sort, as
discussed below.
The statement brings immediately to mind the ever-growing and increasingly complex digital
world. Today's high-tech firms seem compelled to boldly go to whatever effort is required to
devise increasingly complex products, for the ostensible purpose of staying ahead of their
competitors. Yet, the sort of effort and courage to which the statement refers is a different
one--bred of vision, imagination, and a willingness to forego near term profits for the prospect
of making lasting contributions. Surely, a number of entrepreneurs and engineers today are
mustering that courage, and are making the effort to create far simpler, yet more elegant,
technologies and applications, which will truly make our lives simpler in sharp contrast to
what computer technology has delivered to us so far.
Lending even more credence to the statement is the so-called "big government"
phenomenon. Human societies have a natural tendency to create unwieldy bureaucracies, a
fitting example of which is the U.S. tax-law system. The Intemal Revenue Code and its
accompanying Treasury Regulations have grown so voluminous and complex that many
certified accountants and tax attorneys admit that they cannot begin to understand it all.
Admittedly, this system has grown only through considerable effort on the part of all three
branches of the federal government, not to mention the efforts of many special interest groups.
Yet, therein lies the statement's credibility. It requires great effort and courage on the part of a
legislator to risk alienating special interest groups, thereby risking reelection prospects, by
standing on principle for a simpler tax system that is less costly to administer and better serves
the interests of most taxpayers.
Adding further credibility to the statement is the tendency of most people to complicate their
personal lives--a tendency that seems especially strong in today's age of technology and
consumerism. The greater our mobility, the greater our number of destinations each day; the
more time-saving gadgets we use, the more activities we try to pack into our day; and with
readier access to information we try to assimilate more of it each day. I am hard-pressed to
think of one person who has ever exclaimed to me how much effort and courage it has taken to
complicate his or her life in these respects. In contrast, a certain self-restraint and courage of
conviction are both required to eschew modern conveniences, to simplify one'sdaily schedule,
and to establish and adhere to a simple plan for the use of one's time and money.
In sum, whether we are building computer networks, government agencies, or personal
lifestyles, great effort and courage are required to make things simple, or to keep them that
way. Moreover, because humans na~traUy tend to make things big and complex, it arguably
requires more effort and courage to move in the opposite direction. In the final analysis,
making things simple---or keeping them that way--takes a brand of effort born of reflection and
restraint rather than sheer exertion, and a courage character and conviction rather than
unbridled ambition.
























Issue 13
"Most people would agree that buildings represent a valuable record of any society's past, but
controversy arises when old buildings stand on ground that modern planners feel could be
better used for modern purposes. In such situations, modern development should be given
precedence over the preservation of historic buildings so that contemporary needs can be
served."
The speaker asserts that wherever a practical, utilitarian need for new buildings arises this
need should take precedence over our conflicting interest in preserving historic buildings as a
record of our past. In my view, however, which interest should take precedence should be
determined on a case-by-case basis--and should account not only for practical and historic
considerations but also aesthetic ones.
In determining whether to raze an older building, planners should of course consider the
community's current and anticipated utilitarian needs. For example, if an additional hospital is
needed to adequately serve the health-care needs of a fast-growing community, this
compelling interest might very well outweigh any interest in preserving a historic building that
sits on the proposed site. Or if additional parking is needed to ensure the economic survival of
a city's downtown district, this interest might take precedence over the historic value of an old
structure that stands in the way of a parking structure. On the other hand, if the need is mainly
for more office space, in some cases an architecturally appropriate add-on or annex to an
older building might serve just as well as razing the old building to make way for a new one. Of
course, an expensive retrofit might not be worthwhile if no amount of retrofitting would meet
the need.
Competing with a community's utilitarian needs is an interest preserving the historical record.
Again, the weight of this interest should be determined on a case-by-case basis. Perhaps an
older building uniquely represents a bygone era, or once played a central role in the city's
history as a municipal structure. Or perhaps the building once served as the home of a
founding family or other significant historical figure, or as the location of an important historical
event. Any of these scenarios might justify saving the building at the expense of the practical
needs of the community. On the other hand, if several older buildings represent the same
historical era just as effectively, or if the building's history is an unremarkable one, then the
historic value of the building might pale in comparison to the value of a new structure that
meets a compelling practical need.
Also competing with a community's utilitarian needs is the aesthetic and architectural value
of the building itself--apart from historical events with which it might be associated. A building
might be one of only a few that represents a certain architectural style. Or it might be especially
beautiful, perhaps as a result of the craftsmanship and materials employed in its
construction--which might be cost-prohibitive to replicate today. Even retrofitting the building to
accommodate current needs might undermine its aesthetic as well as historic value, by
altering its appearance and architectural integrity. Of course it is difficult to quantify aesthetic
value and weigh it against utilitarian considerations. Yet planners should strive to account for
aesthetic value nonetheless.
In sum, whether to raze an older building in order to construct a new one should never be
determined indiscriminately. Instead, planners should make such decisions on a case-by-case
basis, weighing the community's practical needs against the building's historic and aesthetic
value.
























Issue 14
"Students should memorize facts only after they have studied the ideas, trends, and concepts
that help explain those facts. Students who have learned only facts have learned very little."
The speaker makes a threshold claim that students who learn only facts learn very little, then
condudes that students should always learn about concepts, ideas, and trends before they
memorize facts. While I wholeheartedly agree with the threshold claim, the condusion unfairly
generalizes about the learning process. In fact, following the speaker's advice would actually
impede the learning of concepts and ideas, as well as impeding the development of insightful
and useful new ones.
Turning first to the speaker's threshold daim, I strongly agree that ifwe learn only facts we
learn very little. Consider the task of memorizing the periodic table of dements, which any
student can memorize without any knowledge of chemistry, or that the table relates to
chemistry. Rote memorization of the table amounts to a bit of mental exercise-an opportunity to
practice memorization techniques and perhaps learn some new ones. Otherwise, the student
has learned very little about chemical dements, or about anything for that matter.
As for the speaker's ultimate claim, I concede that postponing the memorization of facts until
after one leams ideas and concepts holds certain advantages. With a conceptual framework
already in place a student is better able to understand the meaning of a fact, and to appreciate
its significance. As a result, the student is more likely to memorize the fact to begin with, and
less likely to forget it as time passes. Moreover, in my observation students whose first goal is
to memorize facts tend to stop there--for whatever reason. It seems that by focusing on facts
first students risk equating the learning process with the assimilation of trivia; in turn, students
risk learning nothing of much use in solving real world problems.
Conceding that students must learn ideas and concepts, as well as facts relating to them, in
order to learning anything meaningful, I nevertheless disagree that the former should always
precede the latter--for three reasons. In the first place, I see know reason why memorizing a
fact cannot precede learning about its meaning and significance--as long as the student does
not stop at rote memorization. Consider once again our hypothetical chemistry student. The
speaker might advise this student to first learn about the historical trends leading to the
discovery of the elements, or to learn about the concepts of altering chemical compounds to
achieve certain reactions--before studying the periodic table. Having no familiarity with the
basic vocabulary of chemistry, which includes the informarion in the periodic table, this student
would come away from the first two lessons bewildered and confused in other words, having
learned little.
In the second place, the speaker misunderstands the process by which we learn ideas and
concepts, and by which we develop new ones. Consider, for example, how economics
students learn about the relationship between supply and demand, and the resulting concept
of market equilibrium, and of surplus and shortage. Learning about the dynamics of supply and
demand involves (1) entertaining a theory, and perhaps even formulating a new one, (2)
testing hypothetical scenarios against the theory, and (3) examining real-world facts for the
purpose of confirming, refuting, modifying, or qualifying the theory. But which step should
come first? The speaker would have us follow steps 1 through 3 in that order. Yet, theories,
concepts, and ideas rarely materialize out of thin air; they generally emerge from empirical
observations--i.e., facts. Thus the speaker's notion about how we should learn concepts and
ideas gets the learning process backwards.
In the third place, strict adherence to the speaker's advice would surely lead to illconceived
ideas, concepts, and theories. Why? An idea or concept conjured up without the benefit of data
amounts to little more than the conjurer's hopes and desires. Accordingly, conjurers will tend to
seek out facts that support their prejudices and opinions, and overlook or avoid facts that
refute them. One telling example involves theories about the center of the universe.
Understandably, we ego-driven humans would prefer that the universe revolve around us.
Early theories presumed so for this reason, and facts that ran contrary to this ego-driven
theory were ignored, while observers of these facts were scorned and even vilified. In short,
students who strictly follow the speaker's prescription are unlikely to contribute significantly to
the advancement of knowledge.
To sum up, in a vacuum facts are meaningless, and only by filling that vacuum with ideas
and concepts can students learn, by gaining useful perspectives and insights about facts. Yet,
since facts are the very stuff from which ideas, concepts, and trends spring, without some facts
students cannot learn much of anything. In the final analysis, then, students should learn facts
right along with concepts, ideas, and trends.
























Issue 15
"Unfortunately, the media tend to highlight what is sensational at the moment. Society would
be better served if the media reported or focused more fully on events and trends that will
ultimately have the most long-term significance."
The speaker asserts that rather than merely highlighting certain sensational events the
media should provide complete coverage of more important events. While the speaker's
assertion has merit from a normative standpoint, in the final analysis I find this assertion
indefensible.
Upon first impression the speaker's claim seems quite compelling, for two reasons. First,
without the benefit of a complete, unfiltered, and balanced account of current events, it is
impossible to develop an informed and intelligent opinion about important social and political
issues and, in turn, to contribute meaningfully to our democratic society, which relies on broad
participation in an ongoing debate about such issues to steer a proper course. The end result
of our being a largely uninformed people is that we relegate the most important decisions to a
handful of legislators, jurists, and executives who may or may not know what is best for us.
Second, by focusing on the "sensational"--by which I take the speaker to mean
comparatively shocking, entertaining, and titillating events which easily catch one's
attention-the media appeal to our emotions and baser instincts, rather than to our intellect and
reason. Any observant person could list many examples aptly illustrating the trend in this
direction--from trashy talk shows and local news broadcasts to The National Enquixer and
People Magazine. This trend dearly serves to undermine a society's collective sensibilities and
renders a society's members more vulnerable to demagoguery; thus we should all abhor and
resist the trend.
However, for several reasons I find the media's current trend toward highlights and the
sensational to be justifiable. First, the world is becoming an increasingly eventful place; thus
with each passing year it becomes a more onerous task for the media to attempt full news
coverage. Second, we are becoming an increasingly busy society. The average U.S. worker
spends nearly 60 hours per week at work now; and in most families both spouses work.
Compare this startlingly busy pace to the pace a generation ago, when one bread-winner
worked just over 40 hours per week. We have far less time today for news, so highlights must
suffice. Third, the media does in fact provide full coverage of important events; anyone can find
such coverage beyond their newspaper's front page, on daily PBS news programs, and on the
Internet. I would wholeheartedly agree with the speaker if the sensational highlights were all
the media were willing or permitted to provide; this scenario would be tantamount to thought
control on a mass scale and would serve to undermine our free society. However, I am aware
of no evidence of any trend in this direction. To the contrary, in my observation the media are
informing us more fully than ever before; we just need to seek out that information.
On balance, then, the speaker's claim is not defensible. In the final analysis the media
serves its proper function by merely providing what we in a free society demand. Thus any
argument about how the media should or should not behave--regardless of its merits from a
normative standpoint begs the question.

























Issue 16
"Public figures such as actors, politicians, and athletes should expect people to be interested
in their private lives. When they seek a public role, they should expect that they will lose at
least some of their privacy."
This statement is fundamentally correct; public figures should indeed expect to lose their
privacy. After all, we are a society of voyeurs wishing to transform our mundane lives; and one
way to do so is to live vicariously through the experiences of others whose lives appear more
interesting than our own. Moreover, the media recognize this societal foible and exploit it at
every opportunity. Nevertheless, a more accurate statement would draw a distinction between
political figures and other public figures; the former have even less reason than the latter to
expect to be left alone, for the reason that their duty as public servants legitimizes public
scrutiny of their private lives.
The chief reason why I generally agree with the statement is that, for better or worse,
intense media attention to the lives of public figures raises a presumption in the collective mind
of the viewing or reading public that our public figures' lives are far more interesting than our
own. This presumption is understandable. After all, I think most people would agree that given
the opportunity for even fleeting fame they would embrace it without hesitation. Peering into
the private lives of those who have achieved our dreams allows us to live vicariously through
those lives.
Another reason why I generally agree with the statement has to do with the forces that
motivate the media. For the most part, the media consist of large corporations whose chief
objective is to maximize shareholder profits. In pursuit of that objective the media are simply
giving the public what they demand a voyeuristic look into the private lives of public figures.
One need look no further than a newsstand, local-television news broadcast, or talk show to
find ample evidence that this is so. For better or worse, we love to peer at people on public
pedestals, and we love to watch them fall off. The media know this all too well, and exploit our
obsession at every opportunity.
Nevertheless, the statement should be qualified in that a political figure has less reason to
expect privacy than other public figures. Why? The private affairs of public servants become
our business when those affairs adversely affect our servants' ability to serve us effectively, or
when our servants betray our trust. For example, several years ago the chancellor of a
university located in my city was expelled from office for misusing university funds to renovate
his posh personal residence. The scandal became front-page news in the campus newspaper,
and prompted a useful system-wide reform. Also consider the Clinton sex scandal, which
sparked a debate about the powers and duties of legal prosecutors vis4-vis the chief executive.
Also, the court rulings about executive privilege and immunity, and even the impeachment
proceedings, all of which resulted from the scandal, might serve as useful legal precedents for
the future.
Admittedly, intense public scrutiny of the personal lives of public figures can carry harmful
consequences, for the public figure as well as the society. For instance, the Clinton scandal
resulted in enormous financial costs to taxpayers, and it harmed many individuals caught up in
the legal process. And for more that a year the scandal served chiefly to distract us from our
most pressing national and global problems. Yet, until as a society we come to appreciate the
potentially harmful effects of our preoccupation with the lives of public figures, they can expect
to remain the cynosures of our attention.
























Issue 17
"The primary goal of technological advancement should be to increase people's efficiency so
that everyone has more leisure time."
The speaker contends that technology's primary goal should be to increase our efficiency for
the purpose of affording us more leisure time. I concede that technology has enhanced our
efficiency as we go about our everyday lives. Productivity software helps us plan and
coordinate projects; intranets, the Internet, and satellite technology make us more efficient
messengers; and technology even helps us prepare our food and access entertainment more
efficiently. Beyond this concession, however, I find the speaker's contention indefensible from
both an empirical and a normative standpoint.
The chief reason for my disagreement lies in the empirical proof: with technological
advancement comes diminished leisure time. In 1960 the average U.S. family included only
one breadwinner, who worked just over 40 hours per week. Since then the average work week
has increased steadily to nearly 60 hours today; and in most families there are now two
breadwinners. What explains this decline in leisure despite increasing efficiency that new
technologies have brought about? I contend that technology itself is the culprit behind the
decline. We use the additional free time that technology affords us not for leisure but rather for
work. As computer technology enables greater and greater office productivity it also raises our
employers' expectations--or demands--for production. Further technological advances breed
still greater efficiency and, in turn, expectations. Our spiraling work load is only exacerbated by
the competitive business environment in which nearly all of us work today. Moreover, every
technological advance demands our time and attention in order to learn how to use the new
technology. Time devoted to keeping pace with technology depletes time for leisure activities.
I disagree with the speaker for another reason as well: the suggestion that technology's
chief goal should be to facilitate leisure is simply wrongheaded. There are far more vital
concerns that technology can and should address. Advances in bio-technology can help cure
and prevent diseases; advances in medical technology can allow for safer, less invasire
diagnosis and treatment; advances in genetics can help prevent birth defects; advances in
engineering and chemistry can improve the structural integrity of our buildings, roads, bridges
and vehicles; information technology enables education while communication technology
facilitates global participation in the democratic process. In short, health, safety, education, and
freedom--and not leisure--are the proper final objectives of technology. Admittedly, advances
in these areas sometimes involve improved efficiency; yet efficiency is merely a means to
these more important ends.
In sum, I find indefensible the speaker's suggestion that technology's value lies chiefly in the
efficiency and resulting leisure time it can afford us. The suggestion runs contrary to the
overwhelming evidence that technology diminishes leisure time, and it wrongly places leisure
ahead of goals such as health, safety, education, and freedom as technology's ultimate aims.
























Issue 18
"Money spent on research is almost always a good investment, even when the results of that
research are controversial."
I agree with the speaker's broad assertion that money spent on research is generally money
well invested. However, the speaker unnecessarily extends this broad assertion to embrace
research whose results are "controversial," while ignoring certain compelling reasons why
some types of research might be unjustifiable. My points of contention with the speaker
involves the fundamental objectives and nature of research, as discussed below.
I concede that the speaker is on the correct philosophical side of this issue. After all,
research is the exploration of the unknown for true answers to our questions, and for lasting
solutions to our enduring problems. Research is also the chief means by which we humans
attempt to satisfy our insatiable appetite for knowledge, and our craving to understand
ourselves and the world around us. Yet, in the very notion of research also lies my first point of
contention with the speaker, who illogically presumes that we can know the results of research
before we invest in it. To the contrary, if research is to be of any value it must explore
uncharted and unpredictable territory. In fact, query whether research whose benefits are
immediate and predictable can break any new ground, or whether it can be considered
"research" at all.
While we must invest in research irrespective of whether the results might be controversial,
at the same time we should be circumspect about research whose objectives are too vague
and whose potential benefits are too speculative. After all, expensive research always carries
significant opportunity costs--in terms of how the money might be spent toward addressing
society's more immediate problems that do not require research. One apt illustration of this
point involves the so-called "Star Wars" defense initiative, championed by the Reagan
administration during the 1980s. In retrospect, this initiative was ill-conceived and largely a
waste of taxpayer dollars; and few would dispute that the exorbitant amount of money devoted
to the initiative could have gone a long way toward addressing pressing social problems of the
day--by establishing after-school programs for delinquent latchkey kids, by enhancing AIDS
awareness and education, and so forth. As it turns out, at the end of the Star Wars debacle we
were left with rampant gang violence, an AIDS epidemic, and an unprecedented federal
budget deficit.
The speaker's assertion is troubling in two other r~sp,ects as well. First, no amount of
research can completely solve the enduring pr~l~rm of war, poverty, and violence, for the
reason that they stem from certain aspects of human nature--such as aggression and greed.
Although human genome research might eventually enable us to engineer away those
undesirable aspects of our nature, in the meantime it is up to our economists, diplomats, social
reformers, and jurists--not our research laboratories--to mitigate these problems. Secondly, for
every new research breakthrough that helps reduce human suffering is another that serves
primarily to add to that suffering. For example, while some might argue that physics
researchers who harnessed the power of the atom have provided us with an alternative source
of energy and invaluable "peace-keepers," this argument flies in the face of the hundreds of
thousands of innocent people murdered and maimed by atomic blasts, and by nuclear
meltdowns. And, in fulfilling the promise of "better living through chemistry" research has given
us chemical weapons for human slaughter. In short, so-called "advances" that scientific
research has brought about often amount to net losses for humanity.
In sum, the speaker's assertion that we should invest in research whose results are
"controversial" begs the question, because we cannot know whether research will turn out
controversial until we've invested in it. As for the speaker's broader assertion, I agree that
money spent on research is generally a sound investment because it is an investment in the
advancement of human knowledge and in human imagination and spirit. Nevertheless, when
we do research purely for its own sake without aim or clear purpose--we risk squandering
resources which could have been applied to relieve the immediate suffering of our dispirited,
disadvantaged, and disenfranchised members of society. In the final analysis, given finite
economic resources we are forced to strike a balance in how we allocate those resources
among competing societal objectives.
























Issue 19
"Creating an appealing image has become more important in contemporary society than is the
reality or truth behind that image."
Has creating an image become more important in our society than the reality or truth behind
the image? I agree that image has become a more central concern, at least where short-term
business or political success is at stake. Nevertheless, I think that in the longer term image
ultimately yields to substance and fact.
The important role of image is particularly evident in the business world. Consider, for
example, today's automobile industry. American cars are becoming essentially identical to
competing Japanese cars in nearly every mechanical and structural respect, as well as in price.
Thus to compete effectively auto companies must now differentiate their products largely
through image advertising, by conjuring up certain illusory benefits--such as machismo, status,
sensibility, or fun. The increasing focus on image is also evident in the book-publishing
business. Publishers are relying more and more on the power of their brands rather than the
content of their books. Today mass-market books are supplanted within a year with products
that are essential the same---except with fresh faces, rifles, and other promotional angles. I
find quite telling the fact that today more and more book publishers are being acquired by large
media companies. And the increasing importance of image is especially evident in the music
industry, where originality, artistic interpretation, and technical proficiency have yielded almost
entirely to sex appeal.
The growing significance of image is also evident in the political realm, particularly when it
comes to presidential politics. Admittedly, by its very nature politicking has always emphasized
rhetoric and appearances above substance and fact. Yet since the invention of the camera
presidential politicians have become increasingly concerned about their image. For example,
Teddy Roosevelt was very careful never to be photographed wearing a tennis outfit, for fear
that such photographs would serve to undermine his rough-rider image that won him his only
term in office. With the advent of television, image became even more central in presidential
politics. After all, it was television that elected J.F.K. over Nixon. And our only two-term
presidents in the television age were elected based largely on their image. Query whether
Presidents Lincoln, Taft, or even F.D.R. would be elected today if pitted against the handsome
leading man Reagan, or the suave and poliricaUy correct Clinton. After all, Lincoln was homely,
Taft was obese, and F.D.R. was crippled.
In the long term, however, the significance of image wanes considerably. The image of the
Marlboro man ultimately gave way to the truth about the health hazards of cigarette smoking.
Popular musical acts with nothing truly innovative to offer musically eventually disappear from
the music scene. And anyone who frequents yard sales knows that today's best-selling books
often become tomorrow's pulp. Even in politics, I think history has a knack for peeling away
image to focus on real accomplishments. I think history will remember Teddy Roosevelt, for
example, primarily for building the Panama Canal and for establishing our National Park
System--and not for his rough-and-ready wardrobe.
In the final analysis, it seems that in every endeavor where success depends to some
degree on persuasion, marketing, or salesmanship, image has indeed become the central
concern of those who seek to persuade. And as our lives become busier, our attention spans
briefer, and our choices among products and services greater, I expect this trend to continue
unabated--for better or worse.
























Issue 20
"Most of the people we consider heroic today were, in fact, very ordinary people who
happened to be in the right place at the right time."
I agree with the statement insofar as our heroes tend to be ordinary people like us. However,
I strongly disagree with the further assertion that people become heroes simply by being "in
the right place at the right time." If we look around at the sorts of people we choose as our
heroes, we real/ze that heroism has far less to do with circumstance than with how a hero
responds to it.
I concede that heroes are generally ordinary people. In my observation we choose as our
heroes people with whom we strongly identify--people who are very much like us. In fact many
of us call a parent, grandparent, or older sibling our hero. Why? My intuition is that the more a
person shares in common with us----m terms of experience, heritage, disposition, motives, and
even physical attributes-----~e more accessible that person's heroic traits are to us, and the
stronger their attraction as a role model. And few would dispute that we share more in common
with immediately family than with anyone else.
However, the statement's further suggestion that people become heroes merely as a result
of circumstances not of their own choosing is simply wrongheaded. Admittedly, circumstance
often serves as a catalyst for heroism. After all, without wars there would be no war heroes. Yet
this does not mean that we should lionize every member of the armed forces. I find quite telling
the oft-used idiom "heroic effort," which suggests that mere coincidence has little to do with
heroism. If one examines the sorts of people we select as our heroes, it becomes evident that
heroism requires great effort, and that the very nub of heroism lies in the response, not in the
circumstance.
Consider the ordinary person who overcomes a personal obstacle through extraordinary
effort, fortitude, or faith---thereby inspiring others toward similar accomplishments. Sports
heroes often fall into this category. For example, Lance Armstrong, a Tour de France cycling
champion, became a national hero not merely because he won the race but because he
overcame a life-threatening illness, against all odds, to do so. Of course, widespread notoriety
is not a requisite for heroic status. Countless individuals with physical and mental disabilities
become heroes in their community and among their acquaintances by treating their obstacles
as personal challenges--thereby setting inspirational examples. Consider the blind law student
who inspires others to overcome the same challenge; or the amputee distance runner who
serves as a role model for other physically challenged people in her community. To assert that
individuals such as these become our heroes merely by accident, as the statement seems to
suggest, is to completely misunderstand the very stuff of which heroes are made.
Another sort of hero is the ordinary person who attains heroic stature by demonstrating
extraordinary courage of conviction--against external oppressive forces. Many such heroes
are champions of social causes, rising to heroic stature by way of the courage of their
convictions; and, it is because we share those convictions--because we recognize these
champions as being very much like us----~at they become our heroes. Such heroes as India's
Mahatma Gandhi, America's Martin Luther King, South Africa's Nelson Mandela, and Poland's
Lech Lawesa come immediately to mind. None of these heroes was born into royalty or other
privilege; they all came from fairly common, or ordinary, places and experiences. Or consider
again our military heroes, whose courage and patriotism in battie the statement would serve to
completely discredit as merely accidental outcomes of certain soldiers being "m the right place
at the right time." I think the preposterousness of such a suggestion is clear enough.
In sum, the statement correctly suggests that heroes are ordinary people like us, and that
opportunity, or circumstance, is part of what breeds heroes. However, the statement overlooks
that serendipity alone does not a hero make. Heroism requires that "heroic effort," or better yet
a "heroic response," to one's circumstances in life.
























Issue 21
"The greatness of individuals can be decided only by those who live after them, not by their
contemporaries."
Can a person's greatness be recognized only in retrospect, by those who live after the
person, as the speaker maintains? In my view the speaker unfairly generalizes. In some areas,
especially the arts, greatness is often recognizable in its nascent stages. However, in other
areas, particularly the physical sciences, greatness must be tested over time before it can be
confirmed. In still other areas, such as business, the incubation period for greatness varies
from case to case.
We do not require a rear-view mirror to recognize artistic greatness--whether in music, visual
arts, or literature. The reason for this is simple: art can be judged at face value.There's nothing
to be later proved or disproved, affirmed or discredited, or even improved upon or refined by
further knowledge or newer technology. History is replete with examples of artistic greatness
immediately recognized, then later confm-ned. Through his patronage, the Pope recognized
Michelangelo's artistic greatness, while the monarchs of Europe immediately recognized
Mozart's greatness by granting him their most generous commissions. Mark Twain became a
best-selling author and household name even during his lifetime. And the leaders of the
modernist school of architecture marveled even as Frank Lloyd Wright was elevating their
notions about architecture to new aesthetic heights.
By contrast, in the sciences it is difficult to identify greatness without the benefit of historical
perspective. Any scientific theory might be disproved tomorrow, thereby demoting the
theorist's contribution to the status of historical footnote. Or the theory might withstand
centuries of rigorous scientific scrutiny. In any event, a theory may or may not serve as a
springboard for later advances in theoretical science. A current example involves the ultimate
significance of two opposing theories of physics: wave theory and quantum theory. Some
theorists now claim that a new so-called "string" theory reconciles the two opposing
theories--at least mathematically. Yet "strings" have yet to be confirmed empirically. Only time
will tell whether string theory indeed provides the unifying laws that all matter in the universe
obeys. In short, the significance of contributions made by theoretical scientists cannot be
judged by their contemporaries--only by scientists who follow them.
In the realm of business, in some cases great achievement is recognizable immediately,
while in other cases it is not. Consider on the one hand Henry Ford's assembly-line approach
to manufacturing affordable cars for the masses. Even Ford could not have predicted the
impact his innovations would have on the American economy and on the modern world. On the
other hand, by any measure, Microsoft's Bill Gates has made an even greater contribution
than Ford; after all, Gates is largely responsible for lifting American technology out of the
doldrums during the 1970s to restore America to the status of economic powerhouse and
technological leader of the world. And this contribution is readily recognizable now--as it is
happening. Of course, the DOS and Windows operating systems, and even Gates' monopoly,
might eventually become historical relics. Yet his greatness is already secured.
In sum, the speaker overlooks many great individuals, particularly in the arts and in business,
whose achievements were broadly recognized as great even during their own time.
Nevertheless, other great achievements, especially scientific ones, cannot be confirmed as
such without the benefit of historical perspective.
























Issue 22
"In the age of television, reading books is not as important as it once was. People can learn as
much by watching television as they can by reading books."
The speaker contends that people learn just as much from watching television as by reading
books, and therefore that reading books is not as important for learning as it once was. I
strongly disagree. I concede that in a few respects television, including video, can be a more
efficient and effective means of learning. In most respects, however, these newer media serve
as poor substitutes for books when it comes to learning.
Admittedly, television holds certain advantages over books for imparting certain types of
knowledge. For the purpose of documenting and conveying temporal, spatial events and
experiences, film and video generally provide a more accurate and convincing record than a
book or other written account. For example, it is impossible for anyone, no matter how keen an
observer and skilled a journalist, to recount in complete and objective detail such events as a
Ballanchine ballet, or the scene at the intersection of Florence and Normandy streets during
the 1992 Los Angeles riots. Besides, since the world is becoming an increasingly eventful
place, with each passing day it becomes a more onerous task for journalists, authors, and
book publishers to recount these events, and disseminate them in printed form. Producers of
televised broadcasts and videos have an inherent advantagein this respect. Thus the
speaker's claim has some merit when it comes to arts education and to learning about modern
and current events.
However, the speaker overlooks several respects m which books are inherently superior to
television as a medium for learning. Watching television or a video is no indication that any
significant learning is taking place; the comparatively passive nature of these media can
render them ineffectual in the learning process. Also, books are far more portable than
television sets. Moreover, books do not break, and they do not depend on electricity, batteries,
or access to airwaves or cable connections---aU of which may or may not be available in a
given place. Finally, the effort required to read actively imparts a certain discipline which
serves any person well throughout a lifetime of learning.
The speaker also ignores the decided tendency on the part of owners and managers of
television media to ffiter information in order to appeal to the widest viewing audience, and
thereby maximize profit. And casting the widest possible net seems to involve focusing on the
sensational---that is, an appeal to our emotions and baser instincts rather than our intellect and
reasonableness. The end result is that viewers do not receive complete, unfiltered, and
balanced information, and therefore cannot rely on television to develop informed and
intelligent opinions about important social and political issues.
Another compelling argument against the speaker's claim has to do with how well books and
television serve their respective archival functions. Books readily enable readers to review and
cross-reference material, while televised broadcasts do not. Even the selective review of
videotape is far more trouble than it is worth, especially if a printed resource is also available.
Moreover, the speaker's claim carries the implication that all printed works, fiction and
non-fiction alike, not transferred to a medium capable of being televised, are less significance
as a result. This implication serves to discredit the invaluable contributions of all the
philosophers, scientists, poets, and others of the past, upon whose immense shoulders society
stands today.
A final argument that books are made no less useful by television has to do with the
experience of perusing the stacks in a library, or even a bookstore. Switching television
channels, or even scanning a video library, simply cannot duplicate this experience. Why not?
Browsing among books allows for serendipity--unexpectedly coming across an interesting and
informative book while searching for something else, or for nothing in particular. Moreover,
browsing through a library or bookstore is a pleasurable sensory experience for many
people--an experience that the speaker would have us forego forever.
In sum, television and video can be more efficient than books as a means of staying abreast
of current affairs, and for education in the arts that involve moving imagery. However, books
facilitate learning in certain ways that television does not and cannot. In the final analysis, the
optimal approach is to use both media side by side--television to keep us informed and to
provide moving imagery, along with books to provide perspective and insight on that
information and imagery.
























Issue 23
"Scholars and researchers should not be concerned with whether their work makes a
contribution to the larger society. It is more important that they pursue their individual interests,
however unusual or idiosyncratic those interests may seem."
Should academic scholars and researchers be free to pursue whatever avenues of inquiry
and research that interest them, no matter how unusual or idiosyncratic, as the speaker
asserts? Or should they strive instead to focus on those areas that are most likely to benefit
society? l strongly agree with the speaker, for three reasons.
First of all, who is to decide which areas of academic inquiry are worthwhile? Scholars
cannot be left to decide. Given a choice they will pursue their own idiosyncratic areas of
interest, and it is highly unlikely that all scholars could reach a fully informed consensus as to
what research areas would be most worthwhile. Nor can these decisions be left to regulators
and legislators, who would bring to bear their own quirky notions about what would be
worthwhile, and whose susceptibility to influence renders them untrustworthy in any event.
Secondly, by human nature we are motivated to pursue those activities in which we excel. To
compel scholars to focus only on certain areas would be to force many to waste their true
talents. For example, imagine relegating today's preeminent astrophysicist Stephen Hawking
to research the effectiveness of affirmative-action legislation in reducing workplace
discrimination. Admittedly, this example borders on hyperbole. Yet the aggregate effect of
realistic cases would be to waste the intellectual talents of our world's scholars and
researchers. Moreover, lacking genuine interest or motivation, a scholar would be unlikely to
contribute meaningfully to his or her "assigned" field of study.
Thirdly, it is "idiosyncratic" and "unusual" avenues of inquiry that lead to the greatest
contributions to society. Avenues of intellectual and scientific inquiry that break no new ground
amount to wasted time, talent, and other resources. History is laden with unusual claims by
scholars and researchers that turned out stunningly significant--that the sun lies at the center
of our universe, that time and space are relative concepts, that matter consists of discrete
particles, that humans evolved from other life forms, to name a few. One current area of
unusual research is terraforming---creating biological life and a habitable atmosphere where
none existed before. This unusual research area does not immediately address society's
pressing social problems. Yet in the longer term it might be necessary to colonize other planets
in order to ensure the survival of the human race; and after all, what could be a more
significant contribution to society than preventing its extinction?
Those who would oppose the speaker's assertion might point out that public universities
should not allow their faculty to indulge their personal intellectual fantasies at taxpayer
expense. Yet as long as our universities maintain strict procedures for peer review, pure
quackery cannot persist for very long. Other detractors might argue that in certain academic
areas, particularly the arts and humanities, research and intellectually inquiry amount to little
more than a personal quest for happiness or pleasure. This specious argument overlooks the
societal benefits afforded by appreciating and cultivating the arts. And, earnest study in the
humanities affords us wisdom to know what is best for society, and helps us understand and
approach societal problems more critically, creatively, and effectively. Thus despite the lack of
a tangible nexus between certain areas of intellectual inquiry and societal benefit, the nexus is
there nonetheless.
In sum, I agree that we should allow academic scholars nearly unfettered freedom of
intellectual inquiry and research within reasonable limits as determined by peer review.
Engaging one's individual talents in one's particular area of fascination is most likely to yield
advances, discoveries, and innovations that serve to make the world a better and more
interesting place in which to live.
























Issue 24
"Such nonmainstream areas of inquiry as astrology, fortune-telling, and psychic and
paranormal pursuits play a vital role in society by satisfying human needs that are not
addressed by mainstream science."
This statement actually consists of two claims: (1) that non-mainstream areas of inquiry are
vital in satisfying human needs, and (2) that these areas are therefore vital to society. I
concede that astrology, fortune-telling, and psychic and paranormal pursuits respond to certain
basic human needs. However, in my view the potential harm they can inflict on their
participants and on society far outweighs their psychological benefits.
Admittedly, these non-mainstream areas of inquiry address certain human needs, which
mainstream science and other areas of intellectual inquiry inherently cannot. One such need
involves our common experience as humans that we freely make our own choices and
decisions in life and therefore carry some responsibility for their consequences. Faced with
infinite choices, we experience uncertainty, insecurity, and confusion; and we feel remorse,
regret, and guilt when in retrospect our choices turn out be poor ones. Understandably, to
prevent these bad feelings many people try to shift the burden of making difficult choices and
decisions to some nebulous authority outside themselves--by rely-ing on the stars or on a
stack of tarot cards for guidance.
Two other such needs have to do with our awareness that we are mortal. This awareness
brings a certain measure of pain that most people try to relieve by searching for evidence of an
afterlife. Absent empirical proof that life extends beyond the grave, many people attempt to
contact or otherwise connect with the so-called "other side" through paranormal and psychic
pursuits. Another natural response to the prospect of being separated from our loved ones by
death is to search for a deeper connection with others here on Earth and elsewhere, in the
present as well as the past. This response manifests itself in people's enduring fascination with
the paranormal search for extraterrestrial life, with so- called "past life" regression and
"channeling," and the like.
While the sorts of pursuits which the speaker lists might be "vital" insofar as they help some
people feel better about themselves and about their choices and circumstances, query
whether these pursuits are otherwise useful to any individual or society. In the first place,
because these pursuits are not rooted in reason, they are favorite pastimes of charlatans and
others who seek to prey on dupes driven by the aforementioned psychological needs. And the
dupes have no recourse. After all, it is impossible to assess the credibility of a tarot card that
tells us how to proceed in life simply because we cannot know where the paths not taken
would have led. Similarly, we cannot evaluate claims about the afterlife because these claims
inherently defy empirical proof--or disproof.
In the second place, without any sure way to evaluate the legitimacy of these avenues of
inquiry, participants become vulnerable to self-deception, false hopes, fantastic ideas, and
even delusions. In turn, so-called "insights" gained from these pursuits can too easily serve as
convenient excuses for irrational and unreasonable actions that harm others. On a personal
level, stubborn adherence to irrational beliefs in the face of reason and empirical evidence can
lead to self-righteous arrogance, intolerance, anti-social behavior, and even hatred. Moreover,
on a societal level these traits have led all too often to holy wars, and to such other atrocities
as genocide and mass persecution.
In sum, I concede that the non-mainstream pursuits that the speaker lists are legitimate
insofar as they afford many people psychological solace in life. However, when such pursuits
serve as substitutes for reason and logic, and for honest intellectual inquiry, participants begin
to distrust intellect as an impediment to enlightenment. In doing so, they risk making
ill-conceived choices for themselves and unfair judgments about others--a risk that in my view
outweighs the psychological rewards of those pursuits.
























Issue 25
"To be an effective leader, a public official must maintain the highest ethical and moral
standards."
Whether successful leadership requires that a leader follow high ethical and moral
standards is a complex issue--one that is fraught with the problems of defining ethics, morality,
and successful leadership in the first place. In addressing the issue it is helpful to consider in
turn three distinct forms of leadership: business, political, and social-spiritual.
In the business realm, successful leadership is generally defined as that which achieves the
goal of profit maximization for a firm's shareholders or other owners. Moreover, the prevailing
view in Western corporate culture is that by maximizing profits a business leader fulfills his or
her highest moral or ethical obligation. Many disagree, however, that these two obligations are
the same. Some detractors claim, for example, that business leaders have a duty to do no
intentional harm to their customers or to the society in which they operate--for example, by
providing safe products and by implementing pollution control measures. Other detractors go
further--to impose on business leaders an affirmative obligation to protect consumers,
preserve the natural environment, promote education, and otherwise take steps to help
alleviate society's problems.
Whether our most successful business leaders are the ones who embrace these additional
obligations depends, of course, on one's own definition of business success. In my
observation, as business leaders become subject to closer scrutiny by the media and by social
activists, business leaders will maximize profits in the long term only by taking reasonable
steps to minimize the social and environmental harm their businesses cause. This observation
also accords with my personal view of a business leader's ethical and moral obligation.
In the political realm the issue is no less complex. Definitions of successful political
leadership and of ethical or moral leadership are tied up in the means a leader uses to wield
his or her power and to obtain that power in the first place. One useful approach is to draw a
distinction between personal morality and public morality. In my observation personal morality
is unrelated to effective political leadership. Modern politics is replete with examples of what
most people would consider personal ethical failings: the marital indiscretions of President
Kennedy, for instance. Yet few would disagree that these personal moral choices adversely
affected his ability to lead.
In contrast, pubhc morality and successful leadership are more closely connected. Consider
the many leaders, such as Stalin and Hitler, whom most people would agree were egregious
violators of public morality. Ultimately such leaders forfeit their leadership as a result of the
immoral means by which they obtained or wielded their power. Or consider less egregious
examples such as President Nixon, whose contempt for the very legal system that afforded
him his leadership led to his forfeiture of it. It seems that in the short term unethical public
behavior might serve a political leader's interest in preserving his or her power; yet in the long
term such behavior invariably results in that leader's down-fall that is, in failure.
One must also consider a third type of leadership: social-spiritual. Consider notable figures
such as Gandhi and Martin Luther King, whom few would disagree were eminently successful
in leading others to practice the high ethical and moral standards which they advocated.
However, I would be hard-pressed to name one successful social or spiritual leader whose
leadership was predicated on the advocacy of patently unethical or immoral behavior. The
reason for this is simple: high standards for one's own public morality are prerequisites for
successful social-spiritual leadership.
In sum, history informs us that effective political and social-spiritual leadership requires
adherence to high standards of public morality. However, when it comes to business
leadership the relationship is less clear; successful business leaders must strike a balance
between achieving profit maximization and fulfilling their broader obligation to the society,
which comes with the burden of such leadership.
























Issue 26
"While some leaders in government, sports, industry, and other areas attribute their success to
a well-developed sense of competition, a society can better prepare its young people for
leadership by instilling in them a sense of cooperation."
Which is a better way to prepare young people for leadership: developing in them a spirit of
competitiveness or one of cooperation? The speaker favors the latter approach, even though
some leaders attribute their success to their keenly developed competitive spirit. I tend to
agree with the speaker, for reasons having to do with our increasingly global society, and with
the true keys to effective leadership.
The chief reason why we should stress cooperation in nurturing young people today is that,
as tomorrow's leaders, they will face pressing societal problems that simply cannot be solved
apart from cooperative international efforts. For example, all nations will need to cooperate in
an effort to disarm themselves of weapons of mass destruction; to reduce harmful emissions
which destroy ozone and warm the Earth to dangerous levels; to reduce consumption of the
Earth's finite natural resources; and to cure and prevent diseases before they become global
epidemics. Otherwise, we all risk self-destruction. In short, global peace, economic stability,
and survival of the species provide powerful reasons for developing educational paradigms
that stress cooperation over competition.
A second compelling reason for instilling in young people a sense of cooperation over
competition is that effective leadership depends less on the latter than the former. A leader
should show that he or she values the input of subordinates--for example, by involving them in
decisions about matters in which they have a direct stake. Otherwise, subordinates might grow
to resent their leader, and become unwilling to devote themselves wholeheartedly to the
leader's mission. In extreme cases they might even sabotage that mission, or even take their
useful ideas to competitors. And after all, without other people worth leading a person cannot
be a leader let alone an effective one.
A third reason why instilling a sense of cooperation is to be preferred over instilling a sense
of competition is that the latter serves to narrow a leader's focus on thwarting the efforts of
competitors. With such tunnel vision it is difficult to develop other, more creative means of
attaining organizational objectives. Moreover, such means often involve synergistic solutions
that call for alliances, partnerships, and other cooperative efforts with would-be competitors.
Those who would oppose the speaker might point out that a thriving economy depends on a
freely competitive business environment, which ensures that consumers obtain high-quality
goods and services at low prices. Thus key leadership positions, especially in business,
inherently call for a certain tenacity and competitive spirit. And, a competitive spirit seems
especially critical in today's hyper-competitive technology-driven economy, where any leader
f~iling to keep pace with ever-changing business and technological paradigms soon fails by
the wayside. However, a leader's effectiveness as a competitor is not necessarily inconsistent
with his or her ability to cooperate with subordinates or with competitors, as noted above.
In sum, ifwe were to take the speaker's advice too far we would risk becoming a world
without leaders, who are bred of a competitive spirit. We would also risk the key benefits of a
free-market economy. Nevertheless, on balance I agree that it is more important to instill in
young people a sense of cooperation than one of competition. The speaker's preference
properly reflects the growing role of cooperative alliances and efforts in solving the world's
most pressing problems. After all, in a world in which our very survival as a species depends
on cooperation, the spirit of even healthy competition, no matter how healthy, is of little value to
any of us.
























Issue 27
"Society does not place enough emphasis on the intellect---that is, on reasoning and other
cognitive skills."
The speaker asserts that society should place more emphasis on intellect and cognition.
While the speaker might overlook the benefits of nurturing certain emotions and feelings, on
balance I agree that it is by way of our heads rather than our hearts that we can best ensure
the well-being of our society.
I concede that undue emphasis on cultivating the intellect at the expense of healthy
emotions can harm an individual psychologically. Undue suppression of legitimate and healthy
desires and emotions can result in depression, dysfunction, and even physical illness. In fact,
the intellect can mask such problems, thereby exacerbating them. To the extent they occur on
a mass scale these problems become societal ones--lowering our economic productivity,
burdening our health-care and social-welfare systems, and so forth. I also concede that by
encouraging and cultivating certain positive emotions and feelings--such as compassion and
empathy--society dearly stands to benefit.
In many other respects, however, emphasizing emotions and de-emphasizing intellect can
carry negative, even dangerous, consequences for any society. Our collective sense of
fairness, equity, and justice can easily give way to base instincts like hate, greed, and lust for
power and domination. Thus, on balance any society is better off quelling or at least tempering
these sorts of instincts, by nurturing reason, judgment, tolerance, fairness, and
understanding--all of which are products of the intellect.
The empirical evidence supporting this position is overwhelming; yet one need look no
further than a television set. Most of us have been witness to the current trend in trashy talk
shows, which eschew anything approaching intellectual discourse in favor of pan &ring to our
baser urges and instincts like jealousy, lust and hate. Episodes often devolve into anti-social,
sometimes violent, behavior on the part of participants and observers alike. And any ostensible
"lessons learned" from such shows hardly justify the antisocial outbursts that the producers
and audiences of these shows hope for.
The dangers of a de-emphasis on intellect are all too evident in contemporary America.The
incidence of hate crimes is increasing at a startUng rate; gang warfare is at an all-time high;
the level of distrust between African Americans and white America seems to be growing.
Moreover, taken to an extreme and on a mass scale, appeal to the emotions rather than the
intellect has resulted in humanity's most horrific atrocities, like the Jewish holocaust, as well as
in nearly every holy war ever waged throughout history. Indeed, suppressing reason is how
demagogues and despots gain and hold their power over their citizen-victims. In contrast,
reason and better judgment are effective deterrents to despotism, demagoguery, and
especially to war.
Those opposed to the speaker's position might argue that stressing cognition and intellect at
the expense of emotion and feeling would have a chilling effect on artistic creativity, which
would work a harm to the society. However, even in the arts students must learn theories and
techniques, which they then apply to their craft whether it be music performance, dance, or
acting. And creative writing requires the cognitive ability to understand how language is used
and how to best communicate ideas. Besides, creative ability is itsdf partly a function of
intellect; that is, creative expression is a marriage between cognitive ability and the expression
of feelings and emotions.
In sum, emotions and feelings can serve as important catalysts for compassion and for
creativity. Yet behaviors that are most harmful to any society are also born of emotions and
instincts, which the intellect can serve to override. The inescapable conclusion, then, is that
the speaker is fundamentally correct.
























Issue 28
"The study of history places too much emphasis on individuals. The most significant events
and trends in history were made possible not by the famous few, but by groups of people
whose identities have long been forgotten."
The speaker claims that significant historical events and trends are made possible by groups
of people rather than individuals, and that the study of history should emphasize the former
instead of the latter. I tend to disagree with both aspects of this claim. To begin with, learning
about key historical figures inspires us to achieve great things ourselves--far more so than
learning about the contributions of groups of people. Moreover, history informs us that it is
almost always a key individual who provide the necessary impetus for what otherwise might be
a group effort, as discussed below.
Admittedly, at times distinct groups of people have played a more pivotal role than key
individuals in important historical developments. For example, history and art apprecia don
courses that study the Middle Ages tend to focus on the artistic achievements of particular
artists such as Fra Angelico, a Benedictine monk of that period. However, Western civilization
owes its very existence not to a few famous painters but rather to a group of Benedictine nuns
of that period. Just prior to and during the decline of the Roman Empire, many women fled to
join Benedictine monasteries, bringing with them substantial dowries which they used to
acquire artifacts, art works, and manuscripts. As a result, their monasteries became centers for
the preservation of Western culture and knowledge which would otherwise have been lost
forever with the fall of the Roman Empire.
However, equally influential was Johannes Gutenberg, whose invention of the printing press
several centuries later rendered Western knowledge and culture accessible to every class of
people throughout the known world. Admittedly, Gutenberg was not single handedly
responsible for the outcomes of his invention. Without the support of paper manufacturers,
publishers, and distributors, and without a sufficient demand for printed books, Gutenberg
would never have become one of"the famous few." However, I think any historian would agree
that studying the groups of people who rode the wave of Gutenberg's invention is secondary in
understanding history to learning about the root historical cause of that wave. Generally
speaking, then, undue attention to the efforts and contributions of various groups tends to
obscure the cause-and-effect relationships with which the study of history is chiefly concerned.
Gutenberg is just one example of an historical pattern in which it is individuals who have
been ultimately responsible for the most significant developments in human history. Profound
scientific inventions and discoveries of the past are nearly all attributable not to forgettable
groups of people but to certain key individuals--for example, Copernicus, Newton, Edison,
Einstein, Curie, and of course Gutenberg. Moreover, when it comes to seminal sociopolitical
events, the speaker's claim finds even less support from the historical record. Admittedly,
sweeping social changes and political reforms require the participation of large groups of
people. However, I would be hard-pressed to identify any watershed sociopolitical event
attributable to a leaderless group. History informs us that groups rally only when incited and
inspired by key individuals.
The speaker might claim that important long-term sociological trends are often instigated not
by key individuals but rather by the masses. I concede that gradual shifts in demography, in
cultural traditions and mores, and in societal attitudes and values can carry just as significant
an historical impact as the words and deeds of "the famous few." Yet, it seems that key
individuals almost invariably provide the initial spark for those trends. For instance, prevailing
attitudes about sexual morality stem from the ideas of key religious leaders; and a culture's
prevailing values concerning human life are often rooted in the policies and prejudices of
political leaders. The speaker might also point out that history's greatest architectural and
engineering feats--such as the Taj Mahal and the Great W~--- came about only thm~h the
efforts of large groups of workers. A~, however, it was the famous few--monarchs in these
cases whose whims and egos were the driving force behind these accomplishments.
To sum up, with few historical exceptions, history is shaped by key individuals, not by
nameless, faceless groups. It is the famous few that provide visions of the future, visions which
groups then bring to fruition. Perhaps the speaker's claim will have more merit at the close of
the next millennium since politics and science are being conducted increasingly by
consortiums and committees. Yet, today it behooves us to continue draw ing inspiration from
"the famous few," and to continue understanding history chiefly in terms of their influence.
























Issue 29
"Imaginative works such as novels, plays, films, fairy tales, and legends present a more
accurate and meaningful picture of human experience than do factual accounts. Because the
creators of fiction shape and focus reality rather than report on it literally, their creations have a
more lasting significance."
Do imaginative works hold more lasting significance than factual accounts, for the reasons
the speaker cites? To some extent the speaker overstates fiction's comparative significance.
On balance, however, I tend to agree with the speaker. By recounting various dimensions of
the human experience, a fictional work can add meaning to and appreciation of the times in
which the work is set. Even where a fictional work amounts to pure fantasy, with no historical
context, it can still hold more lasting significance than a factual account. Examples from
literature and film serve to illustrate these points.
I concede that most fictional works rely on historical settings for plot, thematic, and character
development. By informing us about underlying political, economic, and social conditions,
factual accounts provide a frame of reference needed to understand and appredate
imaginative works. Fact is the basis for fiction, and fiction is no substitute for fact. I would also
concede that factual accounts are more "accurate" than fictional ones--insofar as they are
more objective. But this does not mean that factual accounts provide a "more meaningful
picture of the human experience." To the contrary, only imaginative works can bring an
historical period alive by way of creative tools such as imagery and point of view. And, only
imaginative works can provide meaning to historical events--through the use of devices such
as symbolism and metaphor.
Several examples from literature serve to illustrate this point. Twain's novels afford us a
sense of how 19th-Century Missouri would have appeared through the eyes of 10-year old
boys. Melville's "Billy Budd" gives the reader certain insights into what travel on the high seas
might have been like in earlier centuries, through the eyes of a crewman. And the epic poems
"Beowulf" and "Sir Gawain and the Green Knight" provide glimpses of the relationships
between warriors and their kings in medieval times. Bare facts about these historical eras are
easily forgettable, whereas creative stories and portrayals such as the ones mentioned above
can be quite memorable indeed. In other words, what truly lasts are our impressions of what
life must have been like in certain places, at certain times, and under certain conditions. Only
imaginative works can provide such lasting impressions.
Examples of important films underscore the point that creative accounts of the human
experience hold more lasting significance than bare factual accounts. Consider four of our
most memorable and influential films: Citizen Kane, Schindkr5 LaSt, The Wizard of O~ and
Star Wars. Did Welles' fictional portrayal of publisher William Randolph Hearst or Spielberg's
fictional portrayal of a Jewish sympathizer during the holocaust provide a more "meaningful
picture of human experience" than a history textbook? Did these accounts help give "shape
and focus" to reality more so than newsreels alone could? If so, will these works hold more
"lasting significance" than bare factual accounts of the same persons and events? I think
anyone who has seen these films would answer all three questions affirmatively. Or consider
The Wizard of O~ and Star Wars. Both films, and the novels from which they were adapted,
are pure fantasy. Yet both teem with symbolism and metaphor relating to life's journey, the
human spirit, and our hopes, dreams and ambitions--in short, the human experience. Therein
lies the reason for their lasting significance.
In sum, without prior factual accounts fictional works set in historical periods lose much of
their meaning. Yet only through the exercise of artistic license can we convey human
experience in all its dimensions, and thereby fully understand and appreciate life in other times
and places. And it is human experience, and not bare facts and figures, that endures in our
minds and souls.
























Issue 30
"In order to improve the quality of instruction at the college and university level, all faculty
should be required to spend time working outside the academic world in professions relevant
to the courses they teach."
Whether college faculty should also work outside academia, in professional work related to
their academic fields, depends primarily on the specific academic area. With respect to fields
in which outside work is appropriate, I strongly agree with the statement; students and faculty
all stand to gain in a variety of respects when a professor complements academic duties with
real-world experience.
As a threshold matter, the statement requires qualification in two respects. First, in certain
academic areas there is no profession to speak of outside academia. This is especially true in
the humanities; after all, what work outside academia is there for professors of literature or
philosophy? Secondly, the statement fails to consider that in certain other academic areas a
professor's academic duties typically involve practical work of the sort that occurs outside
academia. This is especially true in the fine and performing arts, where faculty actively engage
in the craft by demonstrating techniques and styles for their students.
Aside from these two qualifications, I strongly agree that it is worthwhile for college faculty to
work outside academia in professional positions related to their field. There are three dear
benefits of doing so. First, in my experience as a student, faculty who are actively engaged in
their fields come to class with fresh insights and a contagious excitement about the subject at
hand. Moreover, they bring to their students practical, real-world examples of the principles
and theories discussed in textbooks, thereby sparking interest, and even motivating some
students to pursue the field as a career.
Secondly, by keeping abreast with the changing demands of work as a professional,
professors can help students who are serious about pursuing a career in that field to make
more informed career decisions. The professor with field experience is better able to impart
useful, up-to-date information about what work in the field entails, and even about the current
job market. After all, college career-planning staff are neither equipped nor sufficiently
experienced to provide such specific advice to students.
A third benefit has to do with faculty research and publication in their areas of specialty.
Experience in the field can help a professor ferret out cutting-edge and controversial
issues--which might be appropriate subjects for research and publication. Moreover, practical
experience can boost a professor's credibility as an expert in the field. For example, each year
a certain sociology professor at my college combined teaching with undercover work
investigating various cults. Not only did the students benefit from the many interesting stories
this professor had to tell about his experiences, the professor's publications about cults
catapulted him to international prominence as an expert on the subject, and justifiably so.
In sum, aside from certain academic areas in which outside work is either unavailable or
unnecessary, students and faculty alike stand everything to gain when faculty enrich their
careers by interspersing field work with academic work.
























Issue 31
"In any academic area or professional field, it is just as important to recognize the limits of our
knowledge and understanding as it is to acquire new facts and information."
Does recognizing the limits of our knowledge and understanding serve us equally well as
acquiring new facts and information, as the speaker asserts? While our everyday experience
might lend credence to this assertion, further reflection reveals its fundamental inconsistency
with our Western view of how we acquire knowledge. Nevertheless, a careful and thoughtful
definition of knowledge can serve to reconcile the two.
On the one hand, the speaker's assertion accords with the everyday experience of working
professionals. For example, the sort of"book'I knowledge that medical, law, and business
students acquire, no matter how extensive, is of little use unless these students also learn to
accept the uncertainties and risks inherent in professional practice and in the business world.
Any successful doctor, lawyer, or entrepreneur would undoubtedly agree that new precedents
and challenges in their fields compel them to acknowledge the limitations of their knowledge,
and that learning to accommodate these limitations is just as important in their professional
success as knowledge itself.
Moreover, the additional knowledge we gain by collecting more information often
diminishes-sometimes to the point where marginal gains turn to marginal losses. Consider, for
instance, the collection of financial-investment information. No amount of knowledge can
eliminate the uncertainty and risk inherent in financial investing. Also, information overload can
result in confusion, which in turn can diminish one's ability to assimilate information and apply
it usefully. Thus, by recognizing the limits of their knowledge, and by accounting for those limits
when making decisions, investment advisors can more effectively serve their clients.
On the other hand, the speaker's assertion seems self-contradictory, for how can we know
the limits of our knowledge until we've thoroughly tested those limits through exhaustive
empirical observation--that is, by acquiring facts and information. For example, it would be
tempting to concede that we can never understand the basic forces that govern all matter in
the universe. Yet due to increasingly precise and extensive fact-finding efforts of scientists, we
might now be within striking distance of understanding the key laws by which all physical
matter behaves. Put another way, the speaker's assertion flies in the face of the scientific
method, whose fundamental tenet is that we humans can truly know only that which we
observe. Thus Francis Bacon, who fn:st formulated the method, might assert that the speaker
is fundamentally incorrect.
How can we reconcile our experience in everyday endeavors with the basic assumption
underlying the scientific method? Perhaps the answer lies in a distinction between two types of
knowledge--one which amounts to a mere collection of observations (i.e., facts and
information), the other which is deeper and includes a realization of principles and truths
underlying those observations. At this deeper level "knowledge" equals "under-standing": how
we interpret, make sense of, and find meaning in the information we collect by way of
observation.
In the final analysis, evaluating the speaker's assertion requires that we define "knowledge,''
which in turn requires that we address complex epistemological issues best left to
philosophers and theologians. Yet perhaps this is the speaker's point: that we can never truly
know either ourselves or the world, and that by recognizing this limitation we set ourselves free
to accomplish what no amount of mere information could ever permit.
























Issue 32
"The concept of 'individual responsibility' is a necessary fiction. Although societies must hold
individuals accountable for their own actions, people's behavior is largely determined by forces
not of their own making."
I fundamentally agree with the speaker's first contention, for unless we embrace the concept
of "individual responsibility" our notions of moral accountability and human equality, both
crucial to the survival of any democratic society, will whither. However, I strongly disagree with
the second contention--that our individual actions are determined largely by external forces.
Although this claim is not entirely without support, it runs contrary to common sense and
everyday human experience.
The primary reason that individual responsibility is a necessary fiction is that a society where
individuals are not held accountable for their actions and choices is a lawless one, devoid of
any order whatsoever. Admittedly, under some circumstances a society of laws should carve
out exceptions to the rule of individual responsibility--for example, for the hopeless psychotic
who has no control over his or her thoughts or actions. Yet to extend forgiveness much further
would be to endanger the social order upon which any civil and democratic society depends.
A correlative argument for individual responsibility involves the fact that lawless, or anarchist,
states give way to despotic rule by strong individuals who seize power. History informs us that
monarchs and dictators often justify their authority by claiming that they are preordained to
assume it--and that as a result they are not morally responsible for their oppressive actions.
Thus, any person abhorring despotism must embrace the concept of individual responsibility.
As for the speaker's second claim, it flies in the face of our everyday experiences in making
choices and decisions. Although people often claim that life's circumstances have "forced"
them to take certain actions, we all have an infinite number of choices; it's just that many of our
choices are unappealing, even self-defeating. Thus, the complete absence of free WIU would
seem to be possible only in the case of severe psychosis, coma, or death.
Admittedly, the speaker's second contention finds support from "strict determinist"
philosophers, who maintain that every event, including human actions and choices, is
physically necessary, given the laws of nature. Recent advances in molecular biology and
genetics lend some credence to this position, by suggesting that these determining physical
forces include our own individual genetic makeup. But, the notion of scientific determinism
opens the door for genetic engineering, which might threaten equality in socioeconomic
opportunity, and even precipitate the development of a "master race." Besides, since neither
free will nor determinism has been proven to be the correct position, the former is to be
preferred by any humanist and in any democratic society.
In sum, without the notion of individual responsibility a civilized, democratic society would
soon devolve into an anarchist state, vulnerable to despotic rule. Yet, this notion is more than a
mere fiction. The idea that our actions spring primarily from our free will accords with common
sense and everyday experience. I concede that science might eventually vindicate the speaker
and show that our actions are largely determined by forces beyond our conscious control. Until
that time, however, I'll trust my intuition that we humans should be, and in fact are, responsible
for our own choices and actions.
























Issue 33
"Universities should require every student to take a variety of courses outside the student's
field of study because acquiring knowledge of various academic disciplines is the best way to
become truly educated."
I fundamentally agree with the proposition that students must take courses outside their
major field of study to become "truly educated." A contrary position would reflect a too narrow
view of higher education and its proper objectives. Nevertheless, I would caution that
extending the proposition too far might risk undermining those objectives.
The primary reason why I agree with the proposition is that "me" education amounts to far
more than gaining the knowledge and ability to excel in one's major course of study and in
one's professional career. True education also facilitates an understanding of one- self, and
tolerance and respect for the viewpoints of others. Courses in psychology, sociology, and
anthropology all serve these ends. "True" education also provides insight and perspective
regarding one's place in society and in the physical and metaphysical worlds. Courses in
political science, philosophy, theology, and even sciences such as astronomy and physics can
help a student gain this insight and perspective. Finally, no student can be truly educated
without having gained an aesthetic appreciation of the world around us--through course work
in literature, the fine arts, and the performing arts.
Becoming truly educated also requires sufficient mastery of one academic area to permit a
student to contribute meaningfully to society later in life. Yet, mastery of any specific area
requires some knowledge about a variety of others. For example, a political-science student
can fully understand that field only by understanding the various psychological, sociological,
and historical forces that shape political ideology. An anthropologist cannot excel without
understanding the social and political events that shape cultures, and without some knowledge
of chemistry and geology for performing field work. Even computer engineering is intrinsically
tied to other fields, even non-technical ones such as business, communications, and media.
Nevertheless, the call for a broad educational experience as the path to becoming truly
educated comes with one important caveat. A student who merely dabbles in a hodgepodge of
academic offerings, without special emphasis on any one, becomes a dilettante lacking
enough knowledge or experience in any single area to come away with anything valuable to
offer. Thus in the pursuit of true education students must be careful not to overextend
themselves----or risk defeating an important objective of education.
In the final analysis, to become truly educated one must strike a proper balance in one's
educational pursuits. Certainly, students should strive to excel in the specific requirements of
their major course of study. However, they should complement those efforts by pursuing
course work in a variety of other areas as well. By earnestly pursuing a broad education one
gains the capacity not only to succeed in a career, but also to find purpose and meaning in that
career as well as to understand and appreciate the world and its peoples. To gain these
capacities is to become "truly educated."
























Issue 34
"People work more productively in teams than individually. Teamwork requires cooperation,
which motivates people much more than individual competition does."
The speaker asserts that because teamwork requires cooperative effort, people are more
motivated and therefore more productive working in teams than working individually as
competitors. My view is that this assertion is true only in some cases. If one examines the
business world, for example, it becomes clear that which approach is more effective in
motivating people and in achieving productivity depends on the specific job.
In some jobs productivity dearly depends on the ability of coworkers to cooperate as
members of a team. For businesses involved in the production of products through complex
processes, all departments and divisions must work in lock-step fashion toward product
roll-out. Cooperative interaction is even essential in jobs performed in relative isolation and in
jobs in which technical knowledge or ability, not the ability to work with others, would seem to
be most important. For example, scientists, researchers, and even computer programmers
must collaborate to establish common goals, coordinate efforts, and meet time lines. Moreover,
the kinds of people attracted to these jobs in the first place are likely to be motivated by a
sense of common purpose rather than by individual ambition.
In other types of jobs individual competition, tenacity, and ambition are the keys to
productivity. For example, a commissioned salesperson's compensation, and sometimes
tenure and potential for promotion as well, is based on comparative sales performance of
coworkers. Working as competitors a firm's individual salespeople maximize productivity-in
terms of profit--both for themselves and for their finn. Key leadership positions also call, above
all, for a certain tenacity and competitive spirit. A finn's founding entrepreneur must maintain
this spirit in order for the firm to survive, let alone to maximize productivity. Moreover, in my
observation the kinds of people inclined toward entrepreneurship and sales in the first place
are those who are competitive by nature, not those who are motivated primarily by a sense of
common purpose.
On balance, however, my view is that cooperation is more crucial for an organization's
long-term productivity than individual competition. Even in jobs where individual
competitiveness is part-and-parcel of the job, the importance of cooperation should not be
underestimated. Competition among sales people can quickly grow into jealousy, back
stabbing, and unethical behavior all of which are counterproductive. And even the most
successful entrepreneurs would no doubt admit that without the cooperative efforts of their
subordinates, partners, and colleagues, their personal visions would never become reality.
In sum, individual competitiveness and ambition are essential motivating forces for certain
types of jobs, while in other jobs it is a common sense of mission that motivates workers to
achieve maximum productivity. In the final analysis, however, the overall productivity of almost
every organization depends ultimately on the ability of its members to cooperate as a team.



























Issue 35
"Colleges and universities should offer more courses on popular music, film, advertising, and
television because contemporary culture has much greater relevance for students than do arts
and literature of the past."
The speaker asserts that the curriculum of colleges and universities should emphasize popular
culture--music, media, literature, and so forth rather than literature and art of the past, for the
reason that the former is more relevant to students. I strongly disagree. Although courses in
popular culture do play a legitimate role in higher education, formal study of the present culture
at the expense of studying past cultures can undermine the function of higher education, and
ultimately provide a disservice to students and to society.
Admittedly, course work in popular culture is legitimate and valuable for three reasons. First,
popular culture is a mirror of society's impulses and values. Thus, any serious student of the
social sciences, as well as students of media and communications, should take seriously the
literature and art of the present. Secondly, in every age and culture some worthwhile art and
literature emerges from the mediocrity. Few would disagree, for example, that the great
modem-jazz pioneers such as Charlie Parker and Thelonius Monk, and more recently Lennon
and McCarmey, and Stevie Wonder, have made just as lasting a contribution to music as some
of the great classical musicians of previous centuries. Thirdly, knowledge of popular films,
music, and art enables a person to find common ground to relate to other people. This leads to
better communication between different subcultures.
Nevertheless, emphasizing the study of popular culture at the expense of studying classical
art and literature can carry harmful consequences for students, as well as for society. Without
the benefit of historical perspective gamed through the earnest study of the art and literature of
the past, it is impossible to fully understand, appreciate, and critique literature and art of the
present. Moreover, by approaching popular culture without any yardstick for quality it is
impossible to distinguish mediocre art from worthwhile art. Only by studying the classics can
an individual develop fair standards for judging popular works. Besides, emphasis on the
formal study of popular culture is unnecessary. Education in popular culture is readily available
outside the classroom---on the Internet, through educational television programming, and
through the sorts of everyday conversations and cross-talk that occur at water coolers and in
the coffee houses of any college campus.
In sum, while the study of popular literature and art can be worthwhile, it has to be
undertaken in conjunction with an even greater effort to learn about the literature and art of the
past. In the absence of the latter, our universities will produce a society of people with no
cultural perspective, and without any standards for determining what merits our attention and
nurtures society.
























Issue 36
"A person's own habits and attitudes often limit that person's freedom more than do restrictions
imposed by others."
I strongly agree with the contention that we often limit our own freedom through our habits
and attitudes. By limiting our own freedom, we often serve our own interests. And as we learn
this lesson, we cultivate certain attitudes and habits--particularly in our relationships with
others--by which we apply that lesson, and which continue throughout life.
To appreciate that from an early age we ingrain in ourselves habits that serve to constrain
our freedom, one need look no further than the neighborhood playground. Even without adult
supervision, a group of youngsters at play invariably establish mutually agreed-upon rules of
conduct--whether or not a sport or game is involved. Children learn that without any rules for
behavior the playground bully usually prevails. Thus our habit of making choices that constrain
our own freedom stems from our desire to protect our own interests, and it begins at an early
age.
This habit of making choices that constrain our own freedom continues into our adult lives.
As we mature, most of us develop the attitude that monogamous relationships are preferable
to polygamous ones--thus our habit of entering into exclusive pair-bonding relationships.
During our teens we agree to "go steady," then as adults we voluntarily enter into marriage
contracts. As we enter the working world, we carry these attitudes and habits with us. We
eagerly engage in exclusive employment relationships---with the attitude that the security of
steady income is preferable to the "freedom" of not knowing where our next paycheck will
come from. Even people who prefer self-employment to job security quickly develop the
attitude that the only way to preserve their autonomy is to constrain themselves in terms of
their agreements with clients and customers, and especially in terms of how they use their me.
Those who disagree that we tend to restrict our own freedom through our habits and
attitudes involving personal and employment relationships might cite the often-heard complaint
about life's circumstances leaving one with "no choice." One complaining person might feel
trapped in a job or a marriage, by their boss or partner. Another complainant might blame his
or her spendthrift habits on enticing advertisements, the pressure to appear successful, and so
forth. However, people in situations such as these are not actually at the mercy of others.
Instead, they have a significant degree of personal freedom, but simply choose one alternative
over others that might be less appealing or even self-defeating. For example, almost every
person who blames someone else for being trapped in a job is simply choosing to retain a
certain measure of financial security. The choice to forego this security is always available,
although it might carry unpleasant consequences.
That through our attitudes we serve to constrain our own freedom is evident on a societal
level as well. Just as children at a playground quickly develop the habit of imposing rules and
regulations on themselves, as a society we do the same. After all, in a democracy our system
of laws is an invention of the people. For example, we insist on being bound by restrictions for
operadng motor vehides, for buying and selling both real and personal property, and for
making public statements about other people. Without these restrictions, we would live in
continual fear for our physical safety, the security of our property, and our personal reputation
and dignity. Thus most of the rules and regulations we claim are imposed on us we have
ultimately imposed on ourselves, as a society, in order to protect ourselves.
In the final analysis, in contenting that our habits and attitudes "often" serve to restrict our
freedom more than restraints that others place on us do, the statement does not even go far
enough. Despite our occasional sense that others are restricting our choices, on both an
individual and a societal level we are ultimately the ones who, through our attitudes and habits,
limit our own freedom.
























Issue 37
"In any realm of life---whether academic, social, business, or political---the only way to
succeed is to take a practical, rather than an idealistic, point of view. Pragmatic behavior
guarantees survival, whereas idealistic views tend to be superceded by simpler, more
immediate options."
I agree with the speaker insofar as that a practical, pragmatic approach toward our endeavors
can help us survive in the short tenn. However, idealism is just as crucial if not more so--for
long-term success in any endeavor, whether it be in academics, business, or political and
social reform.
When it comes to academics, students who we would consider pragmatic tend not to pursue
an education for its own sake. Instead, they tend to cut whatever corners are needed to
optimize their grade average and survive the current academic term. But, is this approach the
only way to succeed academically? Certainly not. Students who eamesdy pursue intellectual
paths that truly interest them are more likely to come away with a meaningful and lasting
education. In fact, a sense of mission about one's area of fascination is strong motivation to
participate actively in class and to study earnesdy, both of which contribute to better grades in
that area. Thus, although the idealist-student might sacrifice a high overall grade average, the
depth of knowledge, academic discipline, and sense of purpose the student gains will serve
that student well later in life.
In considering the business world it might be more tempting to agree with the speaker; after
all, isn't business fundamentally about pragmatism--that is, "getting the job done" and paying
attention to the "bottom line"? Emphatically, no. Admittedly, the everyday machinations of
business are very much about meeting mundane short-term goals: deadlines for production,
sales quotas, profit margins, and so forth. Yet underpinning these activities is the vision of the
company's chief executive--a vision which might extend far beyond mere profit maximization to
the ways in which the frrm can make a lasting and meaningful contribution to the community, to
the broader economy, and to the society as a whole. Without a dream or vision--that is, without
strong idealist leadership--a firm can easily be cast about in the sea of commerce without dear
direction, threatening not only the fLrm's bottom line but also its very survival.
Finally, when it comes to the political arena, again at fzrst blush it might appear that
pragmatism is the best, if not the only, way to succeed. Most politicians seem driven by their
interest in being elected and reelected--that is, in surviving--rather than by any sense of
mission, or even obligation to their constituency or country. Diplomatic and legal maneuverings
and negotiations often appear intended to meet the practical needs of the parties
involved--minimizing costs, preserving options, and so forth. But, it is idealists-not
pragmatists--who sway the masses, incite revolutions, and make political ideology reality.
Consider idealists such as America's founders, Mahatma Gandhi, or Martin Luther IGng. Had
these idealists concerned themselves with short-term survival and immediate needs rather
than with their notions of an ideal society, the United States and India might still be British
colonies, and African-Americans might still be relegated to the backs of buses.
In short, the statement fails to recognize that idealism--keeping one's eye on an ultimate
prize--is the surest path to long-term success in any endeavor. Meeting one's immediate
needs, while arguably necessary for short-term survival, accomplishes litde without a sense of
mission, a vision, or a dream for the long term.
























Issue 38
"The study of history has value only to the extent that it is relevant to our daily lives."
The speaker alleges that studying history is valuable only insofar as it is relevant to our daily
lives. I find this allegation to be specious. It wrongly suggests that history is not otherwise
instructive and that its relevance to our everyday lives is limited. To the contrary, studying
history provides inspiration, innumerable lessons for living, and useful value-clarification and
perspective---all of which help us decide how to live our lives.
To begin with, learning about great human achievements of the past provides inspiration.
For example, a student inspired by the courage and tenacity of history's great explorers might
decide as a result to pursue a career in archeology, oceanography, or astronomy. This decision
can, in turn, profoundly affect that student's everyday life--in school and beyond. Even for
students not inclined to pursue these sorts of careers, studying historical examples of courage
in the face of adversity can provide motivation to face their own personal fears in life. In short,
learning about grand accomplishments of the past can help us get through the everyday
business of living, whatever that business might be, by emboldening us and lifting our spirits.
In addition, mistakes of the past can teach us as a society how to avoid repeating those
mistakes. For example, history can teach us the inappropriateness of addressing certain social
issues, particularly moral ones, on a societal level. Attempts to legislate morality invariably fail,
as aptly illustrated by the Prohibition experiment in the U.S. during the 1930s. Hopefully, as a
society we can apply this lesson by adopting a more enlightened legislative approach toward
such issues as free speech, criminalization of drug use, criminal justice, and equal rights under
the law.
Studying human history can also help us understand and appreciate the mores, values, and
ideals of past cultures. A heightened awareness of cultural evolution, in turn, helps us
formulate informed and reflective values and ideals for ourselves. Based on these values and
ideals, students can determine their authentic life path as well as how they should allot their
time and interact with others on a day-to-day basis.
Finally, it might be tempting to imply from the speaker's allegation that studying history has
little relevance even for the mundane chores that occupy so much of our time each day, and
therefore is of little value. However, from history we learn not to take everyday activities and
things for granted. By understanding the history of money and banking we can transform an
otherwise routine trip to the bank into an enlightened experience, or a visit to the grocery store
into an homage to the many inventors, scientists, engineers, and entrepreneurs of the past
who have made such convenience possible today. And, we can fully appreciate our freedom to
go about our daily lives largely as we choose only by understanding our political heritage. In
short, appreciating history can serve to elevate our everyday chores to richer, more interesting,
and more enjoyable experiences.
In sum, the speaker fails to recognize that in all our
activities and decisions--from our grandest to our most rote--history can inspire, inform, guide,
and nurture. In the final analysis, to study history is to gain the capacity to be more
human--and I would be hard- pressed to imagine a worthier end.
























Issue 39
"It is primarily through formal education that a culture tries to perpetuate the ideas it favors and
discredit the ideas it fears."
The speaker asserts that a culture perpetuates the ideas it favors while discrediting those it
fears primarily through formal education. I agree that grade-school, and even high-school,
education involves cultural indoctrination. Otherwise, I think the speaker misun-derstands the
role of higher education, and overlooks other means by which a culture achieves these ends.
I agree with the speaker with respect to formal grade-school and even high-school
education--which to some extent amount to indoctrination with the values, ideas, and
principles of mainstream society. In my observation, young students are not taught to question
authority, to take issue with what they are taught, or to think critically for themselves. Yet, this
indoctrination is actually desirable to an extent. Sole emphasis on rote learning of facts and
figures is entirely appropriate for grade-school children, who have not yet gained the
intellectual capacity and real-world experience to move up to higher, more complex levels of
thinking. Nevertheless, the degree to which our grade schools and high schools emphasize
indoctrination should not be overstated. After all, cultural mores, values, and biases have little
to do with education in the natural sciences, mathe matics, and specific language skills such
as reading and writing.
Although the speaker's assertion has some merit when it comes to the education of young
people, I find it erroneous when it comes to higher education. The mission of our colleges and
universities is to afford students cultural perspective and a capacity for understanding
opposing viewpoints, and to encourage and nurture the skills of critical analysis and
skepticism--not to indoctrinate students with certain ideas while quashing others. Admittedly,
colleges and universities are bureaucracies and therefore not immune to political influence
over what is taught and what is not. Thus to some extent a college's curriculum is vulnerable to
wealthy and otherwise influential benefactors, trustees, and government agencies who by
advancing the prevailing cultural agenda serve to diminish a college's effectiveness in carrying
out its true mission. Yet, my intuition is that that such influences are minor ones, especially in
public university systems.
The speaker's assertion is also problematic in that it ignores two significant other means by
which our culture perpetuates ideas it favors and discredits ideas it fears. One such means is
our system of laws, by which legislators and jurists formulate and then impose so-called
"public policy." Legislation and judicial decisions carry the weight of law and the threat of
punishment for those who deviate from that law. As a result, they are highly effective means of
forcing on us official notions of what is good for society and for quashing ideas that are
deemed threatening to the social fabric, and to the safety and security of the government and
the governed. A second such means is the mainstream media. By mirroring the culture's
prevailing ideas and values, broadcast and print media serve to perpetuate them. It is
important to distinguish here between mainstream media-such as broadcast television--and
alternative media such as documentary films and non-commercial websites, whose typical
aims are to call into question the status quo, expose the hypocrisy and unfair bias behind
mainstream ideas, and bring to light ideas that the powers-that-be most fear. Yet, the influence
of alternative media pales in comparison to that of mainstream media.
In sum, the speaker's assertion is not without merit when it comes to the role of grade
schools and high schools. However, the speaker over-generalizes about what students are
taught--especially at colleges and universities. Moreover, the speaker's assertion ignores other
effective ways in which mainstream culture perpetuates its agenda.
























Issue 40
"In many countries it is now possible to turn on the television and view government at work.
Watching these proceedings can help people understand the issues that affect their lives. The
more kinds of government proceedings---trials, debates, meetings, etc.---that are televised,
the more society will benefit."
I strongly agree that the more government proceedings--debates, meeting, and so
forth---that are televised, the more society will benefit overall. Nevertheless, undue emphasis
on this means of informing a constituency has the potential for harm--which any society must
take care not to allow.
Access to government proceedings via television carries several significant benefits. The
main benefit lies in two useful archival functions of videotaped proceedings. First, videotapes
are valuable supplements to conventional means of record keeping. Although written
transcripts and audio tapes might provide an accurate record of what is said, only video tapes
can convey the body language and other visual clues that help us understand what people say,
whether they are being disingenuous, sarcastic, or sincere. Secondly, videotape archives
provide a useful catalogue for documentary journalists.
Televised proceedings also provide three other useful functions. First, for shut-ins and people
who live in remote regions, it might be impracticable, or even impossible, to view government
proceedings in person. Secondly, with satellite television systems it is possible to witness the
governments of other cities, states, and even nations at work. This sort of exposure provides
the viewer a valuable sense of perspective, an appreciation for other forms of government, and
so forth. Thirdly, in high schools and universities, television proceedings can be useful
curriculum supplements for students of government, public policy, law, and even public
speaking.
Nevertheless, televising more and more government proceedings carries certain risks that
should not be ignored. Watching televised government proceedings is inherently a rather
passive experience. The viewer cannot voice his or her opinions, objections, or otherwise
contribute to what is being viewed. Watching televised proceedings as a substitute for active
participation in the political process can, on a mass scale, undermine the democratic process
by way of its chilling effect on participation. Undue emphasis on tele government poses the risk
that government proceedings will become mere displays, or shows, for the public, intended as
public relations ploys and so-called "photo opportunities,'' while the true business of
government is moved behind closed doors.
In sum, readier access to the day-day business of a government can only serve to inform
and educate. Although undue reliance on televised proceedings for information can quell
active involvement and serve as a censor for people being televised, I think these are risks
worth taking in the interest of disclosure.
























Issue 41
"The purpose of many advertisements is to make consumers want to buy a product so that
they will 'be like' the person in the ad. This practice is effective because it not only sells
products but also helps people feel better about themselves."
The speaker asserts that the many ads which make consumers want to "be like" the person
portrayed in the ad are effective not only in selling products but also in helping consumers feel
better about themselves. This assertion actually consists of two claims: that this advertising
technique is used effectively in selling many products, and that consumers who succumb to
this technique actually feel better about themselves as a result. While I agree with the first
claim, I strongly disagree with the second one.
Turning first to the statement's threshold claim, do many ads actually use this technique to
sell products in the first place? Consider ads like the wildly popular Budweiser commercial
featuring talking frogs. There's nothing in that ad to emulate; its purpose is merely to call
attention to itself. Notwithstanding this type of ad, in my observation the majority of ads provide
some sort of model that most consumers in the target market would want to emulate, or "be
like." While some ads actually portray people who are the opposite of what the viewer would
want to "be like," these ads invariably convey the explicit message that to avoid being like the
person in the ad the consumer must buy the advertised product. As for whether the many,
many ads portraying models are effective in selling products, I am not privy to the sort of
statistical information required to answer this question with complete certainty. However, my
intuition is that this technique does help sell products; otherwise, advertisers would not use it
so persistently.
Turning next to the statement's ultimate claim that these ads are effective because they help
people who buy the advertised products feel better about themselves, I find this claim to be
specious. Consumers lured by the hope of "being like" the person in an ad might experience
some initial measure of satisfaction in the form of an ego boost. We have all experienced a
certain optimism immediately after acquiring something we've wanted a good feeling that
we're one step closer to becoming who we want to be. However, in my experience this sense
of optimism is ephemeral, invariably giving way to disappointment that the purchase did not
live up to its implicit promise.
One informative example of this false hope involves the dizzying array of diet aids, skin
creams, and fitness machines available today. The people in ads for these products are
youthful, fit, and attractive what we all want to "be like." And the ads are effective in selling
these products; today's health-and-beauty market feeds a multi-billion dollar industry. But the
end result for the consumer is an unhealthy preoccupation with physical appearance and
youth, which often leads to low self-esteem, eating disorders, injuries from over-exercise, and
so forth. And these problems are sure signs of consumers who feel worse, not better, about
themselves as a result of having relied on the false hope that they will "be like" the model in the
ad.
Another informative example involves products that pander to our desire for socioeco-nomic
status. Ads for luxury cars and upscale dothing typically portray people with lucrative careers
living in exclusive neighborhoods. Yet, I would wager that no person whose life-style actually
resembles these portrayals could honestly claim that purchasing certain consumer products
contributed one iota to his or her socioeconomic success. The end result for the consumer is
envy of others that can afford even more expensive possessions, and ultimately low
self-esteem based on feelings of socioeconomic inadequacy.
In sum, while ads portraying people we want to "be like" are undoubtedly effective in selling
products, they are equally ineffective in helping consumers feel better about themselves. In
fact, the result is a sense of false hope, leading ultimately to disappointment and a sense of
failure and inadequacy--in other words, feeling worse about ourselves.
























Issue 42
"When we concern ourselves with the study of history, we become storytellers. Because we
can never know the past directly but must construct it by interpreting evidence, exploring
history is more of a creative enterprise than it is an objective pursuit. All historians are
storytellers."
Are all historians essentially storytellers, for the reasons that the speaker cites? In asserting
that we can never know the past directly, the speaker implies that we truly "know" only what we
experience first-hand. Granting this premise, I agree that it is the proper and necessary role of
historians to "construct" history by interpreting evidence. Nevertheless, the speaker's
characterization of this role as "storytelling" carries certain unfair implications, which should be
addressed.
One reason why I agree with the speaker's fundamental claim lies in the distinction between
the role of historian and the roles of archivist and journalist. By "archivist" I refer generally to
any person whose task is to document and preserve evidence of past events. And by
"journalist" I mean any person whose task is to record, by writing, film, or some other media,
factual events as they occur--for the purpose of creating evidence of those events. It is not the
proper function of either the journalist or the archivist to tell a story. Rather, it is their function to
provide evidence to the historian, who then pieces together the evidence to construct history,
as the speaker suggests. In other words, unless we grant to the historian a license to
"construct" history by interpreting evidence, we relegate the historian to the role of mere
archivist or journalist.
Another reason why I agree with the speaker's characterization of the historian's proper
function is that our understanding of history is richer and fuller as a result. By granting the
historian license to interpret evidence--to "construct" history--we allow for differing viewpoints
among historians. Based on the same essential evidence, two historians might disagree about
such things as the contributing causes of a certain event, the extent of influence or impact of
one event on subsequent events, the reasons and motives for the words and actions of
important persons in history, and so forth. The inexorable result of disagreement, debate, and
divergent interpretations among historians is a fuller and more incisive understanding of
history.
However, we should be careful not to confuse this license to interpret history, which is
needed for any historian to contribute meaningfully to our understanding of it, with artistic
license. The latter should be reserved for dramatists, novelists, and poets. It is one thing to
attempt to explain historical evidence; it is quite another to invent evidence for the sake of
creating a more interesting story or to bolster one's own point of view. A recently released
biography of Ronald Reagan demonstrates that the line which historians should not cross is a
fine one indeed. Reagan's biographer invented a fictional character who provided commentary
as a witness to key episodes during Reagan's life. Many critics charge that the biographer
overstepped his bounds as historian; the biographer claims, however, that the accounts in the
biography were otherwise entirely factual, and that the fictional narrator was merely a literary
device to aid the reader in understanding and appredating the historical Reagan.
In sum, I strongly agree that the historian's proper function is to assemble evidence into
plausible constructs of history, and that an element of interpretation and even creativity is
properly involved in doing so. And if the speaker wishes to call these constructs "storytelling,"
that's fine. This does not mean, however, that historians can or should abandon scholarship for
the sake of an interesting story.
























Issue 43
"Some educational systems emphasize the development of students' capacity for reasoning
and logical thinking, but students would benefit more from an education that also taught them
to explore their own emotions."
The speaker asserts that educational systems should place less emphasis on reason and
logical thinking and more emphasis on the exploration of emotions. While I concede that in
certain fields students are well served by nurturing their emotions and feelings, in most
academic disciplines it is by cultivating intellect rather than emotions that students master their
discipline and, in turn, gain a capacity to contribute to the well-being of society.
I agree with the speaker insofar as undue emphasis on reason and logical thinking can have
a chilling effect on the arts. After all, artistic ideas and inspiration spring not from logic but from
emotions and feelings such as joy, sadness, hope, and love. And, the true measure of artistic
accomplishment lies not in technical proficiency but rather in a work's impact on the emotions
and spirit. Nevertheless, even in the arts, students must learn theories and techniques, which
they then apply to their craft. And, creative writing requires the cognitive ability to understand
how language is used and how to communicate ideas. Besides, creative ability is itself partly a
function of intellect; that is, creative expression is a marriage of one's cognitive abilities and the
expression of one's feelings and emotions.
Aside from its utility in the arts, however, the exploration of emotions has little place in
educational systems. The physical sciences and mathematics are purely products of reason
and logic. Even in the so-called "soft" sciences, emotion should play no part. Consider, for
example, the study of history, political science, or public policy, each of 'which is largely the
study of how the concepts of fairness, equity, and justice work themselves out. It is tempting to
think that students can best understand and learn to apply these concepts by tapping feelings
such as compassion, empathy, sympathy, and indignation. Yet fairness, equity, and justice
have little to do with feelings, and everything to do with reason. After all, emotions are
subjective things. On the other hand, reason is objective and therefore facilitates
communication, consensus, and peaceful compromise.
Indeed, on a systemic scale undue emphasis on the exploration of our emotions can have
deleterious societal consequences. Emotions invite irrationality in thought and action, the
dangers of which are all too evident in contemporary America. For example, when it comes to
the war on drugs, free speech and religion, abortion issues, and sexual choices, public policy
today seems to simply mirror the voters' fears and prejudices. Yet common sense dictates that
social ills are best solved by identifying cause-and-effect relation-ships---in other words,
through critical thinking. The proliferation of shouting-match talk shows fueled by irrationality
and emotion gone amuck is further evidence that our culture lends too much credence to our
emotions and not enough to our minds. A culture that sanctions irrationality and unfettered
venting of emotion is vulnerable to decline. Indeed, exploiting emotions while suppressing
reason is how demagogues gain and hold power, and how humanity's most horrific atrocities
have come to pass. In contrast, reason and better judgment are effective deterrents to incivility,
despotism, and war.
In sum, emotions can serve as important catalysts for academic accomplishment in the arts.
Otherwise, however, students, and ultimately society, are better off by learning to temper their
emotions while nurturing judgment, tolerance, fairness, and understandlng--all of which are
products of reason and critical thinking.
























Issue 44
"It is primarily through our identification with social groups that we define ourselves."
I strongly agree that we define ourselves primarily through our identification with social
groups, as the speaker asserts. Admittedly, at certain stages of life people often appear to
define themselves in other terms. Yet, in my view, during these stages the fundamental need to
define one's self through association with social groups is merely masked or suspended.
Any developmental psychologist would agree that socialization with other children plays a
critical role in any child's understanding and psychological development of self. At the day-care
center or in the kindergarten class young children quickly learn that they want to play with the
same toys at the same time or in the same way as some other children. They come to
understand generally what they share in common with certain of their peers---m terms of
appearance, behavior, likes and dislikes--and what they do not share in common with other
peers or with older students and adults. In other words, these children begin to recognize that
their identity inextricably involves their kinship with certain peers and alienation from other
people.
As children progress to the social world of the playground and other after-school venues,
their earlier recognition that they relate more closely to some people than to others evolves
into a desire to form well-defined social groups, and to set these groups apart from others.
Girls begin to congregate apart from boys; clubs and cliques are quickly formed--often with
exclusive rituals, codes, and rules to further distinguish the group's members from other
children. This apparent need to be a part of an exclusive group continues through high school,
where students identify themselves in their yearbooks by the clubs to which they belonged.
Even in college, students eagerly join clubs, fraternities, and sororities to establish their identity
as members of social groups. In my observation children are not taught by adults to behave in
these ways; thus this desire to identify oneself with an exclusive social group seems to spring
from some innate psychological need to define one's self through one's personal associations.
However, as young adults take on the responsibilities of partnering, parenting, and working,
they appear to define themselves less by their social affiliations and more by their marital
status, parental status, and occupation. The last of these criteria seems particularly important
for many adults today. When two adults meet for the first time, beyond initial pleasantries the
initial question almost invariably is "What do you do for a living?" Yet in my opinion this shift in
focus from one's belonging to a social group to one's occupation is not a shift in how we prefer
to define ourselves. Rather, it is born of economic necessity--we don't have the leisure time or
financial independence to concern ourselves with purely social activities. I find quite telling the
fact that when older people retire from the world of work an interest in identifying with social
groups--whether they be bridge clubs, investment clubs, or country clubs--seems to reemerge.
In short, humans seem possessed by an enduring need to be part of a distinct social group--a
need that continues throughout life's journey.
In sum, I agree that people gain and maintain their sense of self primarily through their
belonging to distinct social groups. Admittedly, there will always be loners who prefer not to
belong, for whatever reasons; yet loners are the exception. Also, while many working adults
might temporarily define themselves in terms of their work for practicality's sake, at bottom we
humans are nothing if not social animals.
























Issue 45
"Humanity has made little real progress over the past century or so. Technological innovations
have taken place, but the overall condition of humanity is no better. War, violence, and poverty
are still with us. Technology cannot change the condition of humanity."
Have technological innovations of the last century failed to bring about true progress for
humanity, as the statement contends? Although I agree that technology cannot ultimately
prevent us from harming one another, the statement fails to account for the significant positive
impact that the modem-industrial and computer revolutions have had on the quality of life at
least in the developed world.
I agree with the statement insofar as there is no technological solution to the enduring
problems of war, poverty, and violence, for the reason that they stem from certain aspects of
human nature--such as aggression and greed. Although future advances in biochemistry might
enable us to "engineer away" those undesirable aspects, in the meantime it is up to our
economists, diplomats, social reformers, and jurists--not our scientists and engineers--to
mitigate these problems.
Admittedly, many technological developments during the last century have helped reduce
human suffering. Consider, for instance, technology that enables computers to map Earth's
geographical features from outer space. This technology allows us to locate lands that can be
cultivated for feeding malnourished people in third-world countries. And, few would disagree
that humanity is the beneficiary of the myriad of 20th-Century innovations in medicine and
medical technology--from prostheses and organ transplants to vaccines and lasers.
Yet, for every technological innovation helping to reduce human suffering is another that has
served primarily to add to it. For example, while some might argue that nuclear weapons serve
as invaluable "peace-keepers," this argument flies in the face of the hundreds of thousands of
innocent people murdered and maimed by atomic blasts. More recently, the increasing use of
chemical weapons for human slaughter points out that socalled "advances" in biochemistry
can amount to net losses for humanity.
Notwithstanding technology's limitations in preventing war, poverty, and violence,
20th-Century technological innovation has enhanced the overall standard of living and comfort
level of developed nations. The advent of steel production and assembly-line manufacturing
created countless jobs, stimulated economic growth, and supplied a plethora of innovative
conveniences. More recently, computers have helped free up our time by performing repetitive
tasks; have aided in the design of safer and more attractive bridges, buildings, and vehicles;
and have made possible universal access to information.
Of course, such progress has not come without costs. One harmful byproduct of industrial
progress is environmental pollution, and its threat to public health. Another is the alienation of
assembly-line workers from their work. And, the Internet breeds information overload and
steals our time and attention away from family, community, and coworkers. Nevertheless, on
balance both the modern-industrial and computer revolutions have improved our standard of
living and comfort level; and both constitute progress by any measure.
In sum, enduring problems such as war, poverty, and violence ultimately spring from human
nature, which no technological innovation short of genetic engineering can alter. Thus the
statement is correct in this respect. However, ifwe define "progress" more narrowly--in terms of
economic standard of living and comfort level--recent technological innovations have indeed
brought about clear progress for humanity.
























Issue 46
"It is through the use of logic and of precise, careful measurement that we become aware of
our progress. Without such tools, we have no reference points to indicate how far we have
advanced or retreated."
Do we need careful measurements and logic to determine whether and to what extent we
are progressing or regressing? I agree that in certain endeavors quantitative measurements
and logical analysis of data are essential for this purpose. However, in other realms objective
data provides little guidance for determining progress. My view applies to individuals as well as
society as a whole.
As for monitoring individual progress, the extent to which careful measurement and logical
analysis of data are required depends on the specific endeavor. In the area of personal finance,
objective measurements are critical. We might feel that we are advancing financially when we
buy a new car or a better home, or when our salary increases. Yet these signs of personal
economic success can be deceptive. Cars depreciate quickly in value, and residential real
estate must appreciate steadily to offset ownership expenses. Even a pay raise is no sure sign
of personal financial progress; if the raise fails to keep pace with the cost of living then the real
salary is actually in decline.
In the area of one's physical well-being, however, quantitative measurement might be useful
yet insufficient. Quantitative data such as blood pressure, cholesterol level, and body weight
are useful objective indicators of physical health. Yet quantitative measurement and logic can
only take us so far when it comes to physical well-being. Levels of physical discomfort and
pain, the most reliable indicators of physical well-being, cannot be quantified. And of course
our emotional and psychological well-being, which can have a profound impact on our physical
health, defy objective measurement altogether.
On a societal level, as on a personal level, the extent to which careful measurement and
logic are needed to determine progress depends on the endeavor. In macro-economics, as in
personal finance, objective measurements are critical. For example, a municipality, state, or
nation might sense that things are improving economically when its rate of unemployment
declines. Yet if new jobs are in poor-paying positions involving unskilled labor, this apparent
advance might actually be a retreat. And, a boom in retail sales might amount to regress if the
goods sold are manufactured by foreign firms, who benefit from the boom at the expense of
domestic business expansion. Technological progress also requires careful measurement.
Advances is computer technology can only be determined by such factors as processing and
transfer speeds, numbers ofinstaUations and users, amounts of data accessed, and so forth.
And, advances in biotechnology are determined by statistical measurements of the
effectiveness of new drugs and other treatments, and by demographic statistics regarding the
incidence of the ailments that the technology seeks to ameliorate.
In contrast, socio-political progress is less susceptible to objective measurement. For
instance, progress in social welfare might be measured by the number of homeless people,
incidence of domestic violence, or juvenile crime rate. Yet would an increase in the number of
single mothers on welfare indicate that our society is becoming more compassionate and
effective in helping its victims, or would it indicate regress by showing that our private sector
and education systems are failing? Moreover, when it comes to our legal system and to politics,
progress has little to do with numbers, or even logic. For example, to what extent, if any, would
more lenient gun ownership laws indicate progress, considering the competing interests of
individual freedom and pubic safety? Do anti-abortion laws indicate a sociological advance or
retreat? Or, when a political party gains greater control of a legislature by sweeping a particular
election, is this progress or regress?
In sum, although the statement has merit, it unfairly generalizes. In areas such as finance,
economics, and computing technology, all of which involve nothing but quantifiable data,
nothing but careful measurement and logic suffice to determine the extent of progress. In other
areas, such as health care and social welfare, determining progress requires both objective
measurement and subjective judgment. Finally, progress in politics and law is an entirely
subjective matter--depending on each individual's values, priorities, and interests.
























Issue 47
"With the growth of global networks in such areas as economics and communication, there is
no doubt that every aspect of society---including education, politics, the arts, and the
sciences---will benefit greatly from international influences."
I agree that the globalization of economic and communication networks will heighten
international influences in all four of the areas listed. However, while those influences will no
doubt benefit education and the sciences, the nature of those influences on the arts and on
politics will probably be a mixed one beneficial in some respects yet detrimental in others.
The dearest and most immediate beneficiaries of international influences are students. When
students learn more about other cultures, systems of government, religions, and so forth, they
advance their knowledge and grow in their understanding of humanity--which is, after all, the
final objective of education. Emerging distance-learning technologies, made practicable now
by the Internet, will no doubt carry an especially profound international influence on education.
Distance learning will permit a class of students located all over the world to video-conference
simultaneously with a teacher and with one other, thereby enlivening and enriching
educational experiences.
The sciences dearly benefit from international influences as well. After all, prindples of
physics, chemistry, and mathematics know no political boundaries; thus a useful insight or
discovery can come from a researcher or theorist anywhere in the world. Accordingly, any
technology that enhances global communication can only serve to advance scientific
knowledge. For example, astronomers can now transmit observational data to other scientists
throughout the world the instant they receive that data, so that the entire global community of
astronomers can begin interpreting that data together in a global brain-storming session. The
sciences also benefit from multi-national economic cooperation. Consider, for instance, the
multi-national program to establish a human colony on the Moon. This ambitious project is
possible only because participating nations are pooling their economic resources as well as
scientific talents.
With respect to the arts, however, the speaker's claim is far less convincing. It might seem
that if artists broaden their cultural exposure and real-world experience their art works would
become richer and more diverse. However, the logical consequence of increasing international
influence on the arts is a homogenous global culture in which art becomes increasingly the
same. The end result is not only a chilling effect on artistic creativity, but also a loss of cultural
identity, which seems to be an important sociological and psychological need.
The impact of global networking on political relations might turn out to be a mixed one as
well. Consider, for instance, the current unification of Europe's various monetary systems.
Since Europe's countries are become economically interdependent, it would seem that it
would be in their best interests to cooperate politically with one another. However, discord over
monetary policy might result in member countries withdrawing from the Community, and in a
political schism or other falling out. Consider also the burgeoning global communications
network. On the one hand, it would seem that instant face-to-face communication between
diplomats and world leaders would help avert and quell political and military crises. By the
same token, however, global networking renders any nation's security system more vulnerable.
This point is aptly illustrated by a recent incident involving a high-ranking Pentagon official who
stored top-secret fries on his home computer, which was connected to the Internet without any
firewall precautions. Incidents such as this one might prompt the world's governments to
become more protective of their sovereignty, more insular, and even-paranoid.
In sum, growing international influences that result naturally from global communications
and economic networks can only serve to facilitate education and to advance scientific
knowledge. However, although the same influences no doubt will have an impact on the arts
and on international politics, the speaker's claim that those influences will be beneficial is
dubious, or at least premature, given that global networking is still in its nascent stages.
























Issue 48
"When research priorities are being set for science, education, or any other area, the most
important question to consider is: How many people's lives will be improved if the results are
successful?"
Should researchers focus on areas that are likely to result in the greatest benefit to the most
people, as the speaker suggests? I agree insofar as areas of research certain to result in
immediate and significant benefits for society should continue to be a priority. Yet, strictly
followed, the speaker's recommendation would have a harmful chilling effect on research and
new knowledge. This is particularly true in the physical sciences, as discussed below.
Admittedly, scientific research whose societal benefits are immediate, predictable, and
profound should continue to be a high priority. For example, biotechnology research is proven
to help cure and prevent diseases; advances in medical technology allow for safer, less
invasive diagnosis and treatment; advances in genetics help prevent birth defects; advances in
engineering and chemistry improve the structural integrity of our buildings, roads, bridges, and
vehicles; information technology enables education; and communication technology facilitates
global peace and participation in the democratic process. To demote any of these research
areas to a lower priority would be patently foolhardy, considering their proven benefits to so
many people. However, this is not to say that research whose benefits are less immediate or
clear should be given lower priority. For three reasons, all avenues of scientific research
should be afforded equal priority.
First of all, ifwe strictly follow the speaker's suggestion, who would decide which areas of
research are more worthwhile than others? Researchers cannot be left to decide. Given a
choice, they will pursue their own special areas of interest, and it is highly unlikely that all
researchers could reach a fully informed consensus as to what areas are most likely to help
the most people. Nor can these decisions be left to regulators and legislators, who would bring
to bear their own quirky notions about what is worthwhile, and whose susceptibility to
influence-peddlers renders them untrustworthy in any event.
A telling example of the inherent danger of setting "official" research priorities involves the
Soviet government's attempts during the 1920s to not only control the direction and the goals
of its scientists' research but also to distort the outcome of that research--ostensibly for the
greatest good of the greatest number of people. During the 1920s the Soviet government
quashed certain areas of scientific inquiry, destroyed entire research facilities and libraries,
and caused the sudden disappearance of many scientists who were viewed as threats the
state's authority. Not surprisingly, during this time period no significant scientific advances
occurred under the auspices of the Soviet government.
Secondly, to compel all researchers to focus only on certain areas would be to force many to
waste their true talents. For example, imagine relegating today's preeminent astrophysicist
Stephen Hawking to research the effectiveness of behavioral modification techniques in the
reform of violent criminals. Admittedly, this example borders on hyperbole. Yet the aggregate
effect of realistic cases would be to waste the intellectual talents of our world's researchers.
Moreover, lacking genuine interest or motivation a researcher would be unlikely to contribute
meaningfully to his or her "assigned" field.
Thirdly, it is difficult to predict which research avenues will ultimately lead to the greatest
contributions to society. Research areas whose benefits are certain often break little new
ground, and in the long term so-called "cutting-edge" research whose potential benefits are
unknown often prove most useful to society. One current example involves
terraforrning---creating biological life and a habitable atmosphere where none existed before.
This unusual research area does not immediately address society's pressing social problems.
Yet in the longer term it might be necessary to colonize other planets in order to ensure the
survival of the human race; and after all, what could be a more significant contribution to
society than preventing its extinction?
In sum, when it comes to setting priorities for research, at least in the sciences, the speaker
goes too far by implying that research whose benefits are unknown are not worth pursuing.
After all, any research worth doing delves into the unknown. In the final analysis, the only
objective of research should be to discover truths, whatever they might be-- not to implement
social policy.
























Issue 49
"So much is new and complex today that looking back for an understanding of the past
provides little guidance for living in the present."
The speaker claims that since so much in today's world is new and complex the past
provides little guidance for living in the present. I agree with this assertion insofar as history
offers few foolproof panaceas for living today. However, I disagree with the speaker's claim
that today's world is so unique that the past is irrelevant. One good example that supports my
dual position is the way society has dealt with its pressing social problems over time.
Admittedly, history has helped us learn the appropriateness of addressing certain social
issues, particularly moral ones, on a societal level. Attempts to legislate morality invariably fail,
as illustrated by Prohibition in the 1930s and, more recently, failed federal legislation to
regulate access to adult material via the Internet. We are slowly learning this lesson, as the
recent trend toward legalization of marijuana for medicinal purposes and the recognition of
equal rights for same-sex partners both demonstrate.
However, the only firm lesson from history about social ills is that they are here to stay.
Crime and violence, for example, have troubled almost every society. All manner of reform,
prevention, and punishment have been tried. Today, the trend appears to be away from reform
toward a "tough-on-crime" approach. Is this because history makes clear that punishment is
the most effective means of eliminating crime? No; rather, the trend merely reflects our current
mores, attitudes, and political climate.
Another example involves how we deal with the mentally-iii segment of the population.
History reveals that neither quarantine, treatment, nor accommodation solves the problem,
only that each approach comes with its own trade-offs. Also undermining the assertion that
history helps us to solve social problems is the fact that, despite the civil-fights efforts of Martin
Luther King and his progenies, the cultural gap today between African-Americans and white
Americans seems to be widening. It seems that racial prejudice is a timeless phenomenon.
To sum up, in terms of how to live together as a society I agree that studying the past is of
some value; for example, it helps us appreciate the futility of legislating morality. However,
history's primary sociological lesson seems to be that today's social problems are as old as
society itself, and that there are no panaceas or prescriptions for solving these problems---only
alternate ways of coping with them.


























Issue 50
"At various times in the geological past, many species have become extinct as a result of
natural, rather than human, processes. Thus, there is no justification for society to make
extraordinary efforts, especially at a great cost in money and jobs, to save endangered
species."
What are the limits of our duty to save endangered species from extinction? The statement
raises a variety of issues about morality, conscience, self-preservation, and economics. On
balance, however, I fundamentally agree with the notion that humans need not make
"extraordinary" efforts--at the expense of money and jobs--to ensure the preservation of any
endangered species.
As I see it, there are three fundamental arguments for imposing on ourselves at least some
responsibility to preserve endangered species. The first has to do culpability. According to this
argument, to the extent that endangerment is the result of anthropogenic events such as
dear-cutting of forests or polluting of lakes and streams, we humans have a duty to take
affirmative measures to protect the species whose survival we've placed in jeopardy.
The second argument has to do with capability. This argument disregards the extent to
which we humans might have contributed to the endangerment of a species. Instead, the
argument goes, if we are aware of the danger, know what steps are needed to prevent
extinction, and can take those steps, then we are morally obligated to help prevent extinction.
This argument would place a very high affirmative duty on humans to protect endangered
species.
The third argument is an appeal to self-preservation. The animal kingdom is an intricate
matrix of interdependent relationships, in which each species depends on many others for its
survival. Severing certain relationships, such as that between a predator and its natural prey,
can set into motion a series of extinctions that ultimately might endanger our own survival as a
species. While this claim might sound far-fetched to some, environmental experts assure us
that in the long run it is very real possibility.
On the other hand are two compelling arguments against placing a duty on humans to
protect endangered species. The first is essentially the Darwinian argument that extinction
results from the inexorable process of so-called natural selection in which stronger species
survive while weaker ones do not. Moreover, we humans are not exempt from the process.
Accordingly, if we see fit to eradicate other species in order to facilitate our survival, then so be
it. We are only behaving as animal must, Darwin would no doubt assert.
The second argument, and the one that I find most compelling, is an appeal to logic over
emotion. It is a scientific fact that thousands of animal species become extinct every year.
Many such extinctions are due to natural forces, while others are due to anthropogenic factors.
In any event, it is far beyond our ability to save them all. By what standard, then, should we
decide which species are worth saving and which ones are not? In my observation, we tend to
favor animals with human-like physical characteristics and behaviors. This preference is
understandable; after all, dolphins are far more endearing than bugs. But there is no logical
justification for such a standard. Accordingly, what makes more sense is to decide based on
our own economic self-interest. In other words, the more money and jobs it would cost to save
a certain species, the lower priority we should place on doing do.
In sum, the issue of endangered-species protection is a complex one, requiring subjective
judgments about moral duty and the comparative value of various life forms. Thus, there are
no easy or certain answers. Yet it is for this very reason I agree that economic self-interest
should take precedence over vague notions about moral duty when it comes to saving
endangered species. In the final analysis, at a point when it becomes critical for our own
survival as a species to save certain others, then we humans will do so if we are fit  in
accordance with Darwins observed process of natural selection.
























Issue 51
"Facts are stubborn things. They cannot be altered by our wishes, our inclinations, or the
dictates of our passions."
Can we alter facts according to our wishes or inclinations? If by "facts" the speaker means
such phenomena as political, economic, social, or legal status quo, then I concede that we can
alter facts. The reason for this is that such systems are abstract constructs of our inclinations,
wishes, and passions to begin with. Otherwise, I strongly agree with the speaker that we
cannot alter facts. When it comes to certain aspect of our personal lives, and to historical
events and scientific truths, no measure of desire or even passion can change external reality.
On an individual level, we all engage in futile attempts to alter facts--by pretending that
certain things are not the way they are because they are inconsistent with our wishes or
personal interests. Psychologists refer to this psychological defensive mechanism, which
seems to be part of human nature, as "denial." Consider curious pastimes such as
mind-reading, psychic healing, rituals that purportedly impart immortality, and other such
endeavors, which seems to transcend all cultures and periods of human history.
Understandably, we would all like to have the ability to alter the physical world, including
ourselves, as we see fit, or even to live forever by means of the sheer force of our will. Yet, not
one iota of scientific evidence lends support to the claim that any human being has ever had
any such ability.
Nor can we alter facts by virtue of our inclinations or passions when it comes to history.
Admittedly, no person can truly know any particular past that the person did not experience
firsthand. In this sense history is a construct, created for us by reporters, archivists, and
historians. Historical facts are therefore susceptible to interpretation, characterization, and of
course errors in commission and omission. This is not to say, however, that historical facts can
be altered by our inventing versions that suit our inclinations or wishes. In short, an historical
event is not rendered any less factual by either our ignorance or characterization of it.
Similarly, when it comes to science our wishes and desires ultimately yield to the
stubbornness of facts--by which I mean empirical scientific evidence and the laws and
principles of the physical world. Admittedly, in many cases it is difficult to distinguish between
scientific "fact" and mere "theory." History is replete with examples of what were considered at
one time to be facts, but later disproved as incorrect theories. Yet it is telling that many such
obsolete theories were based on the subjective inclinations, desires, and wishes of theorists
and of the societies in which the theorists lived. For example, the notions of an Earth-centered
tmiverse and of linear time and space were both influenced by religious notions--that is, by
human wishes and passions. As our factual knowledge increased such theories ultimately give
way.
In sum, I agree that facts are indeed "stubborn things." Understandably, all humans are
guilty of ignoring, overlooking, and misunderstanding facts--at least to some extent. After all,
human passion, desire, and individual bias and perspective are powerful influences when it
comes to what we believe to be true and factual. Moreover, the statement carries deep
epistemological implications regarding the nature of knowledge and truth, which I cannot begin
to adequately address here. Nevertheless, on a less abstract level the speaker is correct that
neither inclination, desire, nor passion, no matter how fervent, can alter that which is past or
beyond our physical control.
























Issue 52
"How children are socialized today determines the destiny of society. Unfortunately, we have
not yet learned how to raise children who can help bring about a better society."
I find the speaker's dual claim to be specious on both counts. The claim that society's
destiny hinges on how children are socialized, while appealing in some respects, is an
over-statement at best. And the claim that we have not yet learned how to raise children who
can better society is poorly supported by empirical evidence.
Consider first the speaker's assertion that society's destiny depends on how children are
socialized. I concede that unless a child is allowed sufficient opportunities for healthy
interaction with peers, that child is likely to grow into an ineffectual, perhaps even an anti-sodal,
adult. To witness healthy socialization in action, one need look no further than the school
playground, where children learn to negotiate, cooperate, and assert themselves in a
respectful manner, and where they learn about the harmful results of bullying and other
anti-social behavior. These lessons help children grow up to be good citizens and effective
leaders, as well as tolerant and respectful members of society.
However, socialization is only one factor influencing the extent to which an individual will
ultimately contribute to a better society. And in my observation it is not the most important one.
Consider certain prominent leaders who have contributed profoundly to a better society.
Mahatma Gandhi's contributions sprang primarily from the courage of his inner convictions, in
spite of his proper socialization among genteel Indian society and, as a law student, among
British society. Martin Luther King's contribution was primarily the result of his strong religious
upbringing, which had more to do with parental influence than with socialization. An even more
remarkable modern example was Theodore Roosevelt, whose social and physical
development were both stunted by life-threatening physical infirmities during his childhood. In
spite of his isolation, odd manner and aloofness throughout his early life, Roosevelt ascended
to a social-activist presidency by means of his will to overcome physical infLrmities, his
voracious appetite for knowledge, and his raw intellect.
Consider next the speaker's claim that we have not yet learned how to raise children who
can better society. Ifwe define a "better" society as one characterized by greater tolerance of
differing viewpoints and people who are different from ourselves, greater respect for individual
rights, and greater cooperation across cultural and national boundaries, then the children of
the most recent half-century are creating a better society. The most recent quarter-century has
seen an increasing sensitivity in our society toward ensuring public health by policing the food
and drug industries and by protecting our natural environment. We're becoming more sensitive
to, and respectful of, the rights of women, various ethnic and racial groups, homosexuals, and
mentally- and physically-challenged individuals. The re-emergence of political third parties with
decidedly libertarian ideals demonstrates an increasing concern for individual freedoms. And
there is ample evidence of increasing international cooperation. The former Soviet Union and
the U.S. have worked coUaboratively in space research and exploration since the 1970s;
peace-keeping missions are now largely multi-national efforts; and nations are now tackling
public health problems coUaboratively through joint research programs. In short, the speaker's
second claim flies in the face of the empirical evidence, as I see it.
In sum, when it comes to whether a child grows up to contribute to a better society, the key
determinant is not socialization but rather some other factor--such as a seminal childhood
event, parental influence, raw intelligence, or personal conviction. And, while reasonable
people with differing political and social viewpoints might disagree about what makes for a
"better" society, in my observation our society is steadily evolving into a more civilized,
respectful, and tolerant one. In the final analysis, then, I fundamentally disagree with both
aspects of the speaker's dual claim.
























Issue 53
"The arts (painting, music, literature, etc.) reveal the otherwise hidden ideas and impulses of a
society."
The speaker asserts that the arts reveal society's hidden ideas and impulses. While this
assertion has merit, I think it unfairly generalizes about art. Consider two particular art forms:
architecture and painting. In more important architecture one consistently sees a refection of
society's ideas and urges. However, in more important paintings of the most recent century
one sees instead the artists' personal and idiosyncratic visions of an aesthetic ideal.
Turning first to public architecture, one sees in ancient and Renaissance forms an impulse
to transcend the human condition. Clearly, the most important architecture of these periods
was built to honor deities and to propel humans into the afterlife. Consider, for example, the
ancient pyramids and the great cathedrals of Europe, which rise upward toward the stars and
heavens. During the Medieval period the most important architectural form was the castle,
which reflected an overriding concern for military security and brute strength during a time of
comparative anarchy. During the 20th Century it was first the steel-forged art deco forms and
then the sky-scraping office building that dominated public architecture. These forms reflect
modern, more mundane concerns for industrial and technological progress.
Turning next to important paintings and painters, it seems to me that the art of previous
centuries reflected the attitudes and ideas of the prevailing culture to a far greater extent than
today's art. The cynosures of the Medieval and Renaissance artists, for instance, were certain
Christian themes--the Trinity, virgin birth of Christ, the Resurrection, and so forth with which the
the society at large was also preoccupied. Later, during the 18 and 19th Centuries, an emerging
genteel class saw itself reflected in the bourgeois themes of impressionists such as Renoir and
Monet.
But in the most recent century the picture has been much different. Consider three of the
20th Century's most influential painters: Picasso, Dali and Pollock. Picasso's style underwent a
series of radical changes throughout his career. Was the reason for Picasso's diverse
"periods" a quick series of radical changes in society's ideas and impulses, or perhaps a
reflection of society's hidden impulse for constant change? Or did Picasso's varied styles
merely reflect the complex psychological profile of one eccentric artist? Dali is known for his
surrealistic images; but do these images reveal some kind of existential angst on a societal
level, or just the odd aesthetic vision of one man? Pollock's penchant was for dripping paint on
the floor in order to create abstract images that would have the sort of visceral impact he was
after. In fact, Pollock turned to this technique only after he tried but failed as a conventional
painter, using brush and easel. So are Pollock's striking abstract murals a reflection of some
mid-20th Century societal impulse, or merely the result of one struggling artist stumbling onto
something he was good at? In all three cases, it seems that the art reflected the artist but not
the society.
In sum, in the art of painting one can observe a shift from styles and themes reflecting broad
societal impulses to a more recent concern for expressing personal impulses and creative
urges. In contrast, the more public art form of architecture has always mirrored society's ideas
and impulses, and probably always will--because architecture is so much more public than the
art of painting.
























Issue 54
"The absence of choice is a circumstance that is very, very rare."
I strongly agree with the contention that absence of choice is a rare circumstance, primarily
because this contention accords with common sense and our everyday experience as human
beings. Besides, the reverse claim that we do not have free choice--serves to undermine the
notions of moral accountability and human equality, which are critical to the survival of any
democratic society.
Our collective life experience is that we make choices and decisions every day----on a
continual basis. Common sense dictates that humans have free will, and therefore the true
absence of choice is very rare. The only possible exceptions would involve extreme and rare
circumstances such as solitary imprisonment or a severe mental or physical deftciency--any of
which might potentially strip a person of his or her ability to make conscious choices. Yet even
under these circumstances, a person still retains choices about voluntary bodily functions and
movement. Thus the complete absence of choice would seem to be possible only in a
comatose state or in death.
People often claim that life's circumstances leave them with "no choice." One might feel
trapped in a job or a marriage. Under financial duress a person might claim that he or she has
"no choice" but to declare bankruptcy, take a demeaning job, or even lie or steal to obtain
money. The fundamental problem with these sorts of claims is that the claimants are only
considering those choices that are not viable or attractive. That is, people in situations such as
these have an infinite number of choices; it's just that many of the choices are unappealing,
even self-defeating. For example, almost every person who claims to be trapped in a job is
simply choosing to retain a certain measure of financial security. The choice to forego this
security is always available, although it might carry unpleasant consequences.
Besides, the contention that we are almost invariably free to choose is far more appealing
from a socio-political standpoint than the opposite claim. A complete lack of choice implies that
every person's fate is determined, and that we all lack free will. According to the philosophical
school of "strict determinism," every event, induding human actions and choices, that occurs is
physically necessary given the laws of nature and events that preceded that event or choice.
In other words, the "choices" that seem part of the essence of our being are actually beyond
our control. Recent advances in molecular biology and genetics lend some credence to the
determinists' position that as physical beings our actions are determined by physical forces
beyond our control. New research suggests that these physical forces include our own
individual genetic makeup.
However, the logical result of strict determinism and of the new "scientific determinism" is
that we are not morally accountable for our actions and choices, even those that harm other
individuals or society. Moreover, throughout history monarchs and dictators have embraced
determinism, at least ostensibly, to bolster their claim that certain individuals are preordained
to assume positions of authority or to rise to the top levels of the socioeconomic infrastructure.
Finally, the notion of scientific determinism opens the door for genetic engineering, which
poses a potential threat to equality in socioeconomic opportunity, and could lead to the
development of a so-caUed "master race." Admittedly, these disturbing implications neither
prove nor disprove the determinists' claims. Nevertheless, assuming that neither free will nor
determinism has been proven to be the correct position, the former is to be preferred by any
humanist and in any democratic society.
In sum, despite the fact that we all experience occasional feelings of being trapped and
having no choice, the statement is fundamentally correct. I would concede that science might
eventually disprove the very notion of free will. However, until that time I'll trust my strong
intuition that free will is an essential part of our being as humans and, accordingly, that humans
are responsible for their own choices and actions.
























Issue 55
"Only through mistakes can there be discovery or progress."
The speaker contends that discovery and progress are made only through mistakes. I
strongly agree with this contention, for two reasons. First, it accords with our personal
experiences. Secondly, history informs us that on a societal level trial-and-error provides the
very foundation for discovery and true progress, in all realms of human endeavor.
To begin with, the contention accords with our everyday experience as humans from early
childhood through adulthood. As infants we learn how to walk by falling down again and again.
As adolescents we discover our social niche, and develop self-confidence and assertiveness,
only by way of the sorts of awkward social encounters that are part-and-parcel of adolescence.
Through failed relationships not only do we discover who we are and are not compatible with,
we also discover ourselves in the process. And, most of us find the career path that suits us
only through trying jobs that don't.
This same principle also applies on a societal level. Consider, for example, how we progress
in our scientific knowledge. Our scientific method is essentially a call for progress through
trial-and-error. Any new theory must be tested by empirical observation, and must withstand
rigorous scientific scrutiny. Moreover, the history of theoretical science is essentially a history
of trial-and-error. One modern example involves two contrary theories of physics: wave theory
and quantum theory. During the last quarter-century scientists have been struggling to
disprove one or the other--or to reconcile them. As it turns out, a new so-called "string" theory
shows that the quantum and wave theories are mistakes in the sense that each one is
inadequate to explain the behavior of all matter; yet both so-called "mistakes" were necessary
for physics to advance, or progress, to this newer theory.
The value of trial-and-error is not limited to the sciences. In government and politics,
progress usually comes about through dissension and challenge--that is, when people point
out the mistakes of those in power. In fact, without our challenging the mistaken notions of
established institutions, political oppression and tyranny would go unchecked. Similarly, in the
fields of civil and criminal law, jurists and legislators who uphold and defend legal precedent
must face continual opposition from those who question the fairness and relevance of current
laws. This ongoing challenge is critical to the vitality and relevance of our system of laws.
In sum, the speaker correctly asserts that it is through mistakes that discovery and true
progress are made. Indeed, our personal growth as individuals, as well as advances in science,
government, and law, depends on making mistakes.
























Issue 56
"What society has thought to be its greatest social, political, and individual achievements have
often resulted in the greatest discontent."
I strongly agree that great achievements often lead to great discontent. In fact, I would
assert more specifically that great individual achievements can cause discontent for the
individual achiever or for the society impacted by the achievement, or both. Neverthe- less, it is
important to acknowledge that whether a great achievement causes great dis- content can
depend on one's personal perspective, as well as the perspective of time.
With respect to individual achievements, great achievers are by nature ambitious people
and therefore tend to be dissatisfied and discontent with their accomplishmentsno matter
how great. Great athletes are compelled to try to better their record-breaking per- formances;
great artists and musicians typically daim that their greatest work will be their next one--a sign
of personal discontent. And many child prot6g6s, especially those who achieve some measure
of fame early in life, later suffer psychological discontent for having "peaked" so early. Perhaps
the paradigmatic modern example of a great achiever's discontent was Einstein, whose
theoretical breakthroughs in physics only raised new theoretical conundrums which Einstein
himself recognized and spent the last twenty years of his life struggling unsuccessfully to
solve.
Individual achievements can often result in discontent on a societal level. The great
achievement of the individual scientists responsible for the success of the Manhattan Project
resulted in worldwide anxiety over the threat of nuclear annihilation--a form of discontent with
which the world's denizens will forever be forced to cope. Even individual achievements that at
first glance would appear to have benefited society turn out to be causes of great discontent.
Consider the invention of the automobile, along with the innovations in manufacturing
processes and materials that made mass production possible. As a result we have become a
society enslaved to our cars, relying on them as crutches not only for transportation but also
for affording us a false sense of socioeconomic status. Moreover, the development of
assembly-line manufacturing has served to alienate workers from their work, which many
psychologists agree causes a great deal of personal discontent.
Turning from individual achievements to societal, induding political, achievements, the
extent to which great achievements have caused great discontent often depends on one's
perspective. Consider, for example, America's spirit of Manifest Destiny during the 19th
Century, or British Imperialism over the span of several centuries. From the perspective of an
Imperialist, conquering other lands and peoples might be viewed as an unqualified success.
However, from the viewpoint of the indigenous peoples who suffer at the hands of Imperialists,
these so-called "achievements" are the source of widespread oppression and misery, and in
turn discontent, to which any observant Native American or South African native could attest.
The extent to which great socio-political achievements have caused great discontent also
depends on the perspective of time. For example, F.D.R.'s New Deal was and still is
considered by many to be one of the greatest social achievements of the 20th Century.
However, we are just now beginning to realize that the social-security system that was an
integral part of F.D.R.'s social program will soon result in great discontent among those
workers currently paying into the system but unlikely to see any benefits after they retire.
To sum up, I agree that great achievements, both individual and socio-political, often result
in great discontent. Moreover, great individual achievements can result in discontent for both
the individual achiever and the society impacted by the achievement. Nevertheless, in
measuring the extent of discontent, we must account for varying personal and political
perspectives as well as different time perspectives.
























Issue 57
"Contemporary art (painting, music, literature, etc.) is absent from the lives of most people,
since it is primarily created only for the enjoyment of other artists. Art should instead be
created purely for popular understanding and appreciation."
This statement asserts that art, not the art critic, provides something of lasting value to
society. I strongly agree with the statement. Although the critic can help us understand and
appreciate art, more often than not, critique is either counterproductive to achieving the
objective of art or altogether irrelevant to that objective.
To support the statement the speaker might point out the three ostensible functions of the art
critic. First, critics can help us understand and interpret art; a critic who is familiar with a
particular artist and his or her works might have certain insights about those works that the
layperson would not. Secondly, a critic's evaluation of an art work serves as a filter, which
helps us determine which art is worth our time and attention. For example, a new novel by a
best-selling author might nevertheless be an uninspired effort, and if the critic can call our
attention to this fact we gain time to seek out more worthwhile literature to read. Thirdly, a critic
can provide feedback for artists; and constructive criticism, if taken to heart, can result in better
work.
However, reflecting on these three functions makes clear that the art critic actually offers
very little to society. The first function is better accomplished by docents and teachers, who are
more able to enhance a layperson's appreciation and understanding of art by providing an
objective, educated interpretation of it. Besides, true appreciation of art occurs at the moment
we encounter art; it is the emotional, even visceral impact that art has on our senses, spirits,
and souls that is the real value of art. A critic can actually provide a disservice by distracting us
from that experience.
The critic's second function that of evaluator who filters out bad art from the worthwhile is
one that we must be very wary of. History supports this caution. In the role of judge, critics
have failed us repeatedly. Consider, for example, Voltaire's rejection of Shakespeare as
barbaric because he did not conform to neo-classical principles of unity. Or, consider the
complete dismissal of Beethoven's music by the esteemed critics of his 6me. The art critic's
judgment is limited by the narrow confines of old and established parameters for evaluation.
Moreover, critical judgment is often misguided by the ego; thus its value is questionable in any
event.
I turn finally to the critic's third function: to provide useful feedback to artists. The value of
this function is especiaUy suspect. Any artist, or anyone who has studied art, would agree that
true art is the product of the artist's authentic passion, a manifestation of the artist's unique
creative impulse, and a creation of the artist's spirit. If art were shaped by the concern for
integrating feedback from ali criticism, it would become a viable craft, but at the same time
would cease to be art.
In sum, none of the ostensible functions of the critic are of much value at all, let alone of
lasting value, to society. On the other hand, the artist, through works of art, provides an
invaluable and unique mirror of the culture of the time during which the work was produced a
mirror for the artist's contemporaries and for future generations to gaze into for insight and
appreciation of history. The art critic in a subordinate role, more often than not, does a
disservice to society by obscuring this mirror.
























Issue 58
"Most people recognize the benefits of individuality, but the fact is that personal economic
success requires conformity."
Personal economic success might be due either to one's investment strategy or to one's
work or career. With respect to the former, non-conformists with enough risk tolerance and
patience invariably achieve more success than conformists. With respect to the latter, while
non-conformists are more likely to succeed in newer industries where markets and technology
are in constant flux, conformists are more likely to succeed in traditional service industries
ensconced in systems and regulations.
Regarding the sort of economic success that results from investing one's wealth, the
principles of investing dictate that those who seek risky investments in areas that are out of
favor with the majority of investors ultimately reap higher returns than those who follow the
crowd. It is conformists who invest, along with most other investors, in areas that are currently
the most profitable, and popular. However, popular investments tend to be overpriced, and in
the long run their values will come down to reasonable levels. As a result, given enough time
conformists tend to reap lower rewards from their investments than nonconformists do.
Turning to the sort of economic success that one achieves by way of one's work, neither
conformists nor non-conformists necessarily achieve greater success than the other group. In
consumer-driven industries, where innovation, product differentiation and creativity are crucial
to lasting success, non-conformists who take unique approaches tend to recognize emerging
trends and to rise above their peers. For example, Ted Tumer's departure from the traditional
format of the other television networks, and the responsiveness of Amazon's Jeff Bezos to
burgeoning Internet commerce, propelled these two non-conformists into leadership positions
in their industries. Particularly in technology industries, where there are no conventional
practices or ways of thinking to begin with, people who cling to last year's paradigm, or to the
status quo in general, are soon left behind by coworkers and competing firms.
However, in traditional service industries--such as fnance, accounting, insurance, legal
services, and health care--personal economic success comes not to non-conformists but
rather to those who can work most effectively within the constraints of established practices,
policies and regulations. Of course, a clever idea for structuring a deal, or a creative legal
maneuver, might play a role in winning smaller battles along the way. But such tac-tics are
those of conformists who are playing by the same ground rules as their peers; winners are just
better at the game.
In conclusion, non-conformists with sufficient risk tolerance and patience are invariably the
most successful investors in the long run. When it comes to careers, however, while
non-conformists tend to be more successful in technology- and consumer-driven industries,
traditionalists are the winners in system-driven industries pervaded by policy, regulation, and
bureaucracy.
























Issue 59
"The well-being of a society is enhanced when many of its people question authority."
The speaker asserts that when many people question authority society is better off. While I
contend that certain forms of disobedience can be harmful to any society, I agree with the
speaker otherwise. In fact, I would go further by contending that society's well-being depends
on challenges to authority, and that when it comes to political and legal authority, these
challenges must come from many people.
Admittedly, when many people question authority some societal harm might result, even if a
social cause is worthy. Mass resistance to authority can escalate to violent protest and rioting,
during which innocent people are hurt and their property damaged and destroyed. The fallout
from the 1992 Los Angeles riots aptly illustrates this point. The "authority" which the rioters
sought to challenge was that of the legal justice system which acquitted police officers in the
beating of Rodney King. The means of challenging that authority amounted to flagrant
disregard for criminal law on a mass scale--by way of looting, arson, and even deadly assault.
This violent challenge to authority resulted in a financially crippled community and, more
broadly, a turning back of the clock with respect to racial tensions across America.
While violence is rarely justifiable as a means of questioning authority, peaceful challenges
to political and legal authority, by many people, are not only justifiable but actually necessary
when it comes to enhancing and even preserving society's well-being. In particular, progress in
human rights depends on popular dissension. It is not enough for a charismatic visionary like
Gandhi or King to call for change in the name of justice and humanity; they must have the
support of many people in order to effect change. Similarly, in a democracy citizens must
respect timeless legal doctrines and principles, yet at the same time question the fairness and
relevance of current laws. Otherwise, our laws would not evolve to reflect changing societal
values. It is not enough for a handful of legislators to challenge the legal status quo; ultimately
it is up to the electorate at large to call for change when change is needed for the well-being of
society.
Questioning authority is also essential for advances in the sciences. Passive acceptance of
prevailing principles quells innovation, invention, and discovery, all of which clearly benefit any
society. In fact, the very notion of scientific progress is predicated on rigorous scientific
inquiry--in other words, questioning of authority. History is replete with scientific discoveries
that posed challenges to political, religious, and scientific authority. For example, the theories
of a sun-centered solar system, of humankind's evolution from other life forms, and of the
rdativity of time and space, clearly flew in the face of "authoritative" scientific as well as
religious doctrine of their time. Moreover, when it comes to science a successful challenge to
authority need not come from a large number of people. The key contributions of a few
individuals---like Copernicus, Kepler, Newton, Darwin, Einstein, and Hawking---often suffice.
Similarly, in the arts, people must challenge established styles and forms rather than imitate
them; otherwise, no gemtinely new art would ever emerge, and society would be worse off.
And again, it is not necessary that a large number of people pose such challenges; a few key
individuals can have a profound impact. For instance, modern ballet owes much of what is new
and exciting to George Ballanchine, who by way of his improvisational techniques posed a
successful challenge to established traditions. And modern architecture arguably owes its
existence to the founders of Germany's Bauhaus School of Architecture, which challenged
certain "authoritative" notions about the proper objective, and resulting design, of public
buildings.
To sum up, in general I agree that when many people question authority the well-being of
society is enhanced. Indeed, advances in government and law depend on challenges to the
status quo by many people. Nevertheless, to ensure a net benefit rather than harm, the means
of such challenges must be peaceful ones.
























Issue 60
"It is the artist, not the critic,* who gives society something of lasting value."
*a person who evaluates works of art, such as novels, films, music, paintings, etc.
This statement asserts that art, not the art critic, provides something of lasting value to
society. I strongly agree with the statement. Although the critic can help us understand and
appreciate art, more often than not, critique is either counterproductive to achieving the
objective of art or altogether irrelevant to that objective.
To support the statement the speaker might point out the three ostensible functions of the art
critic. First, critics can help us understand and interpret art; a critic who is familiar with a
particular artist and his or her works might have certain insights about those works that the
layperson would not. Secondly, a critic's evaluation of an art work serves as a filter, which
helps us determine which art is worth our time and attention. For example, a new novel by a
best-selling author might nevertheless be an uninspired effort, and if the critic can call our
attention to this fact we gain time to seek out more worthwhile literature to read. Thirdly, a critic
can provide feedback for artists; and constructive criticism, if taken to heart, can result in better
work.
However, reflecting on these three functions makes clear that the art critic actually offers
very little to society. The first function is better accomplished by docents and teachers, who are
more able to enhance a layperson's appreciation and understanding of art by providing an
objective, educated interpretation of it. Besides, true appreciation of art occurs at the moment
we encounter art; it is the emotional, even visceral impact that art has on our senses, spirits,
and souls that is the real value of art. A critic can actually provide a disservice by distracting us
from that experience.
The critic's second function that of evaluator who filters out bad art from the worthwhile is
one that we must be very wary of. History supports this caution. In the role of judge, critics
have failed us repeatedly. Consider, for example, Voltaire's rejection of Shakespeare as
barbaric because he did not conform to neo-classical principles of unity. Or, consider the
complete dismissal of Beethoven's music by the esteemed critics of his 6me. The art critic's
judgment is limited by the narrow confines of old and established parameters for evaluation.
Moreover, critical judgment is often misguided by the ego; thus its value is questionable in any
event.
I turn finally to the critic's third function: to provide useful feedback to artists. The value of
this function is especiaUy suspect. Any artist, or anyone who has studied art, would agree that
true art is the product of the artist's authentic passion, a manifestation of the artist's unique
creative impulse, and a creation of the artist's spirit. If art were shaped by the concern for
integrating feedback from ali criticism, it would become a viable craft, but at the same time
would cease to be art.
In sum, none of the ostensible functions of the critic are of much value at all, let alone of
lasting value, to society. On the other hand, the artist, through works of art, provides an
invaluable and unique mirror of the culture of the time during which the work was produced a
mirror for the artist's contemporaries and for future generations to gaze into for insight and
appreciation of history. The art critic in a subordinate role, more often than not, does a
disservice to society by obscuring this mirror.
























Issue 61
"People who are the most deeply committed to an idea or policy are the most critical of it."
The speaker claims that people who are the most fmnly committed to an idea or policy are
the same people who are most critical of that idea or policy. While I find this claim paradoxical
on its face, the paradox is explainable, and the explanation is well supported empirically.
Nevertheless, the claim is an unfair generalization in that it fails to account for other empirical
evidence serving to discredit it.
A threshold problem with the speaker's claim is that its internal logic is questionable. At first
impression it would seem that firm commitment to an idea or policy necessarily requires the
utmost confidence in it, and yet one cannot have a great deal of confidence in an idea or policy
if one recognizes its flaws, drawbacks, or other problems. Thus commitment and criticism
would seem to be mutually exclusive. But are they? One possible explanation for the paradox
is that individuals most fmnly committed to an idea or policy are often the same people who
are most knowledgeable on the subject, and therefore are in the best position to understand
and appreciate the problems with the idea or policy.
Lending credence to this explanation for the paradoxical nature of the speaker's claim are
the many historical cases of uneasy marriages between commitment to and criticism of the
same idea or policy. For example, Edward Teller, the so-called "father of the atom bomb," was
firmly committed to America's policy of gaining military superiority over the Japanese and the
Germans; yet at the same time he attempted fervently to dissuade the U.S. military from
employing his technology for destruction, while becoming the most visible advocate for various
peaceful and productive applications of atomic energy. Another example is George
Washington, who was quoted as saying that all the world's denizens "should abhor war
wherever they may find it." Yet this was the same military general who played a key role in the
Revolutionary War between Britain and the States. A third example was Einstein, who while
committed to the mathematical soundness of his theories about relativity could not reconcile
them with the equally compelling quantum theory which emerged later in Einstein's life. In fact,
Einstein spent the last twenty years of his life criticizing his own theories and struggling to
determine how to reconcile them with newer theories.
In the face of historical examples supporting the speaker's claim are innumerable influential
individuals who were zealously committed to certain ideas and policies but who were not
critical of them, at least not outwardly. Could anyone honestly claim, for instance, that
Elizabeth Stanton and Susan B. Anthony, who in the late 19th Century paved the way for the
women's rights movement by way of their fervent advocacy, were at the same time highly
critical or suspicious of the notion that women deserve equal rights under the law? Also, would
it not be absurd to claim that Mahatma Gandhi and Martin Luther King, history's two leading
advocates of civil disobedience as a means to social reform, had serious doubts about the
ideals to which they were so demonstrably committed? Finally, consider the two ideologues
and revolutionaries Lenin and Mussolini. Is it even plausible that their demonstrated
commitment to their own Communist and Fascist policies, respectively, belied some deep
personal suspicion about the merits of these policies? To my knowledge no private writing of
any of these historical figures lends any support to the claim that these leaders were
particularly critical of their own ideas or policies.
To sum up, while at first glance a deep commitment to and incisive criticism of the same idea
or policy would seem mutually exclusive, it appears they are not. Thus the speaker's claim has
some merit. Nevertheless, for every historical case supporting the speaker's claim are many
others serving to refute it. In the final analysis, then, the correctness of the speaker's assertion
must be determined on a case-by-case basis.
























Issue 62
"Tradition and modernization are incompatible. One must choose between them."
Must we choose between tradition and modernization, as the speaker contends.; I agree
that in certain cases the two are mutually exclusive. For the most part, however, modernization
does not reject tradition; in fact, in many cases the former can and does embrace the latter.
In the first place, oftentimes so-caUed "modernization" is actually an extension or new
iteration of tradition, or a variation on it. This is especially true in language and in law. The
modern English language, in spite of its many words that are unique to modern Western
culture, is derived from, and builds upon, a variety of linguistic traditions--and ultimately from
the ancient Greek and Latin languages. Were we to insist on rejecting traditional in favor of
purely modern language, we would have essentially nothing to say. Perhaps an even more
striking marriage of modernization and tradition is our system of laws in the U.S., which is
deeply rooted in English common-law principles of equity and justice. Our system requires that
new, so-called "modern" laws be consistent with, and in fact build upon, those principles.
In other areas modernization departs from tradition in some respects, while embracing it in
others. In the visual arts, for example, "modern" designs, forms, and elements are based on
certain timeless aesthetic ideals--such as symmetry, balance, and harmony. Modern art that
violates these principles might hold ephemeral appeal due to its novelty and brashness, but its
appeal lacks staying power. An even better example from the arts is modern rock-and-roll
music, which upon first listening might seem to bear no resemblance to classical music
traditions. Yet, both genres rely on the same twelve-note scale, the same notions of what
harmonies are pleasing to the ear, the same forms, the same rhythmic meters, and even many
of the same melodies.
I concede that, in certain instances, tradition must yield entirely to the utilitarian needs of
modern life. This is true especially when it comes to architectural traditions and the value of
historic and archeological artifacts. A building of great historic value might be located in the
only place available to a hospital desperately needing additional parking area. An old school
that is a prime example of a certain architectural style might be so structurally unsafe that the
only practicable way to remedy the problem would be to raze the building to make way for a
modern, structurally sound one. And when it comes to bridges whose structural integrity is
paramount to public safety, modernization often requires no less than replacement of the
bridge altogether. However, in other such cases architecturally appropriate retrofits can solve
structural problems without sacrificing history and tradition, and alternative locations for new
buildings and bridges can be found in order to preserve tradition associated with our historic
structures. Thus, even in architecture, tradition and modernization are not necessarily mutually
exclusive options.
To sum up, in no area of human endeavor need modernization supplant, reject, or otherwise
exclude tradition. In fact, in our modern structures, architecture and other art, and especially
languages and law, tradition is embraced, not shunned.
























Issue 63
"Because of television and worldwide computer connections, people can now become familiar
with a great many places that they have never visited. As a result, tourism will soon become
obsolete."
The speaker asserts that television and computer connectivity will soon render tourism
obsolete. I agree that these technologies might eventually serve to reduce travel for certain
purposes other than tourism. However, I strongly disagree that tourism will become obsolete,
or that it will even decline, as a result.
As for the claim that television will render tourism obsolete, we already have sufficient
empirical evidence that this will simply not happen. For nearly a half-century we have been
peering through our television sets at other countries and cultures; yet tourism is as popular
today as ever. In fact, tourism has been increasing sharply during the last decade, which has
seen the advent of television channels catering exclusively to our interest in other cultures and
countries. The more reasonable conclusion is that television has actually served to spark our
interest in visiting other places.
It is somewhat more tempting to accept the speaker's further claim that computer
connectivity will render tourism obsolete. However, the speaker unfairly assumes that the
purpose of tourism is simply to obtain information about other people and places. Were this the
case, I would entirely agree that the current information explosion spells the demise of tourism.
But, tourism is not primarily about gathering information. Instead, it is about sensory
experience--seeing and heating firsthand, even touching and smelling. Could anyone honestly
claim that seeing a picture or even an enhanced 3-D movie of the Swiss Alps serves as a
suitable substitute for riding a touting motorcycle along narrow roads traversing those
mountains? Surely not. The physical world is laden with a host of such delights that we
humans are compelled to experience firsthand as tourists.
Moreover, in my view tourism will continue to thrive for the same reason that people still go
out for dinner or to the movies: we all need to "get away" from our familiar routines and
surroundings from time to 6me. Will computer connectivity alter this basic need? Certainly not.
In short, tourism is a manifestation of a basic human need for variety and for exploration. This
basic need is why humans have come to inhabit every corner of the Earth, and will just as
surely inhabit other planets of the solar system.
In fact, computer connectivity might actually provide a boon for tourism. The costs of travel
and accommodations are likely to decrease due to Internet price competition. Even more
significantly, to the extent that the Internet enhances communication among the world's
denizens, our level of comfort and trust when it comes to dealing with people from other
cultures will only increase. As a result, many people who previously would not have felt safe or
secure traveling to strange lands will soon venture abroad with a new sense of confidence.
Admittedly, travel for purposes other than tourism might eventually decline, as the business
world becomes increasingly dependent on the Internet. Products that can be reduced to digital
"bits and bites" can now be shipped anywhere in the world without any human travel. And the
volume of business-related trips will surely decline in the future, as teleconferencing becomes
more readily available. To the extent that business travelers "play tourist" during business trips,
tourism will decline as a result. Yet it would be absurd to claim that these phenomena alone will
render tourism obsolete.
In sum, while business travel might decline as a result of global connectivity, tourism is likely
to increase as a result. Global connectivity, especially the Internet, can only pique our curiosity
about other peoples, cultures, and places. Tourism helps satisfy that curiosity, as well as
satisfying a fundamental human need to experience new things first-hand and to explore the
world.
























Issue 64
"High-speed electronic communications media, such as electronic mail and television, tend to
prevent meaningful and thoughtful communication."
Do high-speed means of communication, particularly television and computers, tend to
prevent meaningful and thoughtful communication, as the speaker suggests? Although ample
empirical evidence suggests so with respect to television, the answer is far less dear when it
comes to communication via computers.
Few would argue that since its inception broadcast television has greatly enhanced
communication to the masses. The circulation of even the most widely read newspapers pales
compared to the number of viewers of popular television news programs. Yet traditional
television is a one-way communications medium, affording viewers no opportunity to engage
those so-called "talking heads" in dialogue or respond. Of course, there is nothing inherent
about television that prevents us from meaningful and thoughtful communication with each
other. In fact, in television's early days it was a fairly common occurrence for a family to gather
around the television together for their favorite show, then afterwards discuss among
themselves what they had seen and heard. Yet over time television has proven itself to serve
primarily as a baby-sitter for busy parents, and as an means of escape for those who wish to
avoid communicating with the people around them. Moreover, in the pursuit of profit, network
executives have determined over time that the most effective uses of the medium are for
fast-paced entertainment and advertising--whose messages are neither thoughtful nor
meaningful.
Do computers offer greater promise for thoughtful and reflective communication than
television? Emphatically, yes. After all, media such as email and the Web are interactive by
design. And the opportunity for two-way communication enhances the chances of meaningful
and thoughtful communication. Yet their potential begs the question: Do these media in fact
serve those ends? It is tempting to hasten that the answer is "yes" with respect to email; after
are, we've all heard stories about how email has facilitated reunions of families and old friends,
and new long-distance friendships and romances. Moreover, it would seem that two-way
written communication requires far more thought and reflection than verbal conversation.
Nevertheless, email is often used to avoid face-to-face encounters, and in practice is used as
a means of distributing quick memos. Thus on balance it appears that email serves as an
impediment, not an aide, to thoughtful and reflective communication.
With respect to Web-based communication, the myriad of educational sites, interactive and
otherwise, is strong evidence that the Web tends to enhance, rather than prevent, meaningful
communication. Distance learning courses made possible by the Web lend further credence to
this assertion. Nonetheless, by all accounts it appears that the Web will ultimately devolve into
a mass medium for entertainment and for e-commerce, just like traditional television.
Meaningful personal interactivity is already yielding to advertising, requests for product
information, buy-seU orders, and titillating adult-oriented content.
Thus, on balance these high-speed electronic media do indeed tend to prevent rather than
facilitate meaningful and thoughtful communication. In the final analysis, any mass medium
carries the potential for uplifting us, enlightening us, and helping us to communicate with and
understand one another. However, by all accounts, television has not fulfilled that potential;
and whether the Web will serve us any better is ultimately up to us as a society.
























Issue 65
"No amount of information can eliminate prejudice because prejudice is rooted in emotion, not
reason."
The speaker actually raises two distinct issues here: (1) whether information can eliminate,
or at least help reduce, prejudice; and (2) if not, whether this is because prejudice is rooted in
emotion rather than reason. Despite the evidence to the contrary, I fundamentally agree with
the speaker's essential claim that prejudice is here to stay because it is firmly rooted in
emotion rather than reason.
Regarding the first issue, it would appear at first glance that prejudice is declining as a result
of our becoming a more enlightened, or better informed, society. During the past
quarter-decade, more so than any other period in human history, various voices of reason
have been informing us that racial, sexual, and other forms of prejudice are unfounded in
reason, morally wrong, and harmful to any society. During the 1960s and 1970s such
information came from civil-rights and feminist activists; more recently the primary source of
this information has been mainstream media, which now affirmatively touts the rights of
various racial groups, women, and homosexuals. Moreover, increasing mobility and cultural
awareness surely serve to inform people the world over that we are all essentially alike.
It would seem that, as a result of this flood of information, we would be making clear
progress toward eliminating prejudice. However, much of this so-called progress is forced
upon us legislatively--in the form of anti-discrimination laws in the areas of employment,
housing, and education, which now protect all significant minority groups. Without these laws,
would we voluntarily refrain from the discriminatory behavior and other forms of prejudice that
the laws prevent? Perhaps not.
Moreover, signs of prejudice are all around us today. Extreme factions still rally around
bigoted demagogues; the number of "hate crimes" is increasing alarmingly; and the cultural
gap between white Americans and African-Americans seems to be widening as the level of
mutual distrust heightens. Besides, what appears to be respect for one another's differences
may in fact be an increasing global homogeneity--that is, we are becoming more and more
alike. In short, on a societal level an apparent decline of prejudice is actually legislated morality
and increasing homogeneity. Accordingly, I find the speaker's threshold assertion--that no
amount of information can eliminate prejudice-- compelling indeed.
The second issue that the statement raises is whether prejudice is learned or instinctive. If it
were learned, then it would seem that by obtaining certain information, or by purging one's
mind of certain dis-information, one could learn to not be prejudiced. Despite popular notions
that this is possible, I have my doubts because these are age-old theories but we see little
evidence that prejudice is on the wane. Thus it seems that the root of prejudice lies more in an
instinctive, almost primal, sense of fear than in the sort of distrust that is learned and can
therefore be "unlearned." Accordingly, I also find the speaker's second assertion--that
prejudice is rooted in emotion---compelling as well.
In sum, despite a deluge of information debunking our false notions about people who are
different than us, as a society it appears we have not reversed our inclination toward prejudice.
Therefore, I find convincing the speaker's claim that prejudice is rooted in the sort of emotion
that reason cannot override.


























Issue 66
"The only responsibility of corporate executives, provided they stay within the law, is to make
as much money as possible for their companies."
Should the only responsibility of a business executive be to maximize business profits, within
the bounds of the law? In several respects this position has considerable merit; yet it ignores
certain compelling arguments for imposing on businesses additional obligations to the society
in which they operate.
On the one hand are two convincing arguments that profit maximization within the bounds of
the law should be a business executive's sole responsibility. First, imposing on businesses
additional duties to the society in which they operate can, paradoxically, harm that society.
Compliance with higher ethical standards than the law requires--m such areas as
environmental impact and workplace conditions--adds to business expenses and lowers
immediate profits. In turn, lower profits can prevent the socially conscious business from
creating more jobs, and from keeping its prices low and the quality of its products and services
high. Thus ifbusinesses go further than their legal duties in serving their communities the end
result might be a net disservice to those communities.
Secondly, by affirming that profit maximization within legal bounds is the most ethical
behavior possible for business, we encourage private enterprise, and more individuals enter
the marketplace in the quest of profits. The inevitable result of increased competition is lower
prices and better products, both of which serve the interests of consumers. Moreover, since
maximizing profits enhances the wealth of a company's stakeholders, broad participation in
private enterprise raises the wealth of a nation, expands its economy, and raises its overall
standard of living and quality of life.
On the other hand are three compelling arguments for holding business executives to
certain responsibilities m addition to profit maximization and to compliance with the letter of the
law. First, a growing percentage of businesses are related to technology, and haws often lag
behind advances in technology. As a result, new technology-based products and services
might pose potential harm to consumers even though they conform to current laws. For
example, Intemet commerce is still largely unregulated because our lawmakers are slow to
react to the paradigm shift from brick-and-mortar commerce to e-commerce. As a result,
unethical marketing practices, privacy invasion, and violations of intellectual-property rights
are going unchecked for lack of regulations that would clearly prohibit them.
Secondly, since a nation's laws do not extend beyond its borders, compliance with those
laws does not prevent a business from doing harm elsewhere. Consider, for example, the
trend among U.S. businesses in exploiting workers in countries where labor laws are virtuaUy
non-existent in order to avoid the costs of complying with U.S. labor laws.
Thirdly, a philosophical argument can be made that every business enters into an implied
social contract with the community that permits it to do business, and that this social contract,
although not legally enforceable, places a moral duty on the business to refrain from acting in
ways that will harm that community.
In sum, I agree with the statement insofar as in seeking to maximize profits a business
serves not only itself but also its employees, customers, and the overall economy. Yet today's
rapidly changing business environment and increasing globalization call for certain affirmative
obligations beyond the pursuit of profit and mere compliance with enforceable rules and
regulations. Moreover, in the final analysis any business is indebted to the society in which it
operates for its very existence, and thus has a moral duty, regardless of any legal obligations,
to pay that debt.
























Issue 67
"Students should bring a certain skepticism to whatever they study. They should question what
they are taught instead of accepting it passively."
The speaker contends that students should be skeptical in their studies, and should not
accept passively whatever they are taught. In my view, although undue skepticism might be
counterproductive for a young child's education, I strongly agree with the speaker otherwise.
Ifwe were all to accept on blind faith all that we are taught, our society would never progress or
evolve.
Skepticism is perhaps most important in the physical sciences. Passive acceptance of
prevailing principles quells innovation, invention, and discovery. In fact, the very notion of
scientific progress is predicated on rigorous scientific inquiry--in other words, skepticism. And
history is replete with examples of students of science who challenged what they had been
taught, thereby paving the way for scientific progress. For example, in challenging the notion
that the Earth was in a fixed position at the center of the universe, Copernicus paved the way
for the corroborating observations of Galileo a century later, and ultimately for Newton's
principles of gravity upon which all modern science is based. The staggering cumulative
impact of Copernicus' rejection of what he had been taught is proof enough of the value of
skepticism.
The value of skepticism is not limited to the physical sciences, of course. In the fields of
sociology and political science, students must think critically about the assumptions underlying
the status quo; otherwise, oppression, tyranny and prejudice go unchecked. Similarly, while
students of the law must learn to appreciate timeless legal doctrines and principles, they must
continually question the fairness and relevance of current laws. Otherwise, our laws would not
evolve to reflect changing societal values and to address new legal issues arising from our
ever-evolving technologies.
Even in the arts, students must challenge established styles and forms rather than learn to
imitate them; otherwise, no genuinely new art would ever emerge. Bee-bop musicians such as
Charlie Parker demonstrated through their wildly innovative harmonies and melodies their
skepticism about established rules for harmony and melody. In the area of dance BaUanchine
showed by way of his improvisational techniques his skepticism about established rules for
choreography. And Germany's Bauhaus School of Architecture, to which modern architecture
owes its existence, was rooted in skepticism about the proper objective, and resulting design,
of public buildings.
Admittedly, undue skepticism might be counterproductive in educating young children. I am
not an expert in developmental psychology; yet observation and common sense informs me
that youngsters must first develop a foundation of experiential knowledge before they can
begin to think critically about what they are learning. Even so, in my view no student, no matter
how young, should be discouraged from asking "Why?" and "Why not?"
To sum up, skepticism is the very stuff that progress is made of, whether it be in science,
sociology, politics, the law, or the arts. Therefore, skepticism should be encouraged at all but
the most basic levels of education.
























Issue 68
"Both parents and communities must be involved in the local schools. Education is too
important to leave solely to a group of professional educators."
Should parents and communities participate in local education because education is too
important to leave to professional educators, as the speaker asserts? It might be tempting to
agree with the speaker, based on a parent's legal authority over, familiarity with, and interest in
his or her own children. However, a far more compelling argument can be made that, except
for major decisions such as choice of school, a child's education is best left to professional
educators.
Communities of parents concerned about their children's education rely on three arguments
for active parental and community participation in that process. The fzrst argument, and the
one expressed most often and vociferously, is that parents hold the ultimately legal authority to
make key decisions about what and how their own children learn including choice of
curriculum and text books, pace and schedule for learning, and the extent to which their child
should learn alongside other children. The second argument is that only a parent can truly
know the unique needs of a child including what educational choices are best suited for the
child. The third argument is that parents are more motivated--by pride and ego--than any other
person to take whatever measures are needed to ensure their children receive the best
possible education.
Careful examination of these three arguments, however, reveals that they are specious at
best. As for the first one, were we to allow parents the right to make all major decisions
regarding the education of their children, many children would go with little or no education. In
a perfect world parents would always make their children's education one of their highest
priorities. Yet, in fact many parents do not. As for the second argument, parents are not
necessarily best equipped to know what is best for their child when it comes to education.
Although most parents might think they are sufficiently expert by virtue of having gone through
formal education themselves, parents lack the specialized training to appreciate what
pedagogical methods are most effective, what constitutes a balanced education, how
developmental psychology affects a child's capacity for learning at different levels and at
different stages of childhood. Professional educators, by virtue of their specialized training in
these areas, are far better able to ensure that a child receives a balanced, properly paced
education.
There are two additional compelling arguments against the speaker's contention. First,
parents are too subjective to always know what is truly best for their children. For example,
many parents try to overcome their own shortcomings and failed self-expectations vicariously
through their children's accomplishments. Most of us have known parents who push their child
to excel in certain areas--to the emotional and psychological detriment of the child. Secondly, if
too many parties become involved in making decisions about day-to-day instruction, the end
result might be infighting, legal battles, boycotts, and other protests, all of which impede the
educational process; and the ultimate victims are the children themselves. Finally, in many
jurisdictions parents now have the option of schooling their children at home, as long as certain
state requirements are met. In my observation, home schooling allows parents who prefer it
great control over a child's education, while allowing the professional educators to discharge
their responsibilities as effectively as possible--unfettered by gadfly parents who constantly
interfere and intervene.
In sum, while parents might seem better able and better motivated to make key decisions
about their child's education, in many cases they are not. With the possible exceptions of
responsible home-schoolers, a child's intellectual, social, and psychological development is at
risk when communities of parents dominate the decision-making process involving education.
























Issue 69
"There is no such thing as purely objective observation. All observation is subjective; it is
always guided by the observer's expectations or desires."
The speaker claims that all observation is subjective--colored by desire and expectation.
While it would be tempting to concede that we all see things differently, careful scrutiny of the
speaker's claim reveals that it confuses observation with interpretation. In fact, in the end the
speaker's claim relies entirely on the further claim that there is no such thing as truth and that
we cannot truly know anything. While this notion might appeal to certain existentialists and
epistemologists, it runs against the grain of all scientific discovery and knowledge gained over
the last 500 years.
It would be tempting to afford the speaker's daim greater merit than it deserves. After all, our
everyday experience as humans informs us that we often disagree about what we observe
around us. We've all uttered and heard uttered many times the phase "That's not the way I see
it!" Indeed, everyday observations--for example, about whether a football player was out of
bounds, or about which car involved in an accident ran the red light--vary depending not only
on one's spatial perspective but also on one's expectations or desires. If I'm rooting for one
football team, or if the player is well-known for his ability to make great plays while barely
staying in bounds, my desires or expectations might influence what I think I observe. Or if I am
driving one of the cars in the accident, or if one car is a souped-up sports car, then my desires
or expectations will in all likelihood color my perception of the accident's events.
However, these sorts of subjective "observations" are actually subjective "interpretations'' of
what we observe. Visitors to an art museum might disagree about the beauty of a particular
work, or even about which color predominates in that work. In a court trial several jurors might
view the same videotape evidence many times, yet some jurors might "observe" an incident of
police brutality, will others "observe" the appropriate use of force to restrain a dangerous
individual. Thus when it comes to making judgments about what we observe and about
remembering what we observe, each person's individual perspective, values, and even
emotions help form these judgments and recollections. It is crucial to distinguish between
interpretations such as these and observation, which is nothing more than a sensory
experience. Given the same spatial perspective and sensory acuity and awareness, it seems
to me that our observations would all be essentially in accord--that is, observation can be
objective.
Lending credence to my position is Francis Bacon's scientific method, according to which we
can know only that which we observe, and thus all truth must be based on empirical
observation. This profoundly important principle serves to expose and strip away all subjective
interpretation of observation, thereby revealing objective scientific truths. For example, up until
Bacon's time the Earth was "observed" to lie at the center of the Universe, in accordance with
the prevailing religious notion that man (humankind) was the center of God's creation.
Applying Bacon's scientific method Galileo exposed the biased nature of this claim. Similarly,
before Einstein time and space were assumed to be linear, in accordance with our
"observation." Einstein's mathematical formulas suggested otherwise, and his theories have
been proven empirically to be true. Thus it was our subjective interpretation of time and space
that led to our misguided notions about them. Einstein, like history's other most influential
scientists, simply refused to accept conventional interpretations of what we all observe.
In sum, the speaker confuses observation with interpretation and recollection. It is how we
make sense of what we observe, not observation itself, that is colored by our perspective,
expectations, and desires. The gifted individuals who can set aside their subjectivity and delve
deeper into empirical evidence, employing Bacon's scientific method, are the ones who reveal
that observation not only can be objective but must be objective if we are to embrace the more
fundamental notion that knowledge and truth exist.
























Issue 70
"The human mind will always be superior to machines because machines are only tools of
human minds."
This statement actually consists of a series of three related claims: (1) machines are tools of
human minds; (2) human minds will always be superior to machines; and (3) it is because
machines are human tools that human minds will always be superior to machines. While I
concede the fn:st claim, whether I agree with the other two claims depends partly on how one
defines "superiority," and partly on how willing one is to humble oneself to the unknown future
scenarios.
The statement is clearly accurate insofar as machines are tools of human minds. After all,
would any machine even exist unless a human being invented it? Of course not. Moreover, I
would be hard-pressed to think of any machine that cannot be described as a tool. Even
machines designed to entertain or amuse us--for example, toy robots, cars and video games,
and novelty items--are in fact tools, which their inventors and promoters use for engaging in
commerce and the business of entertainment and amusement. And, the claim that a machine
can be an end in itself, without purpose or utilitarian function for humans whatsoever, is
dubious at best, since I cannot conjure up even a single example of any such machine. Thus
when we develop any sort of machine we always have some sort of end in mind a purpose for
that machine.
As for the statement's second claim, in certain respects machines are superior. We have
devised machines that perform number-crunching and other rote cerebral tasks with greater
accuracy and speed than human minds ever could. In fact, it is because we can devise
machines that are superior in these respects that we devise them--as our tools--to begin with.
However, if one defines superiority not in terms of competence in per-forming rote tasks but
rather in other ways, human minds are superior. Machines have no capacity for independent
thought, for making judgments based on normative considerations, or for developing
emotional responses to intellectual problems.
Up until now, the notion of human-made machines that develop the ability to think on their
own, and to develop so-called "emotional intelligence," has been pure fiction. Besides, even in
fiction we humans ultimately prevail over such machines--as in the cases of Frankenstein's
monster and Hal, the computer in 2001: A Space Odyssey. Yet it seems presumptuous to
assert with confidence that humans will always maintain their superior status over their
machines. Recent advances in biotechnology, particularly in the area of human genome
research, suggest that within the 21st Century we'll witness machines that can learn to think on
their own, to repair and nurture themselves, to experience visceral sensations, and so forth. In
other words, machines will soon exhibit the traits to which we humans attribute our own
superiority.
In sum, because we devise machines in order that they may serve us, it is fair to
characterize machines as "tools of human minds." And insofar as humans have the unique
capacity for independent thought, subjective judgment, and emotional response, it also seems
fair to claim superiority over our machines. Besides, should we ever become so clever a
species as to devise machines that can truly think for themselves and look out for their own
well-being, then query whether these machines of the future would be "machines'' anymore.
























Issue 71
"The most essential quality of an effective leader is the ability to remain consistently committed
to particular principles and objectives. Any leader who is quickly and easily influenced by shifts
in popular opinion will accomplish little."
Whether effective leadership requires that a leader consistently follow his or her principles and
objectives is a complex issue--one that is tied up in the problem of defining effective leadership
in the first place. In addressing the issue it is helpful to consider, in turn, three distinct forms of
leadership: business, political, and social-spiritual.
In the business realm, effective leadership is generally defined, at least in our corporate
culture, as that which achieves the goal of profit maximization for a firm's shareholders or other
owners. Many disagree, however, that profit is the appropriate measure of a business leader's
effectiveness. Some detractors claim, for example, that a truly effective business leader must
also fulfill additional duties--for example, to do no intentional harm to their customers or to the
society in which they operate. Other detractors go further--to impose on business leaders an
affirmative obligation to yield to popular will, by protecting consumers, preserving the natural
environment, promoting education, and otherwise taking steps to help alleviate society's
problems.
Whether our most effective business leaders are the ones who remain consistently
committed to maximizing profits or the ones who appease the general populace by
contributing to popular social causes depends, of course, on one's own definition of business
success. In my observation, as business leaders become subject to closer scrutiny by the
media and by social activists, business leaders will maximize profits in the long term only by
taking reasonable steps to minimize the social and environmental harm their businesses
cause. Thus the two definitions merge, and the statement at issue is ultimately correct.
In the political realm the issue is no less complex. Definitions of effective political leadership
are tied up in the means a leader uses to wield his or her power and to obtain that power in the
first place. Consider history's most infamous tyrants and despots--such as Genghis Khaan,
Stalin, Mao, and Hider. No historian would disagree that these individuals were remarkably
effective leaders, and that each one remained consistently committed to his tyrannical
objectives and Machiavellian principles. Ironically, it was stubborn commitment to objectives
that ultimately defeated all except Khan. Thus in the short term stubborn adherence to one's
objectives might serve a political leader's interest in preserving his or her power; yet in the long
term such behavior invariably results in that leader's downfall if the principles are not in
accord with those of the leader's would-be followers.
Finally, consider social-spiritual leadership. Few would disagree that through their ability to
inspire others and lift the human spirit Mahatma Gandhi and Martin Luther King were
eminently effective in leading others to effect social change through civil disobedience. It
seems to me that this brand of leadership, in order to be effective, inherently requires that the
leader remain steadfastly committed to principle. Why? It is commitment to principle that is the
basis for this brand of leadership in the first place. For example, had Gandhi advocated civil
disobedience yet been persuaded by dose advisors that an occasional violent protest might be
effective in gaining India's independence from Britain, no doubt the result would have been
immediate forfeiture of that leadership. In short, social-spiritual leaders must not be hypocrites;
otherwise, they will lose all credibility and effectiveness.
In sum, strict adherence to principles and objectives is a prerequisite for effective
social-spiritual leadership--both in the short and long term. In contrast, political leadership
wanes in the long term unless the leader ultimately yields to the will of the followers.
Finally, when it comes to business, leaders must strike a balance between the objective of
profit maximization--the traditional measure of effectiveness--and yielding to certain broader
obligations that society is now imposing on them.
























Issue 72
"In this age of intensive media coverage, it is no longer possible for a society to regard any
woman or man as a hero. The reputation of anyone who is subjected to media scrutiny will
eventually be diminished."
In general, I agree with the assertion that intense media scrutiny nearly always serves to
diminish the reputation of society's would-be heroes, for the chief reason that it seems to be
the nature of media to look for ways to demean public figures whether heroic or not.
Moreover, while in isolated cases our so-called heroes have vindicated themselves and
restored their reputations diminished by the media, in my observation these are exceptional
cases to the general rule that once slandered, the reputation of any public figure, hero or
otherwise, is forever tarnished.
The chief reason why I generally agree with the statement has to do with the forces that
motivate the media in the first place. The media generally consist of profit-seeking entities,
whose chief objective is to maximize profits for their shareholders or other owners. Moreover,
our corporate culture has sanctioned this objective by codifying it as a fiduciary obligation of
any corporate executive. For better or worse, in our society media viewers, readers, and
listeners find information about the misfortunes and misdeeds of others, especially heroic
public figures, far more compelling than information about their virtues and accomplishments.
In short, we love a good scandal. One need look no further than the newsstand, local television
news broadcast, or talk show to find ample evidence that this is the case. Thus in order to
maximize profits the media are simply giving the public what they demand scrutiny of heroic
public figures that serves to diminish their reputation.
A second reason why I fundamentally agree with the statement is that, again for better or
worse, intense media scrutiny raises a presumption, at least in the public's collective mind, that
their hero is guilty of some sort of character flaw or misdeed. This presumption is
understandable. After all, I think any demographic study would show that the vast majority of
people relying on mainstream media for their information lack the sort of critical-thinking skills
and objectivity to see beyond what the media feeds them, and to render a fair and fully
informed judgment about a public figure--heroic or otherwise.
A third reason for my agreement with the statement has to do with the longer-term fallout
from intense media scrutiny and the presumption discussed above. Once tarnished as a result
of intense media scrutiny, a person's reputation is forever besmirched, regardless of the merits
or motives of the scrutinizers. Those who disagree with this seemingly cynical viewpoint might
cite cases in which public figures whose reputations had been tarnished were ultimately
vindicated. For example, certain celebrities have successfully challenged rag sheets such as
the National Enquirer in the courts, winning large damage awards for libel. Yet in my
observation these are exceptional cases; besides, a damage award is no indication that the
public has expunged from its collective memory a perception that the fallen hero is guilty of the
alleged character flaw or peccadillo.
In sum, the statement is fundamentally correct. As long as the media are motivated by profit,
and as long as the public at large demands stories that serve to discredit, diminish, and
destroy reputations, the media will continue to harm whichever unfortunate individuals become
their cynosures. And the opportunity for vindication is little consolation in a society that seems
to thrive, and even feed, on watching heroes being knocked off their pedestals.
























Issue 73
"Sometimes imagination is a more valuable asset than experience. People who lack
experience are free to imagine what is possible and thus can approach a task without
constraints of established habits and attitudes."
The speaker asserts that imagination is "sometimes" more valuable than experience
because individuals who lack experience can more freely imagine possibilities for approaching
tasks than those entrenched in established habits and attitudes. I fundamentally agree;
however, as the speaker implies, it is important not to overstate the comparative value of
imagination. Examples from the arts and the sciences aptly illustrate both the speaker's point
and my caveat.
One need only observe young children as they go about their daily lives to appreciate the
role that pure imagination can play as an aid to accomplishing tasks. Young children, by virtue
of their lack of experience, can provide insights and valuable approaches to adult problems.
Recall the movie Big, in which a young boy magically transformed into an adult found himself
in a high-power job as a marketing executive. His inexperience in the adult world of business
allowed his youthful imagination free reign to contribute creative--and successful ideas that
none of his adult colleagues, set in their ways of thinking about how businesses go about
maximizing profits, ever would have considered. Admittedly, Big was a fictional account; yet, I
think it accurately portrays the extent to which adults lack the kind of imagination that only
inexperience can bring to solving many adult problems.
The speaker's contention also finds ample empirical support in certain forms of artistic
accomplishment and scientific invention. History is replete with evidence that our most gifted
musical composers are young, relatively inexperienced, individuals. Notables ranging from
Mozart to McCartney come immediately to mind. Similarly, the wide-eyed wonder of
inexperience seems to spur scientific innovation. Consider the science fiction writer Jules
Veme, who through pure imagination devised highly specific methods and means for
transporting humans to outer space. What makes his imaginings so remarkable is that the
actual methods and means for space flight, which engineers settled on through the experience
of extensive research and trial-and-error, turned out to be essentially the same ones Verne had
imagined nearly a century earlier!
Of course, there are many notable exceptions to the rule that imagination unfettered by
experience breeds remarkable insights and accomplishments. Duke EUington, perhaps jazz
music's most prolific composers, continued to create new compositions until late in life.
Thomas Edition, who registered far more patents with the U.S. patent office than any other
person, continued to invent until a very old age. Yet, these are exceptions to the general
pattern. Moreover, the later accomplishments of individuals such as these tend to build on
earlier ones, and therefore are not as truly inspired as the earlier ones, which sprung from
imagination less fettered by life experience.
On the other hand, it is important not to take this assertion about artistic and scientific
accomplishment too far. Students of the arts, for instance, must learn theories and techniques,
which they then apply to their craft whether music performance, dance, or acting. And,
creative writing requires the cognitive ability to understand how language is used and how to
communicate ideas. Besides, creative ability is itself partly a function of intellect; that is,
creative expression is a marriage of one's cognitive abilities and the expression of one's
feelings and emotions. In literature, for example, a rich life experience from which to draw
ideas is just as crucial to great achievement as imagination. For example, many critics laud
Mark Twam's autobiography, which he wrote on his death bed, as his most inspired work. And,
while the direction and goals of scientific research rely on the imaginations of key individuals,
most scientific discoveries and inventions come about not by sudden epiphanies of youthful
star-gazers but rather by years and years of trial-and-error in corporate research laboratories.
In sum, imagination can serve as an important catalyst for artistic creativity and scientific
invention. Yet, experience can also play a key role; in fact, in literature and in science it can
play just as key a role as the sort of imagination that inexperience breeds.
























Issue 74
"In any given field, the leading voices come from people who are motivated not by conviction
but by the desire to present opinions and ideas that differ from those held by the majority."
I agree with the statement insofar as our leading voices tend to come from people whose
ideas depart from the status quo. However, I do not agree that what motivates these
iconoclasts is a mere desire to be different; in my view they are driven primarily by their
personal convictions. Supporting examples abound in all areas of human endeavor-- including
politics, the arts, and the physical sciences.
When it comes to political power, I would admit that a deep-seated psychological need to be
noticed or to be different sometimes lies at the heart of a person's drive to political power and
fame. For instance, some astute presidential historians have described Clinton as a man
motivated more by a desire to be great than to accomplish great things. And many
psychologists attribute Napoleon's and Mussolini's insatiable lust for power to a so-called
"short-man complex"--a need to be noticed and admired in spite of one's small physical
stature.
Nevertheless, for every leading political voice driven to new ideas by a desire to be noticed
or to be different, one can cite many other political leaders clearly driven instead by the
courage of their convictions. Iconoclasts Mahatma Gandhi and Martin Luther King, for example,
secured prominent places in history by challenging the status quo through civil disobedience.
Yet no reasonable person could doubt that it was the conviction of their ideas that drove these
two leaders to their respective places.
Turning to the arts, mavericks such as Dali, Picasso and Warhol, who departed from
established rules of composition, ultimately emerge as the leading artists. And our most
influential popular musicians are the ones who are flagrantly "different." Consider, for example,
jazz pioneers Thelonius Monk and Miles Davis, who broke all the harmonic rules, or folk
musician-poet Bob Dylan, who established a new standard for lyricism. Were all these leading
voices driven simply by a desire to be different? Perhaps; but my intuition is that creative urges
are born not of ego but rather of some intensely personal commitment to an aesthetic ideal.
As for the physical sciences, innovation and progress can only result from challenging
conventional theories--that is, the status quo. Newton and Einstein, for example, both refused
to blindly accept what were perceived at their time as certain rules of physics. As a result, both
men redefined those rules. Yet it would be patently absurd to assert that these two scientists
were driven by a mere desire to conjure up "different" theories than those of their
contemporaries or predecessors. Surely it was a conviction that their theories were better that
drove these geniuses to their places in history.
To sum up, when one examines history's leading voices it does appear that they typically
bring to the world something radically different than the status quo. Yet in most cases this sort
of iconoclasm is a byproduct of personal conviction, not iconoclasm for its own sake.
























Issue 75
"It is impossible for an effective political leader to tell the truth all the time. Complete honesty is
not a useful virtue for a politician."
Is complete honesty a useful virtue in politics? The speaker contends that it is not, for the
reason that political leaders must sometimes lie to be effective. In order to evaluate this
contention it is necessary to examine the nature of politics, and to distinguish between
short-term and long-term effectiveness.
On the one hand are three compelling arguments that a political leader must sometimes be
less than truthful in order to be effective in that leadership. The first argument lies in the fact
that politics is a game played among politicians--and that to succeed in the game one must
use the tools that are part-and-parcel of it. Complete forthrightness is a sign of vulnerability
and naivete, neither of which will earn a politician respect among his or her opponents, and
which those opponents will use to every advantage against the honest politician.
Secondly, it is crucial to distinguish between misrepresentations of fact in other words,
lies--and mere political rhetoric. The rhetoric of a successful politician eschews rigorous factual
inquiry and indisputable fact while appealing to emotions, ideals, and subjective interpretation
and characterizations. Consider, for example, a hypothetical candidate for political office who
attacks the incumbent opponent by pointing out only certain portions of that opponent's
legislative voting record. The candidate might use a vote against a bill eliminating certain
incentives for local businesses as "dear evidence" that the opponent is "anti-business," "bad
for the economy," or "out of touch with what voters want." None of these allegations are
outright lies; they are simply the rhetorical cant of the effective politician.
Thirdly, politics is a business born not only of idealism but also of pragmatism; after all, in
order to be effective a politician must gain and hold onto political power, which means winning
elections. In my observation some degree of pandering to the electorate and to those who
might lend financial support in reelection efforts is necessary to maintain that position. Modern
politics is replete with candidates who refused to pander, thereby mining their own chance to
exercise effective leadership.
Although in the short term being less-than-truthful with the public might serve a political
leader's interest in preserving power, would-be political leaders who lack requisite integrity
ultimately forfeit their leadership. Consider Richard Nixon, whose leadership seemed born not
of ideology but of personal ambition, which bred contempt of the very people who sanctioned
his leadership in the first place; the ultimate result was his forfeiture of that leadership. In
contrast, Ronald Reagan was a highly effective leader largely because he honestly, and deeply,
believed in the core principles that he espoused and advocated during his presidency--and his
constituency sensed that genuineness and responded favorably to it. Moreover, certain types
of sociopolitical leadership inherently require the utmost integrity and honesty. Consider
notable figures such as Gandhi and King, both of whom were eminently effective in leading
others to practice the high ethical and moral standards which they themselves advocated. The
reason for this is simple: A high standard for one's own personal integrity is a prerequisite for
effective moral leadership.
To sum up, I concede that the game of politics calls for a certain measure of posturing and
disingenuousness. Yet, at the end of the game, without a countervailing measure of integrity,
political game-playing will serve to diminish a political leader's effectiveness perhaps to the
point where the politician forfeits the game.
























Issue 76
"What is called human nature is really a reflection of the human condition: if all people had a
reasonable share of territory and resources, such products of 'human nature' as war and crime
would become extremely rare."
Are products of human nature such as war and crime actually products of the human
condition--specifically, lack of resources and territory? The speaker daims so. I strongly
disagree, however. Whether we look at science and history, or simply look around us in our
daily lives, we see ample evidence that human aggression is the product of our nature as
humans--and not of our circumstances.
First of all, the claim runs contrary to my personal observation about individual
behavior--especially when it comes to males. One need look no further than the local
school-ground or kindergarten playroom to see the roots of crime and war. Every school-yard
has its bully who delights in tormenting meeker school mates; and in every kindergarten
classroom there is at least one miscreant whose habit is to snatch away the favorite toys of
classmates--purely for the enjoyment of having seized property from another. And these
behaviors are clearly not for want of resources or territory. Thus the only reasonable
explanation is that they are products of human nature--not of the human condition.
Secondly, the daim flies in face of what scientists have learned about genetically determined
human traits. Many human traits--not just physical ones but psychological ones as well are
predetermined at birth. And to a great extent we have inherited our genetic predisposition from
our non-human ancestors. One might argue that lower animal species engage in warlike
behavior for the main reason that they must do so to protect their territory, their dan, or for food
not because of their nature. Yet, this point begs the question; for we humans have been
genetically programmed, through the evolutionary process, to behave in similar ways. In other
words, doing so is simply our nature.
Thirdly, the claim makes little sense in the context of human history. Prior to the last few
centuries the inhabitable regions of our planet provided ample territory and resources--such as
food and cultivable land--to accommodate every human inhabitant. Yet our distant ancestors
engaged in war and crime anyway. What else explains this, except that it is part of our inherent
nature to engage in aggressive behavior toward other humans? Moreover, if we consider the
various experiments with Marx's Communism, it becomes clear that the pure Marxist State in
which all territory and resources are shared according to the needs of each individual does not
work in practice. Every attempt, whether on the macro- or micro-level, has failed at the hands
of a few demagogues or despots, who aggress and oppress like playground bullies.
In sum, the author of this statement misunderstands the roots of such phenomena as war
and crime. The statement runs contrary to my personal observations of human behavior, to the
scientific notions of genetic predisposition and evolution of species, and to the overwhelming
lack of evidence that providing ample resources to people solves these problems.
























Issue 77
"Critical judgment of work in any given field has little value unless it comes from someone who
is an expert in that field."
The speaker's assertion that work in any field can be judged only by experts in that field
amounts to an unfair generalization, in my view. I would concur with the speaker when it
comes to judging the work of social scientists, although I would strongly disagree when it
comes to work in the pure physical sciences, as explained in the following discussion.
With respect to the social sciences, the social world presents a seamless web of not only
anthropogenic but also physical forces, which interact in ways that can be understood only in
the context of a variety of disciplines. Thus experts from various fields must collectively
determine the merit of work in the social sciences. For example, consider the field of cultural
anthropology. The merits of researcher's findings and conclusions about an ancient civilization
must be scrutinized by biochemists, geologists, linguists, and even astronomers.
Specifically, by analyzing the hair, nails, blood and bones of mummified bodies, biochemists
and forensic scientists can pass judgment on the anthropologist's conjectures about the life
expectancy, general well-being, and common causes of death of the population. Geologists
are needed to identify the source and age of the materials used for tools, weapons, and
structures--thereby determining whether the anthropologist extrapolated correctly about the
civilization's economy, trades and work habits, life styles, extent of travel and mobility, and so
forth. Linguists are needed to interpret hieroglyphics and extrapolate from found fragments of
writings. And astronomers are sometimes needed to determine with the anthropologist's
explanations for the layout of an ancient city or the design, structure and position of
monuments, tombs, and temples is convincing-because ancients often looked to the stars for
guidance in building cities and structures.
In contrast, the work of researchers in the purely physical sciences can be judged only by
their peers. The reason for this is that scientific theories and observations are either
meritorious or not, depending solely on whether they can be proved or disproved by way of the
scientific method. For example, consider the complex equations which physicists rely upon to
draw conclusions about the nature of matter, time, and space, or the origins and future of the
universe. Only other physicists in these specialties can understand, let alone judge, this type of
theoretical work. Similarly, empirical observations in astrophysics and molecular physics
require extremely sophisticated equipment and processes, which only experts in these fields
have access to and who know how to use reliably.
Those who disagree that only inside experts can judge scientific work might point out that
the expertise of economists and pubic-policy makers is required to determine whether the
work is worthwhile from a more mundane economic or political viewpoint. Detractors might
also point out that ultimately it is our philosophers who are best equipped to judge the ultimate
import of ostensibly profound scientific discoveries. Yet these detractors miss the point of what
I take to be the speaker's more narrow claim: that the integrity and quality of
work---disregarding its socioeconomic utility----can be judged only by experts in the work's
field.
In sum, in the social sciences no area of inquiry operates in a vacuum. Because fields such
as anthropology, sociology, and history are so closely intertwined and even dependent on the
physical sciences, experts from various fields must collectively determine the integrity and
quality of work in these fields. However, in the purely physical sciences the quality and integrity
of work can be adequately judged only by inside experts, who are the only ones equipped with
sufficient technical knowledge to pass judgment.
























Issue 78
"Those who treat politics and morality as though they were separate realms fail to understand
either the one or the other."
Should politics and morality be treated as though they are mutually exclusive? I strongly
agree with the speaker that any person claiming so fails to understand either the one or the
other. An overly narrow definition of morality might require complete forthrightness and
candidness in dealings with others. However, the morality of public politics embraces far
broader concerns involving the welfare of society, and recognizes compromise as a necessary,
and legitimate, means of addressing those concerns.
It is wrong-headed to equate moral behavior in politics with the simple notions of honesty
and putting the other fellow's needs ahead of one's own----or other ways which we typically
measure the morality of an individual's private behavior. Public politics is a game played
among professional politicians--and to succeed in the game one must use the tools that are
part-and-parcel of it. Complete forthrightness is a sign of vulnerability and naivet~, neither of
which will earn a politician respect among his or her opponents, and which opponents will use
to every advantage against the honest politician. Moreover, the rhetoric of a successful
politician eschews rigorous factually inquiry and indisputable fact while appealing to emotions,
ideals, and subjective interpretation and characterizations. For example, the politician who
claims his opponent is "anti-business," "bad for the economy," or "out of touch with what voters
want" is not necessarily behaving immorally. We must understand that this sort of rhetoric is
part-and-parcel of public politics, and thus kept in perspective does not harm the society--as
long as it does not escalate to outright lying.
Those who disagree with the statement also fail to understand that in order to gain the
opportunity for moral leadership politicians must engage in certain compromises along the way.
Politics is a business born not only of idealism but also of pragmatism insofar as in order to be
effective a politician must gain and hold onto political power. In my observation, some degree
of pandering to the electorate and to those who might lend financial support for reelection
efforts is necessary to maintain that position. Modern politics is replete with candidates who
refused to pander, thereby mining their own chance to exercise effective leadership.
Finally, those who claim that effective politicians need not concern themselves with morality
fail to appreciate that successful political leadership, ifit is to endure, ultimately requires a
certain measure of public morality--that is, serving the society with its best interests as the
leader's overriding concern. Consider the many leaders, such as Stalin and Hitler, whom most
people would agree were egregious violators of public morality. Ultmately such leaders forfeit
their leadership as a result of the immoral means by which they obtain or wield their power. Or
consider less egregious examples such as President Nixon, whose contempt for the very legal
system that afforded him his leadership led to his forfeiture of that leadership. It seems to me
that in the short term amoral or immoral public behavior might serve a political leader's interest
in preserving power; yet in the long term such behavior invariably results in that leader's
downfall.
In sum, I fundamentally agree with the statement. It recognizes that the "game" of politics
calls for a certain amount of disingenuousness that we might associate with dubious private
morality. And it recognizes that such behavior is a necessary means to the final objective of
moral political leadership. Besides, at the end of the political game any politician failing to
exercise moral leadership ultimately forfeits the game.



























Issue 79
"Great advances in knowledge necessarily involve the rejection of authority."
The speaker claims that great advances in knowledge necessarily involve rejection of
authority. To the extent that political authority impedes such advances, I agree with this claim.
Otherwise, in my view most advances in knowledge actually embrace certain forms of authority,
rather than rejecting authority out of hand.
One striking example of how political authority can impede the advancement of knowledge
involves what we know about the age and evolution of planet Earth. In earlier centuries the
official Church of England called for a literal interpretation of the Bible, according to which the
Earth's age is determined to be about 6,000 years. IfWestern thinkers had continued to yield to
the ostensible authority of the Church, the fields of structural and historical geology would
never have advanced beyond the blind acceptance of this contention as fact.
A more modern example of how yielding to political authority can impede the advancement
of knowledge involves the Soviet Refusenik movement of the 1920s. During this time period
the Soviet government attempted not only to control the direction and the goals of its scientists'
research but also to distort the outcome of that research. During the 1920s the Soviet
government quashed certain areas of scientific inquiry, destroyed entire research facilities and
libraries, and caused the sudden disappearance of many scientists who were engaged in
research that the state viewed as a potential threat to its power and authority. Not surprisingly,
during this time period no significant advances in scientific knowledge occurred under the
auspices of the Soviet government.
However, given a political climate that facilitates free thought and honest intellectual inquiry,
great advances in knowledge can be made by actually embracing certain forms of "authority."
A good example involves modern computer technology. Only by building on, or embracing,
certain well-established laws of physics were engineers able to develop silicon-based
semi-conductor technology. Although new biotechnology research suggests that organic,
biochemical processors will replace artificial semi-conductors as the computers of the future, it
would be inappropriate to characterize this leap in knowledge as a rejection of authority.
In sum, to the extent that political authority imposes artificial constraints on knowledge, I
agree that advances in knowledge might require rejection of authority. Otherwise, in my
observation advances in knowledge more typically embrace and build on authoritative
scientific principles and laws, and do not require the rejection of any type of authority.
























Issue 80
"The surest indicator of a great nation is not the achievements of its rulers, artists, or scientists,
but the general welfare of all its people."
The speaker claims that great advances in knowledge necessarily involve rejection of
authority. To the extent that political authority impedes such advances, I agree with this claim.
Otherwise, in my view most advances in knowledge actually embrace certain forms of authority,
rather than rejecting authority out of hand.
One striking example of how political authority can impede the advancement of knowledge
involves what we know about the age and evolution of planet Earth. In earlier centuries the
official Church of England called for a literal interpretation of the Bible, according to which the
Earth's age is determined to be about 6,000 years. IfWestern thinkers had continued to yield to
the ostensible authority of the Church, the fields of structural and historical geology would
never have advanced beyond the blind acceptance of this contention as fact.
A more modern example of how yielding to political authority can impede the advancement
of knowledge involves the Soviet Refusenik movement of the 1920s. During this time period
the Soviet government attempted not only to control the direction and the goals of its scientists'
research but also to distort the outcome of that research. During the 1920s the Soviet
government quashed certain areas of scientific inquiry, destroyed entire research facilities and
libraries, and caused the sudden disappearance of many scientists who were engaged in
research that the state viewed as a potential threat to its power and authority. Not surprisingly,
during this time period no significant advances in scientific knowledge occurred under the
auspices of the Soviet government.
However, given a political climate that facilitates free thought and honest intellectual inquiry,
great advances in knowledge can be made by actually embracing certain forms of "authority."
A good example involves modern computer technology. Only by building on, or embracing,
certain well-established laws of physics were engineers able to develop silicon-based
semi-conductor technology. Although new biotechnology research suggests that organic,
biochemical processors will replace artificial semi-conductors as the computers of the future, it
would be inappropriate to characterize this leap in knowledge as a rejection of authority.
In sum, to the extent that political authority imposes artificial constraints on knowledge, I
agree that advances in knowledge might require rejection of authority. Otherwise, in my
observation advances in knowledge more typically embrace and build on authoritative
scientific principles and laws, and do not require the rejection of any type of authority.
























Issue 81
"International relations can never be completely harmonious because many cultures do not
share the same values."
Does a nation's greatness lie in the general welfare of its people rather than in the
achievements of its artists, rulers, and scientists, as the speaker claims? I find this claim
problematic in two respects. First, it fails to define "general welfare." Second, it assumes that
the sorts of achievements that the speaker cites have little to do with a nation's general
welfare--when in fact they have everything to do with it.
At first blush the speaker's claim might appear to have considerable merit. After all, the
overriding imperative for any democratic state is to enhance the general welfare of its citizenry.
Yet the speaker fails to provide a clear litmus test for measuring that welfare. When we speak
of "promoting the general welfare," the following aims come to mind: public health and safety,
security against military invasions, individual autonomy and freedom, cultural richness, and
overall comfort--that is, a high standard of living. Curiously, it is our scientists, artists, and
political leaders-----or so-called "rulers" who by way of their achievements bring these aims
into fruition. Thus, in order to determine what makes a nation great it is necessary to examine
the different sorts of individual achievements that ostensibly promote these aims.
Few would disagree that many scientific achievements serve to enhance a nation's general
welfare. Advances in the health sciences have enhanced our physical well-being, comfort, and
life span. Advances in technology have enabled us to travel to more places, communicate with
more people from different walks of life, and learn about the world from our desktops.
Advances in physics and engineering make our abodes and other buildings safer, and enable
us to travel to more places, and to travel to more distant places, with greater safety and speed.
Artistic achievement is also needed to make a nation a better place for humans overall. Art
provides inspiration, lifts the human spirit, and incites our creativity and imagination, all of
which spur us on to greater accomplishments and help us appreciate our own humanity. Yet
the achievements of scientists and artists, while integral, do not suffice to ensure the welfare of
a nation's citizens. In order to survive, let alone be great, a nation must be able to defend its
borders and to live peaceably with other nations. Thus the military and diplomatic
accomplishments of a nation's leaders provide an integral contribution to the general welfare of
any nation's populace.
Notwithstanding the evidence that, in the aggregate, individual achievements of the sorts
listed above are what promote a nation's general welfare, we should be careful not to hastily
assume that a nation is necessarily great merely by virtue of the achievements of individual
citizens. Once having secured the safety and security of its citizens, political rulers must not
exploit or oppress those citizens. Also, the populace must embrace and learn to appreciate
artistic accomplishment, and to use rather than misuse or abuse scientific knowledge. Of
particular concern are the many ways in which scientific achievements have served to diminish
our quality of life, thereby impeding the general welfare. It is through scientific "achievements"
that chemicals in our food, water, and air increase the incidence and variety of cancers; that
our very existence as a species is jeopardized by the threat of nuclear warfare; and that
greenhouse gases which deplete our ozone layer and heat the Earth's atmosphere threaten
civilization itself.
In sum, in asserting that general welfare--and neither the scientific, artistic, nor political
achievements of individuals--provides the yardstick for measuring a nation's greatness, the
speaker misses the point that general welfare is the end product of individual achievements.
Besides, achievements of artists, scientists, and political leaders rarely inure only to one
particular nation. Rather, these achievements benefit people the world over.
Accordingly, by way of these achievements the world, not just one nation, grows in its
greatness.
























Issue 82
"People who pursue their own intellectual interests for purely personal reasons are more likely
to benefit the rest of the world than are people who try to act for the public good."
I strongly agree with the speaker's threshold claim that international relations can never be
completely harmonious. To assert otherwise would be Pollyannaish and would fly in the face of
human history--which is largely a story of power struggles, war, and general discord between
nations and cultures. However, the speaker's rationale, although appealing and not without
merit, is inadequate to explain why total accord among all nations is impossible.
Supporting the speaker's claim is the fact that each culture has its own distinct
ethos-consisting of its core values, principles, and spirit
which defines and distinguishes the culture.
And I agree that the failure of one culture to understand the unique ethos of another is what
often lies at the root of discord between nations and cultures. An apt current-day illustration of
this point involves a certain American Indian tribe in Washington State, and its traditional
custom of whale hunting. Environmentalists denounce the practice as unnecessary
endangerment of a species. However, underlying this custom is a centuries-old spiritual belief
that ceremonial whale-hunting is sacrificial ritual honoring Nature, and an even more
fundamental Native American ethos, characterized by a far greater respect for animals and for
Nature than the ethos of white Americans.
The sort of unfair judgment exemplified by certain white Americans' denunciation of Native
American customs and practices is what sociologists term "ethnocentricity"-- reference to
one's own cultural ethos as a standard for judging the values and actions of other people.
History informs us all too well that ethnocentricity leads inexorably to disharmony. Virtually all
wars are rooted in religious ethnocentricity. Political ethnocentricity results in
imperialism--assimilation of any and all peoples with complete disregard or respect for ethos.
Understandable resistance to British imperialism during the 19th Century resulted in the
oppression and demise of many indigenous peoples of Africa and Indonesia. And
ethnocentricity on a societal level can lead to mass persecution, as demonstrated by the
legions of citizens and soldiers brainwashed by the Nazis into believing that the Jewish race
posed some sort of threat to German society and to the Arian race.
Thus the speaker's contention that harmonious international relations are impossible
because of conflicting cultural values finds ample support from history. Yet, as compelling as
this argument might be, it nevertheless suffers from two notable deficiencies. First, in spite of
their differences the world's mainstream cultures tenets--particularly about the dignity of human life
all share certain fundamental and that they all agree upon these tenets,
at least tacitly. And people should judge other cultures against such universal standards.
Otherwise, the end result is that we find ourselves acquiescing in or even sanctioning war and
other such atrocities. Since all cultures share a universal ethos the speaker's rationale seems
inadequate. Discord occurs not only as a result of an ethos clash but also upon violation of the
universal ethos.
A second problem with the speaker's rationale is that it overlooks the fact that we can find
considerable discord within almost every culture. On a microcosmic scale we all observe
so-caUed infighting among members of the same church congregations, political factions, and
so forth. On a larger scale infighting is all too evident--from overt gang warfare and civil war to
covert corporate espionage and political back-stabbing. Thus even if all cultures were to share
the same ethos the promise of complete harmony would still be an illusory one. In short,
contentiousness seems to be part of human nature.
To sum up, I agree with the speaker that complete harmony among nations is unrealistic, but
not just because of conflicting cultural values; it runs contrary to human nature. Yet, the outlook
for international relations is not necessarily so grim. An enlightened understanding of the ethos
of other cultures, and of our own cultural bias, can foster a universal ethos of respect for
human dignity and life. The end result would be to stem, or at least minimize, discord among
nations and cultures.
























Issue 83
"Originality does not mean thinking something that was never thought before; it means putting
old ideas together in new ways."
Are people who make the greatest contributions to society those who pursue their personal
intellectual interests, as the speaker asserts? Or are they the ones who focus instead on areas
that are most likely to benefit society? I strongly agree with the speaker, for three reasons.
First of all, by human nature we are motivated to pursue activities in which we excel. To
compel people to focus their intellectual interests only on certain areas would be to force many
to waste their true talents. For example, imagine relegating today's preeminent astrophysicist
Stephen Hawking to researching the effectiveness of affirmative-action legislation in reducing
workplace discrimination. Admittedly, this example borders on hyperbole. Yet the aggregate
effect of realistic cases would be to waste the intellectual talents of our world's scholars and
researchers.
Secondly, it is unusual avenues of personal interest that most often lead to the greatest
contributions to society. Intellectual and scientific inquiry that breaks no new ground amount to
wasted time, talent, and other resources. History is laden with quirky claims of scholars and
researchers that turned out stunningly significant--that the sun lies at the center of our universe,
that time and space are relative concepts, that matter consists of discrete particles, that
humans evolved from other life forms, to name a few. One current area of unusual research is
terraforrning---creating biological life and a habitable atmosphere where none existed before.
This unusual research area does not immediately address society's pressing social problems.
Yet in the longer term it might be necessary to colonize other planets in order to ensure the
survival of the human race; and after all, what could be a more significant contribution to
society than preventing its extinction?
Thirdly, to adopt a view that runs contrary to the speaker's position would be to sanction
certain intellectual pursuits while proscribing others which smacks of thought control and
political oppression. It is dangerous to afford ultimate decision-making power about what
intellectual pursuits are worthwhile to a handful of regulators, legislators, or elitists, since they
bring to bear their own quirky notions about what is worthwhile, and since they are notoriously
susceptible to influence-peddling which renders them untrustworthy in any event. Besides,
history informs us well of the danger inherent in setting official research priorities. A telling
modern example involves the Soviet government's attempts during the 1920s to not only
control the direction and the goals of its scientists' research but also to distort the outcome of
that research----ostensibly for the greatest good of the greatest number of people. During the
1920s the Soviet government quashed certain areas of scientific inquiry, destroyed entire
research facilities and libraries, and caused the sudden disappearance of many scientists who
were viewed as threats to the state's authority. Not surprisingly, during this time period no
significant scientific advances occurred under the auspices of the Soviet government.
Those who would oppose the speaker's assertion might argue that intellectual inquiry in
certain areas, particularly the arts and humanities, amounts to little more than a personal quest
for happiness or pleasure, and therefore is of little benefit to anyone but the inquirer. This
specious argument overlooks the palpable benefits of cultivating the arts. It also ignores the
fact that earnest study in the humanities affords us wisdom to know what is best for society,
and helps us understand and approach societal problems more critically, creatively, and
effectively. Thus, despite the lack of a tangible nexus between certain areas of intellectual
inquiry and societal benefit, the nexus is there nonetheless.
In sum, I agree that society is best served when people are allowed unfettered freedom of
intellectual inquiry and research, and use that freedom to pursue their own personal interests.
Engaging one's individual talents in one's particular area of fascination is most likely to yield
advances, discoveries, and a heightened aesthetic appreciation that serve to make the world a
better and more interesting place in which to live.
























Issue 84
"Laws should not be stationary and fixed. Instead, they should be flexible enough to take
account of various circumstances, times, and places."
Does "originality" mean putting together old ideas in new ways, as the speaker contends,
rather than conjuring up truly new ideas? Although I agree that in various realms of human
endeavor, such as linguistics, law, and even the arts, so-called "new" or "original" ideas rarely
are. However, when it comes to the physical sciences originality more often entails chartering
completely new intellectual territory.
The notion that so-called "originality" is actually variation or synthesis of existing ideas finds
its greatest support in linguistics and in law. Regarding the former, in spite of the many words
in the modern English language that are unique to Western culture, modern English is derived
from, and builds upon, a variety of linguistic traditions--and ultimately from the ancient Greek
and Latin languages. Were we to insist on rejecting tradition in favor of purely modern
language we would have essentially nothing to say. The same holds true for all other modern
languages. As for law, consider the legal system in the United States, which is deeply rooted in
traditional English common-law principles of equity and justice. The system in the U.S.
requires that new, so-called "modern" laws be consistent with and indeed build upon--those
traditional principles.
Even in the arts--where one might think that true originality must surely reside--so-called
"new" ideas almost always embrace, apply, or synthesize what came earlier. For example,
most "modern" visual designs, forms, and elements are based on certain well-established
aesthetic ideals--such as symmetry, balance, and harmony. Admittedly, modern art works often
eschew these principles in favor of true originality. Yet, in my view the appeal of such works
lies primarily in their novelty and brashness. Once the ephemeral novelty or shock dissipates,
these works quickly lose their appeal because they violate fn:rnly established artistic ideals. An
even better example from the arts is modern rock-and-roll music, which upon first listening
might seem to bear no resemblance to dassical music traditions. Yet, both genres rely on the
same 12-note scale, the same notions of what harmonies are pleasing to the ear, the same
forms, the same rhythmic meters, and even many of the same melodies.
When it comes to the natural sciences, however, some new ideas are truly original while
others put established ideas together in new ways. One striking example of truly original
scientific advances involves what we know about the age and evolution of the Earth. In e~rlier
centuries the official Church of England called for a literal interpretation of the Bible, according
to which the Earth's age is determined to be about 6,000 years. If Western thinkers had simply
put these established ideas together in new ways the fields of structural and historical geology
might never have advanced further. A more recent example involves Einstein's theory of
relativity. Einstein theorized, and scientists have since proven empirically, that the pace of time,
and possibly the direction of time as well, is relative to the observer's motion through space.
This truth ran so contrary to our subjective, linear experience, and to previous notions about
time and space, that I think Einstein's theory can properly be characterized as truly original.
However, in other instances great advances in science are made by putting together current
theories or other ideas in new ways. For example, only by building on certain well-established
laws of physics were engineers able to develop silicon-based semiconductor technology. And,
only by struggling to reconcile the quantum and relativity theories have physicists now posited
a new so-called "string" theory, which puts together the two preexisting theories in a
completely new way.
To sum up, for the most part originality does not reject existing ideas but rather embraces,
applies, or synthesizes what came before. In fact, in our modern languages, our new laws, and
even our new art, existing ideas are reflected, not shunned. But, when it comes to science,
whether the speaker's claim is true must be determined on a case-by-case basis, with each
new theory or innovation.
























Issue 85
"It is always an individual who is the impetus for innovation; the details may be worked out by a
team, but true innovation results from the enterprise and unique perception of an individual."
Some measure of consistency and stability in the law is critical for any society to function.
Otherwise, I strongly agree with the speaker's assertion that laws should be flexible enough to
adapt to different circumstances, times and places. The law of marital property apdy illustrates
this point.
On the one hand, a certain measure of consistency, stability, and predictability in our laws is
required in order for us to understand our legal obligations and rights as we go about our
day-to-day business as a society. For example, in order for private industry to thrive,
businesses must be afforded the security of knowing their legal rights and obligations visi-vis
employees, federal regulatory agencies, and tax authorities--as well as their contractual rights
and duties vis-~t-vis customers and suppliers. Undue uncertainty in any one of these areas
would surely have a chilling effect on business. Moreover, some measure of consistency in the
legal environment from place to place promotes business expansion as well as interstate and
international commerce, all of which are worthwhile endeavors in an increasingly mobile
society.
On the other hand, rigid laws can result in unfairness if applied inflexibly in all places at all
times. The framers of the U.S. Constitution recognized the need both for a flexible legal
system and for flexible laws--by affording each state legal jurisdiction over all but interstate
matters. The framers understood that social and economic problems, as well as standards of
equity and fairness, can legitimately change over time and vary from region to region----even
from town to town. And our nation's founders would be pleased to see their flexible system that
promotes equity and fairness as it operates today.
Consider, for example, marital property rights, which vary considerably from state to state,
and which have evolved considerably over time as inflexible, and unfair, systems have given
way to more flexible, fairer ones. In earlier times husbands owned all property acquired during
marriage as well as property brought into the marriage by either spouse. Understandably, this
rigid and unfair system ultimately gave way to separate-property systems, which
acknowledged property rights of both spouses. More recently certain progressive states have
adopted even more flexible, and fairer, "community property" systems, under which each
spouse owns half of all property acquired during the marriage, while each spouse retains a
separate-property interest in his or her other property. Yet even these more egalitarian
community-property systems can operate unfairly whenever spouses contribute unequally;
accordingly, some community-property states are now modifying their systems for even
greater flexibility and fairness.
Thus, the evolution of state marital-property laws aptly illustrates the virtue of a legal system
that allows laws to evolve to keep pace with changing mores, attitudes, and our collective
sense of equity. This same example also underscores the point that inflexible laws tend to
operate unfairly, and properly give way to more flexible ones--as our nation's founders
intended.
























Issue 86
"The function of science is to reassure; the purpose of art is to upset. Therein lies the value of
each."
The speaker claims that individual enterprise, energy, and commitment, and not team-work,
provide the impetus for innovation in every case. In my view, although the claim is not without
merit, especially when it comes to business innovation, it overlooks the synergistic relationship
between individual effort and teamwork, particularly with respect to scientific innovations.
With respect to business innovation, I agree that it is the vision and commitment of key
individuals--such as a firm's founder or chief executive--from which businesses burgeon and
innovative products, services, and marketing and management strategies emerge. One
notable example involves the Apple Computer &bade following the departure of its founding
visionary Steve Jobs. It wasn't until Jobs reassumed the helm, once again injecting his unique
perception, insight, and infectious fervor, that the ailing Apple was able to resume its
innovative ways, thereby regaining its former stature in the computer industry. Admittedly, the
chief executives of our most successful corporations would no doubt concede that without the
cooperative efforts of their subordinates, their personal visions would never become reality. Yet,
these efforts are merely the carrying out of the visionary's marching orders.
Nevertheless, the speaker would have us accept a too-narrow and distorted view of how
innovation comes about, particularly in today's world. Teamwork and individual enterprise are
not necessarily inconsistent, as the speaker would have us believe. Admittedly, if exercised in
a self-serving manner--for example, through pilfering or back stabbing--individual enterprise
and energy can serve to thwart a business organization's efforts to innovate. However, if
directed toward the firm's goals these traits can motivate other team members, thereby
facilitating innovation. In other words, teamwork and individual enterprise can operate
synergistically to bring about innovation.
We must be especiaUy careful not to understate the role of teamwork in scientific innovation,
especially today. Important scientific innovations of the previous millennium might very well
have been products of the epiphanies and obsessions of individual geniuses. When we think
of the process of inventing something great we naturally conjure up a vision of the lone
inventor hidden away in a laboratory for months on end, in dogged pursuit of a breakthrough.
And this image is not entirely without empirical support. For example, Thomas Edison's early
innovations--including the light bulb, the television, and the phonograph--came about in
relative isolation, and solely through his individual persistence and commitment.
However, in today's world, sdentific innovation requires both considerable capital and
extensive teams of researchers. Admittedly, in all likelihood we will continue to encounter the
exceptional case---~ke Hewlett and Packard, or Jobs and Wozniak, whose innovations sprang
from two-man operations. But for the most part, scientific breakthroughs today typically occur
only after years of trial-and-error by large research teams. Even Thomas Edison relied more
and more on a team of researchers to develop new innovadons as his career progressed.
Thus the statement flies in the face of how most modern scientific innovations actually come
about today.
To sum up, I agree that, when it comes to the world of business, true innovation is possible
only through the imagination of the individual visionary, and his or her commitment to see the
vision through to its fruition. However, when it comes to scientific innovation, yesterday's
enterprising individuals have yielded to today's cooperative research teams--a trend that will
no doubt continue as scientific research becomes an increasingly expensive and complex
undertaking.
























Issue 87
"The study of an academic discipline alters the way we perceive the world. After studying the
discipline, we see the same world as before, but with different eyes."
The speaker maintains that the function of art is to "upset" while the function of science is to
"reassure," and that it is in these functions that the value of each lies. In my view, the speaker
unfairly generalizes about the function and value of art, while completely missing the point
about the function and value of science.
Consider first the intent and effect of art. In many cases artists set about to reassure, not to
upset. Consider the frescos of Fra Angelico and others monks and nuns of the late medieval
period, who sought primarily through their representations of the Madonna and Child to
reassure and be reassured about the messages of Christian redemption and salvation. Or
consider the paintings of impressionist and realist painters of the late 19th Century. Despite the
sharp contrast in the techniques employed by these two schools, in both genres we find
soothing, genteel, pastoral themes and images---certainly nothing to upset the viewer.
In other cases, artists set about to upset. For example, the painters and sculptors of the
Renaissance period, like the artists who preceded them, approached their art as a form of
worship. Yet Renaissance art focuses on other Christian images and themes--especially those
involving the crucifxiion and apocalyptic notions of judgment and damnation--which are clearly
"upsetting" and disconcerting, and clearly not reassuring. Or consider the works of two
important 20th-Century artists; few would argue that the surrealistic images by Salvador Dali or
the jarring, splashy murals by abstract painter Jackson Pollock serve to "upset," or at the very
least disquiet, the viewer on a visceral level.
When it comes to the function and value of science, in my view the speaker's assertion is
simply wrongheaded. The final objective of science, in my view, is to discover truths about our
world, our universe, and ourselves. Sometimes these discoveries serve to reassure, and other
times they serve to upset. For example, many would consider reassuring the various laws and
principles of physics which provide unifying explanations for what we observe in the physical
world. These principles provide a reassuring sense of order, even simplicity, to an otherwise
mysterious and perplexing world.
On the other hand, many scientific discoveries have dearly "upset" conventional notions
about the physical world and the universe. The notions of a sun-centered universe, that
humans evolved from lower primate forms, and that time is relative to space and motion, are
all disquieting notions to anyone whose belief system depends on contrary assumptions. And
more recently, researchers have discovered that many behavioral traits are functions of
individual neurological brain structure, determined at birth. This notion has "upset" many
professionals in fields such as behavioral psychology, criminology, mental health, and law,
whose work is predicated on the notion that undesirable human behavior can be
changed--through various means of reform and behavior modification.
In sum, the speaker over-generalizes when it comes to the function and value of art and
science both of which serve in some cases to reassure and in other cases to upset. In any
event, the speaker misstates the true function and value of science, which is to discover truths,
whether reassuring or upsetting.
























Issue 88
"Many problems of modern society cannot be solved by laws and the legal system because
moral behavior cannot be legislated."
I strongly agree that by studying any particular academic discipline we alter the way we
perceive the world. As intellectual neophytes we tend to polarize what we see as either right or
wrong, or as either good or bad. We also tend to interpret what we see by way of our emotions.
Once educated, we gain the capacity to see a broader spectrum of opinion and perspective,
and to see our own culture and even ourselves as a tapestry-like product of history.
Through the earnest pursuit of knowledge--particularly in history and literature--we reveal to
ourselves the flaws and foibles of other humans whose lives we study and read about. History
teaches us, for example, that demagogues whom society places on pedestals often fall under
the weight of their own prejudices, jealousies, and other character flaws. And, any serious
student of Shakespeare comes away from reading King Lear and Hamlet with a heightened
awareness of the tragically flawed ironic hero, and of the arbitrariness by which we distinguish
our heroes from our villains.
Through education we begin to see flaws not only in people but also in ideologies that we
had previously embraced on pure faith. A student of government and public policy learns that
many of the so-called "solutions" which our legislatures and jurists hand down to us from atop
their pedestals are actually Band-Aid comprises designed to appease opponents and pander
to the electorate. A philosophy student learns to recognize logical fallacies of popular ideas
and the rhetoric of our political parties, religious denominations, and social extremists. And, a
law student learns that our system of laws is not a monolithic set of truths but rather an
ever-changing reflection of whatever the society's current mores, values, and attitudes happen
to be.
While education helps us see the flawed nature of our previously cherished ideas,
paradoxically it also helps us see ideas we previously rejected out of hand in a different
light--as having some merit after all. Through education in public policy and law,
once-oppressive rules, regulations, and restrictions appear reasonable constraints on freedom
in light of legitimate competing interests. Through the objective study of different religious
institutions, customs, and faiths, a student learns to see the merits of different belief systems,
and to see the cultural and philosophical traditions in which they are rooted.
Education also helps us see our own culture through different eyes. As cultural neophytes
we participate unwittingly in our culture's own customs, rituals, and ceremonies--because we
see them as somehow sacrosanct. A student of sociology or cultural anthropology comes to
see those same customs, rituals, and ceremonies as tools which serve our psychological need
to belong to a distinct social group, and to reinforce that sense of belonging by honoring the
group's traditions. And, by reading the literary works of writers from bygone eras, a literature
student comes to see his or her own culture as a potential treasure trove of fodder for the
creative literary mind. For example, by studying Twain's works a student learns that Twain saw
19th-Century life along the Mississippi not as a mundane existence but as a framework for the
quintessential adventure story, and that we can similarly transform the way we see our own
culture.
Finally, education in the arts alters forever the way we perceive the aesthetic world around
us. Prior to education we respond instinctively, emotionally, and viscerally to the forms, colors,
and sounds of art. Post education we respond intellectually. We seek to appreciate what art
reveals about our culture and about humanity. We also seek to understand the aesthetic
principles upon which true art is founded. For instance, an earnest art student learns to see not
just pigments and shapes but also historical influences and aesthetic principles. An informed
listener of popular music hears not just the same pleasing sounds and pulsating rhythms as
their naive counterparts, but also the rhythmic meters, harmonic structure, and compositional
forms used by the great classical composers of previous centuries, and which provided the
foundation of modern music.
To sum up, through education we no longer see our heroes, leaders, and idols through the
same credulous eyes, nor do we see other humans and their ideas through the
black-and-white lens of our own point of view. In the final analysis, through education we come
not only to perceive the world differently but also to understand the subjective, and therefore
changeable, nature of our own perceptions.
























Issue 89
"The way students and scholars interpret the materials they work with in their academic fields
is more a matter of personality than of training. Different interpretations come about when
people with different personalities look at exactly the same objects, facts, data, or events and
see different things."
The speaker asserts that many laws are ineffective in solving society's problems because
moral behavior cannot be legislated. I agree with this assertion insofar as it relates to
constraints on certain personal freedoms. However, when it comes to the conduct of
businesses, I think that moral behavior not only can but must be legislated for the purpose of
alleviating societal problems.
Morality laws that impinge upon freedom of choice about our personal lives--to control what
we do with and to ourselves--simply do not work in a democratic society. People always find
ways to circumvent such laws, which ultimately give way to more lenient laws that
acknowledge personal freedom of choice. The failed Prohibition experiment of the 1930s is
perhaps the paradigmatic example of this. And we are slowly learning history's lesson, as aptly
demonstrated by the recognition of equal rights for same-sex partners, and current trends
toward legalization of physician-assisted suicide and the medicinal use of marijuana. In short,
history informs us that legislating morality merely for morality's sake simply does not work.
Morality laws impinging on personal freedoms are not made any more useful or effective by
purporting to serve the greater good of society, because on balance their costs far outweigh
their benefits. For instance, those who defend the cfiminalization of drug use cite a variety of
harms that result from widespread addiction: increased incidence of domestic violence,
increased burden on our health-care and social-welfare systems, and diminished productivity
of addicts. However, these defenders overlook the fact that outlawing addictive substances
does not prevent, or even deter, people from obtaining and using them. It only compels users
to resort to theft and even violent means of procuring drugs, adding to the economic costs of
enforcement, prosecution, and punishment. In short, the costs of proscription outweigh the
benefits.
In sharp contrast to personal behavior, the behavior of businesses can and must be
controlled through legislation. Left unfettered, businesses tend to act on behalf of their own
financial interest, not on behalf of the society at large. And when excessive business profits
accrue at the expense of public health and safety, in my view business has behaved immorally.
Examples of large-scale immoral behavior on the part of businesses abound. For example,
although technology makes possible the complete elimination of polluting emissions from
automobiles, auto manufacturers are unwilling to voluntarily make the short-term sacrifices
necessary to accomplish this goal. Tobacco companies have long known about the health
hazards of smoking cigarettes; yet they weigh the costs of defending law suits against the
profit from cigarette sales, and continue to cater to nicotine addicts. And when given the
chance, many manufacturers will exploit underage or underprivileged workers to reduce labor
costs, thereby enhancing profits. In short, only govemment holds the regulatory and
enforcement power to impose the standards needed to ensure moral business behavior.
In sum, whether legislating morality is effective or even appropriate depends on whether the
behavior at issue involves personal freedom or public duty. Legislating personal moral
behavior is neither practicable nor proper in a democratic society. On the other hand,
legislating business morality is necessary to ensure public health and safety.
























Issue 90
"We live under the illusion that we know what we want, when actually we merely want what we
are supposed to want."
I strongly disagree that personality is the key to how a student or scholar interprets the
material with which he or she works. Whether those materials be facts, events, data, or
observations, in my view the key factor in their interpretation is a person's training and
educational background.
Assuming that by personality the speaker embraces such personal attributes as individual
temperament, disposition and general mood, and outlook, it seems to me that personality has
little bearing on how students and scholars interpret the materials with which they work.
Admittedly, whether an individual tends to be an optimist or a pessimist might have some
beating on interpretation. For instance, an archeology student with a generally sanguine
outlook toward life might respond to a lengthy yet unsuccessful search for certain artifacts as
discovery and progress--insofar as certain possibilities have been eliminated, bringing us
closer to affirmative discoveries. In contrast, an archeology student with a generally
pessimistic outlook might condude that the same effort was in vain and that nothing has been
learned or otherwise gained. Yet it strikes me that these reactions are emotional ones that
have nothing to do with intellectual interpretation.
In sharp contrast, one's educational background and training can serve as a strong influence
on how one interprets historical events involving human affairs, statistical data, and especially
art. With respect to human affairs, consider the centuries-old imperialist policies of Great
Britain. A student of political science might interpret British imperialism as a manifestation of
that nation's desire for political power and domination over others. A student of economics
might see it as a strategy to gain control over economic resources and distribution channels for
goods. A sociology or anthropology student might see it as an assimilation of culture. And, a
student of theology or religion might interpret the same phenomenon as an attempt, well
intentioned or otherwise, to proselytize and to impose certain beliefs, rituals, and customs on
others.
Educational training and background also affects how students and scholars interpret
seemingly objective statistical data. It is crucial here to distinguish between numbers
themselves, which are not subject to varying interpretations, from what the numbers
signify--that is, what conclusions, prescriptions, or lessons we might come away with. Consider,
for example, a hypothetical increase in the rate of juvenile crime in a particular city. Although
the percent change itself might be subject to only one reasonable meaning, what the change
signifies is open to various interpretations. A sociologist might interpret this data as an
indication of deteriorating family unit or community. A student of public policy or government
might see this statistic as an indication that current legislation fails to implement public policy
as effectively as it could. And a student of law or criminal justice might interpret the same
statistic as a sign of overburdened courts or juvenile detention facilities.
Finally, when it comes to how students and scholars interpret art, training and educational
background play an especially significant role. After all, while facts and figures are to some
extent objective, the meaning Of art is an inherently subjective, and highly personal, matter. A
business student might interpret a series of art works as attempts by the artist to produce
viable products for sale in the marketplace. However, a theology student might eschew such a
cold and cynical interpretation, seeing instead an expression of praise, a celebration of life, a
plea for grace, or a struggle to come to terms with mortality. Even art students and scholars
can interpret the same art differently, depending on their training. A student of art history might
see a particular work as the product of certain artistic influences, while a student of art theory,
composition, and technique might view the same work as an attempt to combine color foi
visual impact, or as an experiment with certain brush-stroke techniques.
To sum up, I concede that as students and scholars our working "materials"--facts, data,
objects, and events--are open to subjective interpretation in terms of what they teach us.
However, what our materials teach us is a function of what we've already learned, and has little
if anything to do with our personal basket of emotions and moods called "personality."
























Issue 91
"As we acquire more knowledge, things do not become more comprehensible, but more
complex and more mysterious."
Does knowledge render things more comprehensible, or more complex and mysterious? In
my view the acquisition of knowledge brings about all three at the same time. This paradoxical
result is aptly explained and illustrated by a number of advances in our scientific knowledge.
Consider, for example, the sonar system on which blind bats rely to navigate and especially
to seek prey. Researchers have learned that this system is startlingly sophisticated. By
emitting audible sounds, then processing the returning echoes, a bat can determine in a
nanosecond not only how far away its moving prey is but also the prey's speed, direction, size
and even specie! This knowledge acquired helps explain, of course, how bats navigate and
survive. Yet at the same time this knowledge points out the incredible complexity of the
auditory and brain functions of certain animals, even of mere humans, and creates a certain
mystery and wonder about how such systems ever evolved organically.
Or consider our knowledge of the universe. Advances in telescope and space-exploration
technology seem to corroborate the theory of a continually expanding universe that began at
the very beginning of time with a "big bang." On one level this knowledge, assuming it qualifies
as such, helps us comprehend our place in the universe and our ultimate destiny. Yet on the
other hand it adds yet another chapter to the mystery about what existed before time and the
universe.
Or consider the area of atomic physics. The naked human eye perceives very little, of
course, of the complexity of matter. To our distant ancestors the physical world appeared
simple--seemingly comprehensible by means of sight and touch. Then by way of scientific
knowledge we learned that all matter is comprised of atoms, which are further comprised of
protons, neutrons, and electrons. Then we discovered an even more basic unit of matter called
the quark. And now a new so-called "string" theory posits the existence of an even more
fundamental, and universal, unit of matter. On the one hand, these discoveries have rendered
things more comprehensible, by explaining and reconciling empirical observations of how
matter behaves. The string theory also reconciles the discrepancy between the quantum and
wave theories of physics. On the other hand, each discovery has in turn revealed that matter is
more complex than previously thought. In fact, the string theory, which is theoretically sound,
calls for seven more dimensions---in addition to the three we already know about! I'm
hard-pressed to imagine anything more complex or mysterious.
In sum, the statement overlooks a paradox about knowledge acquired, at least when it
comes to understanding the physical world. When through knowledge a thing becomes more
comprehensible and explainable we realize at the same time that it is more complex and
mysterious than previously thought.
























Issue 92
"It is a grave mistake to theorize before one has data."
Is it a "grave mistake" to theorize without data, as the speaker contends? I agree insofar as
to theorize before collecting sufficient data is to risk tainting the process of collecting and
interpreting further data. However, in a sense the speaker begs the question, by overlooking
the fact that every theory requires some data to begin with. Moreover, the claim unfairly
ignores equally grave consequences of waiting to theorize until we obtain too much data.
In one important respect I agree with the speaker's contention. A theory conjured up without
the benefit of data amounts to little more that the theorist's hopes and desires-- what he or she
wants to be true and not be true. Accordingly, this theorist will tend to seek out evidence that
supports the theory, and overlook or avoid evidence that refutes it. One telling historical
example involves theories about the center of the Universe. Understandably, we ego-driven
humans would prefer that the universe revolve around us. Early theories presumed so for this
reason, and subsequent observations that ran contrary to this ego-driven theory were ignored,
while the observers were scorned and even vilified.
By theorizing before collecting data the theorist also runs that risk of interpreting that data in
a manner which makes it appear to lend more credence to the theory than it actually does.
Consider the theory that the Earth is flat. Any person with a clear view of the horizon must
agree in all honesty that the evidence does not support the theory. Yet prior to Newtonian
physics the notion of a spherical Earth was so unsettling to people that they interpreted the
arc-shaped horizon as evidence of a convex, yet nevertheless "flattish," Earth.
Despite the merits of the speaker's claim, I find it problematic in two crucial respects. First,
common sense informs me that it is impossible to theorize in the first place without at least
some data. How can theorizing without data be dangerous, as the speaker con tends, if it is not
even possible? While a theory based purely on fantasy might ultimately be born out by
empirical observation, it is equally possible that it won't. Thus without prior data a theory is not
worth our time or attention. Secondly, the speaker's claim overlooks the inverse problem: the
danger of continuing to acquire data without venturing a theory based on that data. To
postpone theorizing until all the data is in might be to postpone it forever. The danger lies in the
reasons we theorize and test our theories: to solve society's problems and to make the world a
better place to live. Unless we act timely based on our data we render ourselves impotent. For
example, governments tend to respond to urgent social problems by establishing agencies to
collect data and think-tanks to theorize about causes and solutions. These agencies and
think-tanks serve no purpose unless they admit that they will never have all the data and that
no theory is foolproof, and unless timely action is taken based on the best theory currendy
available--before the problem overwhelms us.
To sum up, I agree with the speaker insofar as a theory based on no data is not a theory but
mere whimsy and fancy, and insofar as by theorizing first we tend to distort the extent to which
data collected thereafter supports our own theory. Nevertheless, we put ourselves in equal
peril by mistaking data for knowledge and progress, which require us not only to theorize but
also to act upon our theories with some useful end in mind.


























Issue 93
"Scandals---whether in politics, academia, or other areas---can be useful. They focus our
attention on problems in ways that no speaker or reformer ever could."
Are scandals useful in calling our attention to important problems, as this statement
suggests? I agree that in many cases scandals can serve to reveal larger problems that a
community or society should address. On the other hand, scandals can sometimes distract us
from more important societal issues.
On the one hand, scandals can sometimes serve to call our attention to pervasive social or
political problems that we would otherwise neglect. Perhaps the paradigmatic modern example
is the Watergate scandal. Early in that scandal it would have been tempting to dismiss it as
involving one isolated incidence of underhanded campaign tactics. But, in retrospect the
scandal forever increased the level of scrutiny and accountability to which our public officials
are held, thereby working a significant and lasting benefit to our society. More recently, the
Clinton-Gore fundraising scandal sparked a renewed call for campaign-finance reform. In fact
the scandal might result in the passage of a congressional bill outlawing private campaign
contributions altogether, thereby rendering presidential candidates far less susceptible to
undue influence of special-interest groups. Our society would be the dear beneficiary of such
reform. Surely, no public speaker or reformer could have called our nation's collective attention
to the problem of presidential misconduct unless these two scandals had surfaced.
On the other hand, scandals can sometimes serve chiefly to distract us from more pressing
community or societal problems. At the community level, for example, several years ago the
chancellor of a university located in my city was expelled from office for misusing university
funds to renovate his posh personal residence. Every new development during the scandal
became front-page news in the campus newspaper. But did this scandal serve any useful
purpose? No. The scandal did not reveal any pervasive problem with university accounting
practices. It did not result in any sort of useful system-wide reform. Rather, it was merely one
incidence of petty misappropriation. Moreover, the scandal distracted the university community
from far more important issues, such as affu'mative action and campus safety, which were
relegated to the second page of the campus news paper during the scandal.
Even on a societal level, scandals can serve chiefly to distract us from more important
matters. For example, time will tell whether the Clinton sex scandal will benefit our political,
social, or legal system. Admittedly, the scandal did call our attention to certain issues of federal
law. It sparked a debate about the powers and duties of legal prosecutors, under the
Independent Counsel Act, vis-i-vis the chief executive while in and out of office. And the
various court rulings about executive privilege and immunity WIU serve useful legal
precedents for the furore. Even the impeachment proceedings xxhll no doubt provide useful
procedural precedent at some future time. Yet on balance, it seems to me that the deleterious
effects of the scandal in terms of the financial expense to taxpayers and the various harms to
the many individuals caught up in the legal process---outweigh these benefits. More
importantly, for more that a year the scandal served chiefly to distract us from our most
pressing national and global problems, such as the Kosovo crisis, our social-security crisis,
and health-care reform, to name just a few.
In sum, I agree that scandals often serve to flag important socio-political problems more
effectively than any speaker or reformer can. However, whether a scandal works more benefit
than harm to a community or society must be addressed on a case-by-case basis.
























Issue 94
"Practicality is now our great idol, which all powers and talents must serve. Anything that is not
obviously practical has little value in today's world."
In today's world is practicality our idol---one which all powers and talents must serve. While
this claim has considerable merit with respect to most areas of human endeavor--including
education, art, and politics--I take exception with the claim when it comes to the direction of
scientific research today.
Practicality seems clearly to be the litmus test for education today. Grade-schoolers are
learning computer skills right along with reading and writing. Our middle and high schools are
increasingly cutting arts education, which ostensibly has less practical value than other course
work. And, more and more college students are majoring in technical fields for the purpose of
securing lucrative jobs immediately upon graduation. Admittedly, many college students still
advance to graduate-level study; yet the most popular such degree today is the MBA; after all,
business administration is fundamentally about practicality and pragmatism that is, "getting
the job done" and paying attention to the "bottom line."
Practicality also dictates what sort of art is produced today. Most new architecture today is
driven by functionality, safety, and cost; very few architectural masterpieces find their way past
the blueprint stage anymore. The content of today's feature films and music is driven entirely
by demographic considerations--that is, by pandering to the interests of 18-35 year olds, who
account for most ticket and CD sales. And, the publishing industry today is driven by
immediate concern to deliver viable products to the marketplace. The glut of how-to books in
our bookstores today is evidence that publishers are pandering to our practicality as well. It
isn't that artists no longer create works of high artistic value and integrity. Independent record
labels, filmmakers, and publishing houses abound today. It's just that the independents do not
thrive, and they constitute a minuscule segment of the market. In the main, today's real-estate
developers, entertainment moguls, and publishing executives are concerned with practicality
and profit, and not with artistic value and integrity.
Practicality is also the overriding concern in contemporary politics. Most politicians seem
driven today by their interest in being elected and reelected that is, in short-term survival
rather than by any sense of mission, or even obligation to their constituency or country.
Diplomatic and legal maneuverings and negotiations often appear intended to meet the
practical needs of the parties involved minimizing costs, preserving options, and so forth.
Those who would defend the speaker might claim that it is idealists--not pragmatists who
sway the masses, incite revolutions, and make political ideology reality. Consider idealists
such as the America's founders, or Mahatma Gandhi, or Martin Luther King. Had these
idealists concerned themselves with short-term survival and immediate needs rather than with
their notions of an ideal society, the United States and India might still be British colonies, and
African-Americans might still be relegated to the backs of buses. Although I concede this point,
the plain fact is that such idealists are far fewer in number today.
On the other hand, the claim amounts to an overstatement when it comes to today's
scientific endeavors. In medicine the most common procedures today are cosmetic; these
procedures strike me as highly impractical, given the health risks and expense involved.
Admittedly, today's digital revolution serves a host of practical concerns, such as
communicating and accessing information more quickly and efficiently. Much of chemical
research is also aimed at practicality--at providing convenience and enhancing our immediate
comfort. Yet, in many other respects scientific research is not driven toward immediate
practicality but rather toward broad, long-term objectives: public health, quality of life, and
environmental protection.
In sum, practicality may be our idol today when it comes to education, the arts, and politics;
but with respect to science I find the claim to be an unfair generalization. Finally, query whether
the claim begs the question. After all, practicality amounts to far more than meeting immediate
needs; it also embraces long-term planning and prevention aimed at ensuring our future
quality of life, and our very survival as a species.
























Issue 95
"It is easy to welcome innovation and accept new ideas. What most people find difficult,
however, is accepting the way these new ideas are put into practice."
The speaker maintains that it is easy to accept innovation and new ideas, yet difficult to
accept how they are put to use. In my view the speaker has it backwards when it comes to
socio-political ideas, at least in our democratic society. Nevertheless, I tend to agree with the
speaker insofar as scientific innovation is concerned.
In the areas of politics and law, new ideas are not often easily accepted. More often than not,
the status quo affords people a measure of security and predictability in terms of what they can
expect from their government and what rights and duties they have under the law. The
civil-fights movement of the 1960s aptly illustrates this point. The personal freedoms and rights
championed by leading civil-rights leaders of that era threatened the status quo, which
tolerated discrimination based on race and gender, thereby sanctioning prejudice of all kinds.
The resulting civil unrest, especially the protests and riots that characterized the late 1960s,
was dear evidence that new ideas were not welcome. And today those who advocate gay and
lesbian rights are encountering substantial resistance as well, this time primarily from certain
religious quarters.
Yet once society grows to accept these new ideas, it seems that it has an easier time
accepting how they are put into practice. The explanation for this lies in the fact that our
system of laws is based on legal precedent. New ideas must past muster among the
government's legislative, judicial, and executive branches, and ultimately the voters, before
these ideas can be codified, implemented and enforced. Once they've passed the test of our
democratic and legal systems, they are more readily welcomed by the citizenry at large.
In contrast, consider innovations in the natural sciences. It seems that we universally
embrace any new technology in the name of progress. Of course there are always in formed
dissenters with legitimate concerns. For example, many scientists strongly opposed the
Manhattan Project, by which nuclear warfare was made possible. Innovations involving
alternative energy sources meet with resistance from those who rely on and profit from fossil
fuels. Some sociologists and psychologists claim that advances in Internet technology WIU
alienate society's members from one another. And opponents of genetic engineering predict
certain deleterious social and political consequences.
Yet the reasons why these dissenters oppose certain innovations have to do with their
potential applications and uses, not with the renovations themselves. Edward Teller, the father
of the atom bomb, foresaw the benefits of atomic energy, yet understood the grave
consequences of applying the technology instead for destruction. Innovations involving
alternative energy sources meet with resistance from many businesses because of their
potential application in ways that will threaten the financial interests of these businesses. And
those who would impede advances in Internet technology fear that consumers and businesses
will use the technology for crass commercialism, exploitation, and white-collar crime, rather
than for the sorts of educational and communication purposes for which it was originally
designed. Finally, opponents of genetic engineering fear that, rather than using it to cure birth
defects and prevent disease, the technology will be used instead by the wealthy elite to breed
superior offspring, thereby causing society's socioeconomic gap to widen even further, even
resulting in the creation of a master race.
In sum, when it comes to new social and political ideas, the power and security afforded by
the status quo impedes initial acceptance, yet by the same token ensures that the ideas will be
applied in ways that will be welcome by our society. On the other hand, it seems that scientific
innovation is readily embraced yet meets stronger resistance when it comes to applying the
innovation.
























Issue 96
"Success, whether academic or professional, involves an ability to survive in a new
environment and--, eventually, --to change it."
Do academic and professional success both involve surviving in a new environment and
eventually changing it, as the speaker claims? Regarding academic success, in my view the
speaker overstates the significance of environment. Regarding professional success the
speaker's threshold claim that adaptation is necessary has considerable merit; however, the
extent to which professional success also entails shaping the environment in which the
professional operates depends on the type of profession under consideration.
Turning fzrst to academic success, I concede that as students advance from grade school to
high school, then to college, they must accustom themselves not just to new curricula but also
to new environments--mompfised of campuses, classmates, teachers, and teaching methods.
The last item among this list is proving particularly significant in separating successful students
from less successful ones. As computers and the Internet are becoming increasing important
tools for learning academic skills and for research, they are in effect transforming our learning
environment--at every educational level. Students who fail to adapt to this change will fred
themselves falling behind the pace of their peers.
Otherwise, the speaker's prescription for academic success makes little sense. Aside from
the environmental variables listed above, academia is a relatively staid environment over time.
The key ingredients of academic success have always been, and will always be, a student's
innate abilities and the effort the student exerts in applying those abilities to increasingly
advanced course work. Besides, to assert that academic success involves changing one's
environment is tantamount to requiring that students alter their school's teaching methods or
physical surroundings in order to be successful students--an assertion that nonsensically
equates academic study with educational reform.
Turning next to professional success, consider the two traditional professions of law and
medicine. A practicing lawyer must stay abreast of new developments and changes in the law,
and a physician must adapt to new and improved medical devices, and keep pace with new
and better ways to treat and prevent diseases. Otherwise, those professionals risk losing their
competency, and even their professional licenses. However, this is not to say that success in
either profession also requires that the practitioner help shape the legal, medical, technological,
or ethical environment within which these professions operate. To the contrary, undue time and
energy devoted to advancing the profession can diminish a practitioner's effectiveness as such.
In other words, legal and medical reform is best left to former practitioners, and to legislators,
jurists, scientists, and academicians. Thus the speaker's claim unfairly overrates the ability to
change one's professional environment as a key ingredient of professional success.
In contrast, when it comes to certain other professions, such as business and scientific
research, the speaker's claim is far more compelling. Our most successful business leaders
are not those who merely maximize shareholder profits, but rather those who envision a lasting
contribution to the business environment and to society, and realize that vision. The industrial
barons and information-age visionaries of the late 19th and 20th Centuries, respectively, did
not merely adapt to the winds of business and technological change imposed upon them. They
altered the direction of those winds, and to some extent were the fans that blew those winds.
Similarly, ultimate success in scientific research lies not in reacting to new environments but in
shaping future ones--by preventing disease, inventing products that transform the ways in
which we live and work, and so forth. Perhaps the most apt example is the field of space
exploration, which has nothing to do with adapting to new environments, and everything to do
with discovering them and making them available to us in the first place.
To sum up, the speaker's daim has merit insofar as any individual must adapt to new
environments to progress in life and to survive in a dynamic, ever-changing world. However,
the speaker's sweeping definition of success overlooks certain crucial distinctions between
academics and the professions, and between some professions and others.
























Issue 97
"The function of art is not to keep pace with science and technology but rather to provide an
escape from these forces."
I strongly disagree with this statement, on two counts. First, in my observation art embraces
the current state of science and technology more often than it rejects or opposes it. More
significantly, however, I find the speaker's suggestion that the function of art relates to science
and technology to be misguided.
In general, it would appear that art is more likely motivated by an interest in keeping pace
with science and technology than by a desire to break from it. Particularly in architecture,
where engineering is part-and-parcel of the art, new creations take full advantage of new
technologies. For example, the burgeoning sted industry of the Industrial Age made possible
for the first time the erection of skyscrapers. And rather than avoiding the technology,
architects embraced it. But did the artists who designed our modern office buildings view their
"function" as keeping pace with technology? Probably not. Instead, the technology simply
provided a larger canvas and an expanded array of tools with which to create their art.
Admittedly, the arts-and-crafts architectural movement during the late 19th Century was a
conscious reaction to the Industrial Age's influence on architectural processes and materials,
as well as the overly ornate Victorian style. However, this break from technology is the
historical exception to the rule. Besides, Frank Lloyd Wright, who championed the
arts-and-crafts style during the first half of the 20th Century, eagerly exploited many of the
building materials and engineering processes which new technology offered at the time.
Eagerness among artists to embrace new technology, as opposed to providing an escape
from it, is not limited to architecture. Much of modem abstract painting seems to convey a
boldness and daring that characterizes modern technological progress. And in contemporary
sculpture one finds the widespread use of the new materials of modern chemistry-from plastics
to synthetic fabrics. Again, however, to suggest that the "function" of modern abstract art or
contemporary sculpture is to keep pace with science seems wrongheaded. It makes far more
sense to view the relationship between art and science as one in which the technologies are
tools which artists use to augment their palettes.
Admittedly, some works of art would appear to reject, or at least provide a respite from,
science and technology. One example is the modern minimalist movement, which one might
interpret as a reaction against, or a break from, the increasingly complex modern industrial age.
However, I am hard-pressed to think of any other significant art form or movement that dearly
seemed motivated by a desire to break free of science and technology.
Moreover, the speaker's concern for whether art's function is to embrace or oppose science
and technology begs the question, for the final objective of art lies instead in its ability to
convey a society's values, ideals, and concerns. The pyramids and obelisks of the ancient
world, as well as the great cathedrals of Renaissance Europe, including the murals and
sculptures in and around them, reflected a societal preoccupation with transcending the
human condition. During the Medieval period the most important architectural form was the
castle, which reflected an overriding concern for military security during a time of relative
anarchy. During the 18th and 19th Centuries, an emerging genteel upper-middle class saw
itself reflected in the bourgeois themes of impressionists such as Renoir and Monet. The
machine-tooled art deco style of the early 20th Century reflected industrial society's penchant
for technological progress, while modern abstract art mirrors the frenetic world that has
resulted from that progress.
In sum, while I agree that art is indeed influenced by science and technology, this influence
is mainly in the materials and processes that science makes available to the artist. The final
objective of art, far from having any beating on science or technology per se, is to hold a mirror
up to the society in which the artist operates.
























Issue 98
"As long as people in a society are hungry or out of work or lack the basic skills needed to
survive, the use of public resources to support the arts is inappropriate---and, perhaps, even
cruel---when one considers all the potential uses of such money."
The speaker asserts that using public resources to support the arts is unjustifiable in a
society where some people go without food, jobs, and basic survival skills. It might be tempting
to agree with the speaker on the basis that art is not a fundamental human need, and that
government is not entirely trustworthy when it comes to its motives and methods. However, the
speaker overlooks certain economic and other societal benefits that accrue when government
assumes an active role in supporting the arts.
The implicit rationale behind the speaker's statement seems to be that cultural enrichment
pales in importance compared to food, clothing, and shelter. That the latter needs are more
fundamental is indisputable; after all, what starving person would prefer a good painting to
even a bad meal? Accordingly, I concede that when it comes to the use of public resources it is
entirely appropriate to assign a lower priority to the arts than to these other pressing social
problems. Yet, to postpone public arts funding until we completely eliminate unemployment
and hunger would be to postpone arts funding forever; any informed person who believes
otherwise is envisioning a pure socialist state where the government provides for all of its
citizens' needs--a vision which amounts to fantasy.
It might also be tempting to agree with the speaker on the basis that arts patronage is
neither an appropriate nor a necessary funcuon of government. This argument has
considerable merit, in three respects. First, it seems ill-conceived to relegate decision and
choices about arts funding to a handful of bureaucrats, who are likely to decide based on their
own quirky notions about art, and whose decisions might be susceptible to influence-peddling.
Second, private charity and philanthropy appear to be alive and well today. For example, year
after year the Public Broadcasting System is able to survive, and even thrive, on donations
from private foundations and individuals. Third, government funding requires tax dollars from
our pockets--leaving us with less disposable dollars with which to support the arts directly and
more efficiently than any bureaucracy ever could.
On the other hand are two compelling arguments that public support for the arts is desirable,
whether or not unemployment and hunger have been eliminated. One such argument is that
by allocating public resources to the arts we actually help to solve these social problems.
Consider Canada's film industry, which is heavily subsidized by the Canadian government, and
which provides countless jobs for film-industry workers as a result. The Canadian government
also provides various incentives for American productoion companies to f~n and produce their
movies in Canada. These incentives have sparked a boon for the Canadian economy, thereby
sumulating job growth and wealth that can be applied toward education, job training, and
social programs. The Canadian example is proof that public arts support can help solve the
kinds of social problems with which the speaker is concerned.
A second argument against the speaker's position has to do with the function and ultimate
objectives of art. Art serves to lift the human spirit and to put us more in touch with our feelings,
foibles, and fate in short, with our own humanity. With a heightened sensitivity to the human
condition, we become more others-oriented, less self-centered, more giving of ourselves. In
other words, we become a more charitable society--more willing to give to those less fortunate
than ourselves in the ways with which the speaker is concerned. The speaker might argue, of
course, that we do a disservice to others when we lend a helping hand by enabling them to
depend on us to survive. However, at the heart of this specious argument lies a certain
coldness and lack of compassion that, in my view, any society should seek to discourage.
Besides, the argument leads inexorably to certain political, philosophical, and moral issues
that this brief essay cannot begin to address.
In the final analysis, the beneficiaries of public arts funding are not limited to the elitists who
stroll through big-city museums and attend symphonies and gallery openings, as the speaker
might have us believe. Public resources allocated to the arts create jobs for artists and others
whose livelihood depends on a vibrant, rich culture--just the sort of culture that breeds
charitable concern for the hungry, the helpless, and the hapless.
























Issue 99
"The goal of politics should not be the pursuit of an ideal, but rather the search for common
ground and reasonable consensus."
Should educators focus equally on enriching students' personal lives and on job preparation,
as the speaker contends? In my view, preparing students for the mundane aspects of work
should be secondary to providing a broader education that equips students with historical and
cultural perspective, as well as thoughtful and principled personal value systems and priorities.
Paradoxically, it is through the liberal studies, which provide these forms of personal
enrichment, that students can also best prepare for the world of work.
One reason why educators should emphasize personal enrichment over job preparation is
that rote technical knowledge and skill do not help a student determine which goals in life are
worthwhile and whether the means of attaining those goals are ethically or morally acceptable.
Liberal studies such as philosophy, history, and comparative sociology enable students to
develop thoughtful and consistent value systems and ethical standards, by which students can
determine how they can best put their technical knowledge and skills to use in the working
world. Thus, by nurturing the development of thoughtful personal value systems, educators
actually help prepare students for their jobs and careers.
Another reason why educators should emphasize personal enrichment over job preparation
is that specific knowledge and skills needed for jobs are changing more and more quickly.
Thus it would be a waste of our education system to focus on specific knowledge and skills
that will soon become obsolete--at the expense of providing a lasting and personally satisfying
educational experience. It seems more appropriate today for employers to provide the training
our work force needs to perform their jobs, freeing up our educators to help enrich students'
lives in ways that will serve them in any walk of life.
A third reason why educators should emphasize personally enriching course
work--particularly anthropology, sociology, history, and political philosophy--is that these
courses help students understand, appreciate, and respect other people and their viewpoints.
As these students grow into working adults they will be better able to cooperate, compromise,
understand various viewpoints, and appreciate the rights and duties of coworkers, supervisors,
and subordinates. Rote technical knowledge and skill do little to help us get along with other
people.
Admittedly, certain aspects of personal enrichment, especially spirituality and religion,
should be left for parents and churches to provide; after all, by advocating teachings of any
particular religion, public educators undermine our basic freedom of religion. Yet it is perfectly
appropriate, and useful, to inform students about various religious beliefs, customs and
institutions. Learning about different religions instills respect, tolerance, and understanding.
Moreover, students grow to appreciate certain fundamental virtues, such as compassion,
virtue, and humility, which all major religions share. Through this appreciation students grow
into adults who can work well together toward mutually agreed-upon goals.
In sum, it is chiefly through the more personally enriching Liberal studies that educators help
students fully blossom into well-rounded adults and successful workers. There will always be a
need to tram people for specific jobs, of course. However, since knowledge is advancing so
rapidly, employers and job-training programs are better equipped to provide this function,
leaving formal educators free to provide a broader, more personally enriching education that
will serve students throughout their lives and in any job or career.
























Issue 100
"Technology creates more problems than it solves, and may threaten or damage the quality of
life."
Whether technology enhances or diminishes our overall quality of life depends largely on the
type of technology one is considering. While mechanical automation may have diminished our
quality of life on balance, digital automation is doing more to improve life than to undermine its
quality.
First consider mechanical automation, particularly assembly-line manufacturing. With
automation came a loss of pride in and alienation from one's work. In this sense, automation
both diminished our quality of life and rendered us slaves to machines in our inability to
reverse "progress." Admittedly, mechanical automation spawned entire industries, creating
jobs, stimulating economic growth, and supplying a plethora of innovative conveniences.
Nevertheless, the sociological and environmental price of progress may have outweighed its
benefits.
Next consider digital technology. Admittedly, this newer form of technology has brought its
own brand of alienation, and has adversely affected our quality of life in other ways as well. For
example, computer automation, and especially the Internet, breeds information overload and
steals our time and attention away from family, community, and coworkers. In these respects,
digital technology tends to diminish our quality of life and create its own legion of human
slaves.
On the other hand, by relegating repetitive tasks to computers, digital technology has
spawned great advances in medicine and physics, helping us to better understand the world,
to enhance our health, and to prolong our lives. Digital automation has also emancipated
architects, artists, designers, and musicians, by expanding creative possibilities and by saving
time. Perhaps most important, however, information technology makes possible universal
access to information, thereby providing a democratizing influence on our cultul:e.
In sum, while mechanical automation may have created a society of slaves to modern
conveniences and unfulfRling work, digital automation holds more promise for improving our
lives without enslaving us to the technology.


























Issue 101
"The material progress and well-being of one country are necessarily connected to the
material progress and well-being of all other countries."
I strongly agree that each nation's progress and well-being are now tied to the progress and
well-being of other nations. In the pursuit of its citizens' economic and social welfare, as well
as their safety, security, and health, each nation today creates a ripple effect-- sometimes
beneficial and sometimes detrimentS---felt around the globe. And, although I disagree that our
global interconnectedness is necessary, in all likelihood it is with us to stay.
Turning first to economic progress and well-being, the economic pursuits of any nation today
are not merely connected to but actually interwoven with those of other nations. In some cases
one nation's progress is another's problem. For instance, strong economic growth in the U.S.
attracts investment in U.S. equities from foreign investors, to the detriment of foreign business
investments, which become less attractive by comparison. Or consider the global
repercussions of developed nations' over-consumption of natural resources mined from
emerging nations. Having been exploited once for the sake of fueling the high standard of
living in the developed world, emerging nations are now being pressured to comply with the
same energy conservation policies as their exploiters--even though they did not contribute to
the problems giving rise to these policies, and cannot afford to make the sacrifices involved.
Finally, although international drug trafficking provides an economic boon for the rogue nations
supplying the drugs, it carries deleterious economic, social, and public-health consequences
for user nations.
In other cases the economic connection between nations is synergistic--either mutually
beneficial or detrimental. A financial crisis--or a political crisis or natural disaster in one country
can spell trouble for foreign companies, many of which are now multinational in that they rely
on the labor forces, equipment, and raw materials of other nations. And, as trade barriers and
the virtual distance between nations collapse, the result is economic synergies among all
trading nations. For instance, the economic well-being of Middle East nations relies almost
entirely on demand from oil-consuming nations such as the U.S., which depend on a steady
supply from the Middle East.
Nations have also become interconnected in the pursuit of scientific and technological
progress. And while it might be tempting to hasten that the ripples generally benefit other
nations, often one nation's pursuit of progress spells trouble for other nations. For example,
the development of nudear weapons and biological and chemical agents affords the nation
possessing them political and military leverage over other nations. And, global computer
connectivity has served to heighten national-security concerns of all connected nations who
can easily fall prey to Internet espionage.
Finally, the world's nations have become especially interconnected in terms of their public
health. Prior to the modern industrial age, no nation had the capacity to inflict lasting
environmental damage on other nations. But, as that age draws to a close it is evident that
so-called industrial "progress" has carried deleterious environmental consequences worldwide.
Consider, for instance, the depletion of atmospheric ozone, which has warmed the Earth to the
point that it threatens the very survival of the human species. And, we are now learning that
dear-cutting the world's rainforests can set into motion a chain of animal extinction that
threatens the delicate balance upon which all animals--including humans--depend.
In closing, I take exception to the statement only insofar as a nation can still pursue progress
and the well-being of its own citizens in relative isolation from other nations. And I concede that
in the future the world's nations might respond to the health and security risks of the ripple
effect that I've described by adopting isolationist trade, communications, and military policies.
Yet, having benefited from the economic synergies which free trade and global financial
markets afford, and having seen the potential for progress technological revolution has
brought about, I think that the world's nations will be willing to assume those risks.
























Issue 102
"The purpose of education should be to provide students with a value system, a standard, a
set of ideas---not to prepare them for a specific job."
Should educators teach values or focus instead on preparing students for jobs? In my view
the two are not mutually exclusive. It is by helping students develop their own principles for
living, as well as by instilling in them certain fundamental values, that educators best prepare
young people for the world of work.
One reason for my viewpoint is that rote learning of facts, figures, and technical skills does
not help us determine which goals are worthwhile and whether the means of attaming those
goals are ethically or morally acceptable. In other words, strong values and ethical standards
are needed to determine how we can best put our rote knowledge to use in the working world.
Thus, by helping students develop a thoughtful, principled value system educators actually
help prepare students for jobs.
Another reason for my viewpoint lies in the fact that technology-driven industries account for
an ever4ncreasing portion of our jobs. As advances in technology continue to accelerate,
specific knowledge and skills needed for jobs will change more and more quickly. Thus it would
be a waste of our education system to focus on specific knowledge and job skills that might
soon become obsolete--at the expense of teaching values. It seems more appropriate today
for employers to provide the training our work force needs to perform their jobs, freeing up our
educators to help students develop guiding principles for their careers.
Besides helping students develop their own thoughtful value systems, educators should
instill in students certain basic values upon which any democratic society depends; otherwise,
our freedom to choose our own jobs and careers might not survive in the long term. These
values include principles of fairness and equity upon which our system of laws is based, as
well as the values of tolerance and respect when it comes to the viewpoints of others. It seems
to me that these basic values can best by instilled at an early age in a classroom setting,
where young students can work out their value systems as they interact with their peers.
Moreover, as students grow into working adults, practicing the basic values of fairness and
respect they learned as students serves them well in their jobs. At the workplace these values
manifest themselves in a worker's ability to cooperate, compromise, understand various
viewpoints, and appreciate the rights and duties of coworkers, supervisors, and subordinates.
This ability cannot help but serve any worker's career goals, as well as enhancing overall
workplace productivity.
Admittedly, values and behavioral standards specific to certain religions are best left to
parents and churches. After all, by advocating the values and teachings of any particular
religion public educators undermine our basic freedom of religion. However, by exposing
students to various religious beliefs, educators promote the values of respect and tolerance
when it comes to the viewpoints of others. Besides, in my observation certain fundamental
values--such as compassion, virtue, and humility--are common to all major religions. By
appreciating certain fundamental values that we should all hold in common, students are more
likely to grow into adults who can work together at the workplace toward mutually agreed-upon
goals.
In sum, only when educators help students develop their own principles for living, and when
they instill certain fundamental values, do young people grow into successful working adults.
Although there will always be a need to train people for specific jobs, in our technological
society where knowledge advances so rapidly, employers and job training programs are better
equipped to provide this function leaving formal educators to equip students with a moral
compass and ballast to prevent them from being tossed about aimlessly in a turbulent
vocational sea.
























Issue 103
"The best way to understand the character of a society is to examine the character of the men
and women that the society chooses as its heroes or its heroines."
The speaker claims that the character of a society's heroes and heroines ('heroes' hereafter)
reflects the character of that society. I tend to disagree. In my observation a society chooses
as its heroes not people who mirror the society but rather people whose character society's
members wish they could emulate but cannot--for want of character. Nevertheless, I concede
that one particular type of hero----the sociopolitical hero--by definition mirrors the character of
the society whose causes the hero champions.
First consider the sports hero, whom in my observation society chooses not merely by virtue
of athletic prowess. Some accomplished athletes we consider heroes because they have
overcome significant obstacles to achieve their goals. For example, Lance Arm-strong was not
the first Tour de France cycling champion from the U.S.; yet he was the first to overcome a
life-threatening illness to win the race. Other accomplished athletes we consider heroes
because they give back to the society which lionize them. As Mohammed Ali fought not just for
boxing rifles but also for racial equality, so baseball hero Mark McGuire fights now for
disadvantaged children, while basketball hero Magic Johnson fights for AIDS research and
awareness. Yet, do the character traits and resulting charitable efforts of sports heroes reflect
similar traits and efforts among our society at large? No; they simply reveal that we admire
these traits and efforts in other people, and wish we could emulate them but for our own
personal failings.
Next consider the military hero, who gains heroic stature by way of courage in battle, or by
otherwise facing certain defeat and emerging victorious. Former presidential hopeful John
McCain, whom even his political opponents laud as a war hero for having not only endured
years of torture as a prisoner of war but also for continuing to serve his country afterwards. Do
his patriotism and mettle reveal our society's true character? Certainly not. They reveal only
that we admire his courage, fortitude, and strength.
On the other hand, consider a third type of hero: the champion of social causes who inspires
and incites society to meaningful political and social change. Such luminaries as India's
Mahatma Gandhi, America's Martin Luther King, South Africa's Nelson Mandela, and Poland's
Lech Lawesa come immediately to mind. This unique brand of hero does reflect, and indeed
must reflect, the character of the hero's society. After all, it is the function of the social
champion to call attention to the character of society, which having viewed its reflection in the
hero is incited to act bravely--in accordance with its collective character.
In sum, I agree with the speaker's claim only with respect to champions of society's social
causes. Otherwise, what society deems heroic reflects instead a basic, and universal, human
need for paragons--to whom we can refer as metaphors for the sorts of virtues that for lack of
character we cannot ourselves reflect.
























Issue 104
"Rituals and ceremonies help define a culture. Without them, societies or groups of people
have a diminished sense of who they are."
The speaker asserts that rituals and ceremonies are needed for any culture or group of
people to retain a strong sense of identity. I agree that one purpose of ritual and ceremony is to
preserve cultural identity, at least in modern times. However, this is not their sole purpose; nor
are ritual and ceremony the only means of preserving cultural identity.
I agree with the speaker insofar as one purpose of ritual and ceremony in today's world is to
preserve cultural identity. Native American tribes, for example, cling tenaciously to their
traditional ceremonies and rituals, which typically tell a story about tribal heritage.
The reason for maintaining these rituals and customs lies largely in the tribes' 500-year
struggle against assimilation, even extinction, at the hands of European intruders. An outward
display of traditional customs and distinct heritage is needed to put the world on notice that
each tribe is a distinct and autonomous people, with its own heritage, values, and ideas.
Otherwise, the tribe risks total assimilation and loss of identity.
The lack of meaningful ritual and ceremony in homogenous mainstream America
underscores this point. Other than a few gratuitous ceremonies such as weddings and funerals,
we maintain no common rituals to set us apart from other cultures. The reason for this is that
as a whole America has little cultural identity of its own anymore. Instead, it has become a
patchwork quilt of many subcultures, such as Native Americans, Hasidic Jews, Amish, and
urban African Americans--each of which resort to some outward demonstration of its
distinctiveness in order to establish and maintain a unique cultural identity.
Nevertheless, preserving cultural identify cannot be the only purpose of ritual and ceremony.
Otherwise, how would one explain why isolated cultures that don't need to distinguish
themselves to preserve their identity nevertheless engage in their own distinct rituals and
ceremonies? In fact, the initial purpose of ritual and ceremony is rooted not in cultural identity
but rather superstition and spiritual belief. The original purpose of a ritual might have been to
frighten away evil spirits, to bring about weather conditions favorable to bountiful harvests, or
to entreat the gods for a successful hunt or for victory in battle. Even today some primitive
cultures engage in rituals primarily for such reasons.
Nor are ritual and ceremony the only means of preserving cultural identity. For example, our
Amish culture demonstrates its distinctiveness through dress and life-style. Hasidic Jews set
themselves apart by their dress, vocational choices, and dietary habits. And African-Americans
distinguish themselves today by their manner of speech and gesture. Of course, these
subcultures have their own distinct ways of cerebrating events such as weddings, coming of
age, and so forth. Yet ritual and ceremony are not the primary means by which these
subcultures maintain their identity.
In sum, to prevent total cultural assimilation into our modern-day homogenous soup, a
subculture with a unique and proud heritage must maintain an outward display of that
heritage--by way of ritual and ceremony. Nevertheless, ritual and ceremony serve a spiritual
function as well--one that has little to do with preventing cultural assimilation. Moreover, rituals
and ceremonies are not the only means of preserving cultural identity.
























Issue 105
"The way people look, dress, and act reveals their attitudes and interests. You can tell much
about a society's ideas and values by observing the appearance and behavior of its people."
This statement generalizes unfairly that the way people look, dress, and act reveals their
attitudes and their society's values. In my view, while in certain respects the habits and
customs of a people are accurate indicators of their attitudes and values, in other respects
they are not.
Turning first to the way people look and dress, certain aspects of the outward appearance of
a culture's people do inform us of their ideas, attitudes, and values. A society whose members
tend to be obese might place a high value on indulgence and pleasure, and a low value on
physical health. A general preference for ready-made, inexpensive clothing might indicate a
preference for practicality or for saving rather than spending. And, a society whose members
prefer to wear clothing that is traditional and distinct to that society is one that values tradition
over modernization. In other respects, however, the way people look and dress is not a
function of their attitudes and values but rather their climatic and work environment. In harsh
climates people bundle up, while in hot, humid climates they go with few clothes. In developed
nations people dress for indoor work and their skin appears pink and supple, while in agrarian
cultures people dress for outdoor work and appear weather-beaten.
I turn next to the way people act. The habits, rituals and lifestyles of a culture often do
provide accurate signals about its values. For instance, a society characterized by
over-consumption is clearly one that values comfort and convenience over a healthy
environment. And, a society whose members behave in a genteel, respectful, and courteous
manner toward one another is one which values human dignity, while a society of people who
act in a hateful manner toward others clearly places a low value on respect for others and on
tolerance of other people's opinions and beliefs. In other respects, however, the way people
behave can belie their attitudes and values. For instance, a society whose members tend to
work long hours might appear to place a high value on work for its own sake, when in reality
these work habits might be born of financial necessity for these people, who would prefer more
leisure time if they could afford it.
Finally, the statement overlooks a crucial distinction between free societies and oppressed
ones. Free societies, such as contemporary America, are characterized by a panoply of rituals,
behaviors, and manners of dress among its members. Such diversity in appearances surely
indicates a society that places a high value on individual freedoms and cultural diversity.
Accordingly, it might seem that a society whose members share similar rituals, ways of
dressing, and public behaviors places a low value on individual freedoms and cultural diversity.
However, any student of modern Communism and Fascism would recognize cultural
homogeneity as an imposition on society's members, who would happily display their
preference for individuality and diversity but for their oppressors.
To sum up, while the statement has merit, it amounts to an unfair generalization. The way
that people look, dress, and act is often bred of necessity, not of attitude or values. And in
oppressed societies people's customs and habits belie their true attitudes and values in any
event.
























Issue 106
"Progress is best made through discussion among people who have contrasting points of
view."
The speaker contends that progress is best made through discourse among people with
opposing opinions and viewpoints. I strongly agree with this contention. In all realms of human
endeavor, including the behavioral and natural sciences as well as government and law,
debate and disagreement form the foundation for progress.
Regarding the physical sciences, our scientific method is essentially a call for progress
through opposition. Any new theory must withstand rigorous scientific scrutiny. Moreover, the
history of theoretical science is essentially a history of opposing theories. A current example
involves two contrary theories of physics: wave theory and quantum theory. During the last 20
years or so scientists have been struggling to disprove one or the other, or to reconcile them.
By way of this intense debate, theorists have developed a new so-called "string" theory which
indeed reconciles them--at least mathematically. Although "strings" have yet to be confirmed
empirically, string theory might turn out to provide the unifying laws that all matter in the
universe obeys.
The importance of opposing theories is not limited to the purely physical sciences.
Researchers interested in human behavior have for some time been embroiled in the so-called
"nature-nurture" debate, which involves whether behavioral traits are a function of genetic
disposition and brain chemistry ("nature") or of learning and environment ("nurture"). Not
surprisingly, psychologists and psychiatrists have traditionally adopted sharply opposing
stances in this debate. And it is this very debate that has sparked researchers to discover that
many behavioral traits are largely a function of the unique neurological structure of each
individual's brain, and not a function of nurture. These and further discoveries certainly will
lead to progress in dealing effectively with pressing social issues in the felds of education,
juvenile delinquency, criminal reform, and mental illness. The outcomes of the debate also
carry important implications about culpability and accountability in the eyes of the law. In short,
the nature-nurture debate will continue to serve as a catalyst for progress across the entire
social spectrum.
The value of discourse between people with opposing viewpoints is not limited to the
physical and behavioral sciences. In government and politics, progress in human rights comes
typically through dissension from and challenges to the status quo; in fact, without
disagreement among factions with opposing viewpoints, political oppression and tyranny
would go unchecked. Similarly, in the fields of civil and criminal law, jurists and legislators who
uphold and defend legal precedent must face continual opposition from those who question
the fairness and relevance of current laws. This ongoing debate is critical to the vitality and
relevance of our system of laws.
History informs us of the chilling effect suppression of free discourse and debate can have on
progress. Consider the Soviet Refusenik movement of the 1920s. During this time period the
Soviet government attempted not only to control the direction and the goals of scientific
research but also to distort the outcomes of that research. During the 1920s the Soviet
government quashed certain areas of scientific inquiry, destroyed research facilities and
libraries, and caused the sudden disappearance of scientists who were engaged in research
that the state viewed as a potential threat. Not surprisingly, during this time period no
significant advances in scientific knowledge occurred under the auspices of the Soviet
government.
In sum, the speaker correctly asserts that it is through discourse, disagreement, and debate
between opposing viewpoints that true progress can best be made. Indeed, advances in
science, social welfare, government and law depend on the debate.
























Issue 107
"Most people choose a career on the basis of such pragmatic considerations as the needs of
the economy, the relative ease of finding a job, and the salary they can expect to make. Hardly
anyone is free to choose a career based on his or her natural talents or interest in a particular
kind of work."
The speaker believes that economic and other pragmatic concerns are what drive people's
career decisions, and that very few people are free to choose their careers based on their
talents and interests. I tend to disagree; although practical considerations often play a
significant role in occupational trends, ultimately the driving forces behind people's career
decisions are individual interest and ability.
At first glance the balance of empirical evidence would seem to lend considerable credence
to the speaker's claim. The most popular fields of study for students today are the computer
sciences--fields characterized by a relative glut of job opportunities. Graduates with degrees in
liberal arts often abandon their chosen fields because they cannot find employment, and
reenter school in search of more "practical" careers. Even people who have already achieved
success in their chosen field are often forced to abandon them due to pragmatic concerns. For
example, many talented and creative people from the entertainment industry find themselves
looking for other, less satisfying, kinds of work when they turn 40 years of age because
industry executives prefer younger artists who are "tuned in" to the younger demographic
group that purchases entertainment products.
However, upon further reflection it becomes clear that the relationship between
career-seekers and the supply of careers is an interdependent one, and therefore it is unfair to
generalize about which one drives the other. Consider, for example, the two mainstream fields
of computer science and law. In the computer industry it might appear that supply dearly drives
job interest--and understandably so, given the highly lucrative financial rewards. But, would
our legions of talented programmers, engineers, scientists, and technicians really pursue their
careers without a genuine fascination, a passion, or at least an interest in those areas? I think
not.
Conversely, consider the field of law, in which it would appear that demand drives the job
market, rather than vice versa. The number of applications to law schools soared during the
civil rights movement of the 1960s, and again in the 1980s during the run of the popular
television series LA. Lmv. More recently, the number of students pursuing paralegal and
criminal-justice careers spiked during and immediately after the O.J. Simpson trial. Query,
though, whether these aspiring lawyers and paralegals wood have been sufficiently motivated
had the supply of jobs and the financial rewards not already been waiting for them upon
graduation.
Another compelling argument against the speaker's claim has to do with the myriad of ways
in which people earn their living. Admittedly, the job market is largely clustered around certain
mainstream industries and types of work. Nevertheless, if one peers beyond these mainstream
occupational areas it becomes evident that many, many people do honor their true interests
and talents--in spite of where most job openings lie and regardless of their financial rewards.
Creative people seem to have a knack for creating their own unique vocational niche
whether it be in the visual or the performing arts; many animal lovers create work which allows
them to express that love. Caregivers and nurturers manage to find work teaching, socializing,
counseling, and healing others. And people bitten by the travel bug generally have little trouble
finding satisfying careers in the travel industry.
In sum, the speaker's threshold claim that it is strictly the pragmatic concerns of job
availability and financial compensation that drive people's career decisions oversimplifies both
why and how people make career choices. Besides, the speaker's final claim that people are
not free to choose their work violates my intuition. In the final analysis, people are ultimately
free to choose their work; it's just that they often choose to betray their true talents and
interests for the sake of practical, economic considerations.
























Issue 108
"If a goal is worthy, then any means taken to attain it is justifiable."
The speaker asserts that if a goal is worthy then any means of attaining that goal is
justifiable. In my view this extreme position misses the point entirely. Whether certain means
are justifiable in reaching a goal must be determined on a case-by-case basis, by weighing the
benefits of attaining the goal against the costs, or harm, that might accrue along the way. This
applies equally to individual goals and to societal goals.
Consider the goal of completing a marathon running race. If I need to reduce my working
hours to train for the race, thereby jeopardizing my job, or if I run a high risk of incurring a
permanent injury by training enough to prepare adequately for the event, then perhaps my
goal is not worth attaining. Yet if I am a physically challenged person with the goal of
completing a highly-publicized marathon, risking financial hardship or long-term injury might be
worthwhile, not only for my own personal satisfaction but also for the inspiration that attaining
the goal would provide many others.
Or consider the goal of providing basic food and shelter for an innocent child. Anyone would
agree that this goal is highly worthy--considered apart from the means used to achieve it. But
what if those means involve stealing from others? Or what if they involve employing the child in
a sweatshop at the expense of educating the child? Clearly, determining the worthiness of
such goals requires that we confront moral dilemmas, which we each solve individually--based
on our own conscience, value system, and notions of fairness and equity.
On a societal level we determine the worthiness of our goals in much the same way--by
weighing competing interests. For instance, any thoughtful person would agree that reducing
air and water pollution is a worthy societal goal; dean air and water reduce the burden on our
health-care resources and improves the quality of life for everyone in society. Yet to attain this
goal would we be justified in forcing entire industries out of business, thereby running the risk
of economic paralysis and widespread unemployment?
Or consider America's intervention in Iraq's invasion of Kuwait. Did our dual interest in a
continuing flow of oil to the West and in deterring a potential threat against the security of the
world justify our committing resources that could have been used instead for domestic
social-welfare programs--or a myriad of other productive purposes? Both issues underscore
the fact that the worthiness of a societal goal cannot be considered apart from the means and
adverse consequences of attaining that goal.
In sum, the speaker begs the question. The worthiness of any goal, whether it be personal
or societal, can be determined only by weighing the benefits of achieving the goal against its
costs--to us as well as others.
























Issue 109
"Society should identify those children who have special talents and abilities and begin training
them at an early age so that they can eventually excel in their areas of ability. Otherwise, these
talents are likely to remain undeveloped."
I agree that we should attempt to identify and cultivate our children's talents. However, in my
view the statement goes too far, by suggesting that selected children receive special attention.
If followed to the letter, this suggestion carries certain social, psychological, and human-rights
implications that might turn out to be more harmful than beneficial not just to children but to the
entire society.
At frrst blush the statement appears compelling. Although I am not a student of
developmental psychology, my understanding is that unless certain innate talents are nurtured
and cultivated during early childhood those talents can remain forever dormant; and both the
child and the society stand to lose as a result. After all, how can a child who is musically gifted
ever see those gifts come to fruition without access to a musical instrument? Or, how can a
child who has a gift for linguistics ever learn a foreign language without at least some exposure
to it? Thus I agree with the statement insofar as any society that values its own future
well-being must be attentive to its children's talents.
Beyond this concession, however, I disagree with the statement because it seems to
recommend that certain children receive special attention at the expense of other children--a
recommendation that I find troubling in three respects. First, this policy would require that a
society of parents make choices that they surely will never agree upon to begin with---for
example, how and on what basis each child's talents should be deter mined, and what sorts of
talents are most worth society's time, attention, and resources. While society's parents would
never reach a reasonable consensus on these issues, it would be irresponsible to leave these
choices to a handful of legislators and bureaucrats.
After all, they are unlikely to have the best interests of our children in mind, and their choices
would be tainted by their own quirky, biased, and otherwise wrongheaded notions of what
constitutes worthwhile talent. Thus the unanswerable question becomes: Who is to make
these choices to begin with?
Secondly, a public policy whereby some children receive preferential treatment carries
dangerous sociological implications. The sort of selectivity that the statement recommends
might tend to split society into two factions: talented elitists and all others. In my view any
democratic society should abhor a policy that breeds or exacerbates socioeco nomic
disparities.
Thirdly, in suggesting that it is in society's best interest to identify especially talented children,
the statement assumes that talented children are the ones who are most likely to contribute
greatly to the society as adults. I find this assumption somewhat dubious, for I see no reason
why a talented child, having received the benefit of special attention, might nevertheless be
unmotivated to ply those talents in useful ways as an adult. In fact, in my observation many
talented people who misuse their talents--in ways that harm the very society that helped
nurture those talents.
Finally, the statement ignores the psychological damage that a preferential policy might
inflict on all children. While children selected for special treatment grow to deem themselves
superior, those left out feel that they a worth less as a result. I think any astute child
psychologist would warn that both types of cases portend psychological trouble later in life. In
my view we should favor policies that affirm the self-worth of every child, regardless of his or
her talents---or lack thereof. Otherwise, we will quickly devolve into a society of people who
cheapen their own humanity.
In the final analysis, when we help our children identify and develop their talents we are all
better off. But ifwe help only some children to develop only some talents, I fear that on balance
we will all be worse off.
























Issue 110
"Too much time, money, and energy are spent developing new and more elaborate technology.
Society should instead focus on maximizing the use of existing technology for the immediate
benefit of its citizens."
The speaker asserts that rather than devoting its resources to developing new technology,
society should try to maximize the use of technology already available. While I would concede
that in a few areas society might be well served by adopting this recommendation, in general I
disagree with the speaker.
Admittedly, when a society's members devote their collective time, energy, talent, and money
to developing a new and more elaborate technology, the society necessarily incurs various
opportunity costs. The space program aptly illustrates this point. Virtually every additional step
in space exploration requires new technology, which diverts our resources from addressing
pressing problems here on Earth. Of course, space technologies have imparted a myriad of
benefits in areas such as weather forecasting, telecommunications, chemical engineering, and
medical technology, to name just a few. Yet, these technologies were developed in Earth's
orbit and for the most part were stated objectives of our space missions. Our goals in probing
further into space are far more vague: to learn more about the universe, its origins and destiny,
and to search for life elsewhere. Thus society might be better served by redirecting resources
used for developing new space exploration technology toward programs which impart clear,
certain, and immediate societal benefits and which avail themselves to a greater extent of
current technologies.
Yet space exploration is an exceptional and extreme example. In other areas the benefits of
new technology are far more immediate and certain, and thus justify the new technology.
Consider, for example, computer semi-conductor technology. The benefits of continually
developing faster, more reliable, and more affordable processors are immediate, predictable,
and profound. To halt advances in semi-conductor technology at any given point would be to
impede progress in global communication, knowledge and information access, the
development of safer buildings and vehides, and even the cure and prevention of disease.
The call for new computing technology seems particularly compelling in light of the last area
listed above. A great measure of valuable genetic research would simply not be possible
without the aid of fast and reliable computers. And effective treatment and cure of many
diseases also require more precise lasers and more powerful microscopes than those
currently available. In short, maximizing the use of existing technology in lieu of developing
new technology will not suffice to cure, prevent, and treat many diseases. Thus the speaker
would have society resign itself to its current state of physical health and well being--a dismal
prospect for society and for all humanity.
In sum, I find the speaker's recommendation indefensible. Admittedly, as a society we
should be careful not to pursue new technology merely for technology's sake or to satisfy our
curiosity. It is important that we direct our resources in ways that clearly benefit the society.
Nonetheless, without new technology we resign ourselves to life less safe, less healthy, and
less interesting than it need be.
























Issue 111
"Most important discoveries or creations are accidental: it is usually while seeking the answer
to one question that we come across the answer to another."
The speaker contends that most important discoveries and creations are accident~-----that
they come about when we are seeking answers to other questions. I concede that this
contention finds considerable support from important discoveries of the past. However, the
contention overstates the role of accident, or serendipity, when it comes to modern day
discoveries--and when it comes to creations.
Turning first to discoveries, I agree that discovery often occurs when we unexpectedly
happen upon something in our quest for something else--such as an answer to unrelated
question or a solution to an unrelated problem. A variety of geographical, scientific, and
anthropological discoveries aptly illustrate this point. In search of a trade route to the West
Indies Columbus discovered instead an inhabited continent unknown to Europeans; and
during the course of an unrelated experiment Fleming accidentally discovered penicillin. In
search of answers to questions about marine organisms, oceanographers often happen upon
previously undiscovered, and important, archeological artifacts and geological phenomena;
conversely, in their quest to understand the Earth's structure and history geologists often
stumble upon important human artifacts. In light of the foregoing examples, "intentional
discovery" might seem an oxymoron; yet in fact it is not. Many important discoveries are
anticipated and sought out purposefully.
For instance, in their efforts to find new celestial bodies astronomers using increasingly
powerful telescopes do indeed find them. Biochemists often discover important new vaccines
and other biological and chemical agents for the curing, preventing, and treating diseases not
by stumbling upon them in search of something else but rather through methodical search for
these discoveries. In fact, in today's world discovery is becoming increasingly an anticipated
result of careful planning and methodical research, for the reason that scientific advancement
now requires significant resources that only large corporations and governments possess.
These entities are accountable to their share-holders and constituents, who demand dear
strategies and objectives so that they can see a return on their investments.
Turning next to how our creations typically come about, in marked contrast to discoveries,
creations are by nature products of their creators' purposeful designs. Consider humankind's
key creations, such as the printing press, the internal combustion engine, and semi-conductor
technology. Each of these inventions sprung quite intentionally from the inventor's imagination
and objectives. It is crucial to distinguish here between a creation and the spin-offs from that
creation, which the original creator may or may not foresee. For instance, the engineers at a
handful of universities who originally created the ARPAnet as a means to transfer data
amongst themselves certainly intended to create that network for that purpose. What these
engineers did not intend to create, however, was what would eventually grow to become the
infrastrucRLre for mass media and communications, and even commerce. Yet the ARPAnet
itself was no accident, nor are the many creations that it spawned, such as the World Wide
Web and the coundess creations that the Web has in turned spawned.
In sum, the speaker has overlooked a crucial distinction between the nature of discovery
and the nature of creation. Although serendipity has always played a key role in many
important discoveries, at least up until now, purposeful intent is necessarily the key to human
creation.
























Issue 112
"In order for any work of art---whether film, literature, sculpture, or a song---to have merit, it
must be understandable to most people."
The speaker's assertion that art must be widely understood to have merit is wrongheaded.
The speaker misunderstands the final objective of art, which has little to do with cognitive
"understanding."
First consider the musical art form. The fact that the listener must "understand" the
composer's artistic expression without the benefit of words or visual images forces us to ask:
"What is there to understand in the first place?" Of course, the listener can always struggle to
appreciate how the musical piece employs various harmonic, melodic, and rhythmic principles.
Yet it would be absurd to assert that the objective of music is to challenge the listener's
knowledge of music theory. In fact, listening to music is simply an encounter--an experience to
be accepted at face value for its aural impact on our spirit and our emotions.
Next consider the art forms of painting and sculpture. In the context of these art forms, the
speaker seems to suggest that ifwe cannot all understand what the work is supposed to
represent, then we should dismiss the work as worthless. Again, however, the speaker misses
the point of art. Only by provoking and challenging us, and inciting our emotions, imagination,
and wonder do paintings and sculpture hold merit. Put another way, if the test for meritorious
art were its ability to be dearly understood by every observer, then our most valuable art would
simply imitate the mundane physical world around us. A Polaroid picture taken by a monkey
would be considered great art, while the abstract works of Pollock and Picasso would be worth
no more than the salvage value of the materials used to create them.
Finally, consider art forms such as poetry, song, and prose, where the use of language is
part-and-parcel of the art. It is easy to assume that where words are involved they must be
strung together in understandable phrases in order for the art to have any merit. Moreover, if
the writer-artist resorts exclusively to obscure words that people simply do not know, then the
art can convey nothing beyond the alliterative or onomatopoeic impact that the words might
have when uttered aloud. However, in poetry and song the writer-artist often uses words as
imagery--to conjure up feelings and evoke visceral reactions in the reader or listener. In these
cases stanzas and verses need not be "understood" to have merit, as much as they need be
experienced for the images and emotions they evoke.
When it comes to prose, admittedly the writer-artist must use words to convey cognitive
ideas--for example, to help the reader follow the plot of a novel. In these cases the art must
truly be "understood" on a Linguistic and cognitive level; otherwise it is mere gibberish
without merit except perhaps as a doorstop. Nevertheless, the final objective even of literature
is to move the reader emotionally and spiritually--not simply to inform. Thus, even though a
reader might understand the twists and turns of a novel's plot intellectually, what's the point if
the reader has come away unaffected in emotion or spirit?
In the final analysis, whether art must be understood by most people, or by any person, in
order for it to have merit begs the question. To "understand" art a person need only have eyes
to see or ears to hear, and a soul to feel.
























Issue 113
"The chief benefit of the study of history is to break down the illusion that people in one period
of time are significantly different from people who lived at any other time in history."
I concede that basic human nature has not changed over recorded history, and that coming
to appreciate this fact by studying history can be beneficial in how we live as a society.
However, I disagree with the statement in two respects. First, in other ways there are marked
differences between people of different time periods, and learning about those differences can
be just as beneficial. Second, studying history carries other equally important benefits as well.
I agree with the statement insofar as through the earnest study of human history we learn
that basic human nature---our desires and motives, as well as our fears and foibles---has
remained constant over recorded time. And through this realization we can benefit as a society
in dealing more effectively with our enduring social problems. History teaches us, for example,
that it is a mistake to attempt to legislate morality, because humans by nature resist having
their moral choices forced upon them. History also teaches us that our major social ills are
here to stay, because they spring from human nature. For instance, crime and violence have
troubled almost every society; all manner of reform, prevention, and punishment have been
tried with only partial success. Today, the trend appears to be away from reform toward a
"tough-on-crime" approach, to no avail.
However beneficial it might be to appreciate the unchanging nature of humankind, it is
equally beneficial to understand and appreciate significant differences between peoples of
different time periods----in terms of cultural mores, customs, values, and ideals. For example,
the ways in which societies have treated women, ethnic minorities, animals, and the
environment have confin, mlly evolved over the course of human history. Society's attitudes
toward artistic expression, literature, and scientific and intellectual inquiry are also in a
continual state of evolution. And, perhaps the most significant sort of cultural evolution involves
spiritual beliefs, which have always spun themselves out, albeit uneasily, through clashes
between established traditions and more enlightened viewpoints. A heightened awareness of
all these aspects of cultural evolution help us formulate informed, reflective, and enlightened
values and ideals for ourselves; and our society dearly benefits as a result.
Another problem with the statement is that it undervalues other, equally important benefits of
studying history. Learnmgabout the courage and tenacity of history's great explorers, leaders,
and other achievers inspires us to similar accomplishments, or at least to face own fears as we
travel through life. Learning about the mistakes of past societies helps us avoid repeating them.
For instance, the world is slowly coming to learn by studying history that political states whose
authority stems from suppression of individual freedoms invariably fall of their own oppressive
weight. And, learning about one's cultural heritage, or roots, fosters a healthy sense of self and
cultivates an interest in preserving art, literature, and other cultural artifacts--all of which serve
to enrich society.
To sum up, history informs us that basic human nature has not changed, and this history
lesson can help us understand and be more tolerant of one another, as well as develop
compassionate responses to the problems and failings of others. Yet, history has other lessons
to offer us as well. It helps us formulate informed values and ideals for ourselves, inspires us to
great achievements, points out mistakes to avoid, and helps us appreciate our cultural
heritage.
























Issue 114
"Imprisonment for violent crimes should be made as unpleasant as possible in order to deter
potential offenders from committing such crimes."
The speaker contends that ifprison conditions are made "as unpleasant as possible" then
potential violent criminals would be deterred from committing crimes. I strongly disagree.
History makes dear that so-called "tough-on-crime" approaches are simply not effective crime
deterrents. Moreover, the speaker recommends a policy that would serve to undermine two
other important objectives of incarceration, and that would run contrary to certain
countervailing societal interests.
In light of all the conveniences that our society provides its prisoners today, it might be
tempting to agree with the speaker. Violent criminals tend to come from neighborhoods where
drug trafficking, vandalism and burglary, and therefore violent crime are commonplace. For
these individuals prison can be a haven--a comparatively secure place where inmates are
provided with room, board, health care, exercise facilities, and so forth. Accordingly, unless
prison life is made more unpleasant overall than life outside prison walls, individuals will not be
deterred from committing violent crimes.
Conceding this point, I nevertheless find the speaker's contention dubious at best. Even
assuming that potential criminals are made aware of the unpleasantness that awaits them
behind bars--for example, through the various "scared straight" social programs that are
popular in inner-city schools today--for three reasons the deterrent effect of the speaker's
proposed policy would be negligible. First, most violent criminals are relatively young; and
young people tend to act impetuously, to lack self-restraint, and to disregard potential adverse
consequences of their actions. Second, recent genetic research reveals that violent behavior
is largely the result of genetic makeup rather than environmental factors; thus attempts to
deter "born criminals" are unlikely to succeed. Third, consider the various means of public
execution used throughout history: crucifixion, burning at the stake, hanging, and so forth.
While I have no doubt that these shocking public displays have always deterred crime,
extreme unpleasantness behind modern prison walls would simply not be sufficiently
gruesome or public to effectively deter potential criminals.
Even if I were to concede that severely unpleasant prison conditions would serve to reduce
the incidence of violent crime, following the speaker's advice would risk thwarting two other
purposes of incarcerating criminals: to reform them and to quarantine them. If prison
conditions are made too severe, then any attempt to reform--whether it be through education,
psychological counseling, or work programs--~ght have little effect on inmates, who upon
release from prison would lash out at the society that subjected them to such severe
conditions. Moreover, the chief reason we imprison dangerous individuals is to quarantine
them--that is, to protect ourselves from them. Thus as long as prisons are secure, living
conditions in those prisons are incidental.
Finally, the speaker overlooks certain competing public-policy considerations. One such
consideration is our constitutional right to due process of law, by which convicted criminals
have the right to appeal their convictions. If prison conditions are made extremely harsh, then
any eventual acquittal might be little consolation for the wrongfully accused inmate who has
already been forced to suffer those harsh conditions. Secondly, the speaker recommends a
course of action that might sanction abuse of inmates by prison officials and guards. Thirdly,
the argument overlooks all the ways in which prison inmates serve society in productive ways
while in prison. For example, many prisons have recently instituted programs by which
inmates refurbish used computers for use in public schools. A prison whose conditions are "as
unpleasant as possible" might consider such programs too pleasant for inmates, and decline
to participate; and society would be worse off as a result.
In sum, I find the speaker's contention indefensible in light of numerous countervailing
considerations. In the final analysis, history informs us that violent crime is a universal and
timeless social problem, and that no manner of punishment can eliminate it.


























Issue 115
"People often look for similarities, even between very different things, and even when it is
unhelpful or harmful to do so. Instead, a thing should be considered on its own terms; we
should avoid the tendency to compare it to something else."
Do people too often look for similarities between things, regardless of whether it is helpful or
harmful to do so, and not often enough evaluate things on their own individual merits? The
speaker believes so. I agree to an extent, especially when it comes to making determinations
about people. However, the speaker overlooks a fundamental and compelling reason why
people must always try to find similarities between things.
I agree with the speaker insofar as insisting on finding similarities between things can often
result in unfair, and sometimes harmful, comparisons. By focusing on the similarities among all
big cities, for example, we overlook the distinctive character, architecture, ethnic diversity, and
culture of each one. Without evaluating an individual company on its own merits before buying
stock in that company, an investor runs the risk of choosing a poor performer in an otherwise
attractive product sector or geographic region. And schools tend to group students according
to their performance on general intelligence tests and academic exams. By doing so, schools
overlook more specific forms of intelligence which should be identified and nurtured on a more
individualized basis so that each student can fulffil his or her potential.
As the final example above illustrates, we should be especially careful when looking for
similarities between people. We humans have a tendency to draw arbitrary condusions about
one another based on gender, race, and superficial characteristics. Each individual should be
evaluated instead on the basis of his or her own merit in terms of character, accomplishment,
and so forth. Otherwise, we run the risk of unfair bias and even prejudice, which manifest
themselves in various forms of discrimination and oppression. Yet prejudice can result from
looking too hard for differences as well, while overlooking the things that all people share.
Thus while partly correct, the speaker's assertion doesn't go far enough--to account for the
potential harm in drawing false distinctions between types of people.
Yet, in another sense the speaker goes too far by overlooking a fundamental, even
philosophical, reason why we should always look for similarities between things. Specifically, it
is the only way humans can truly learn anything and communicate with one another. Any
astute developmental psychologist, epistemologist, or even parent would agree that we come
to understand each new thing we encounter by comparing it to something with which we are
already familiar. For example, if a child first associates the concept of blue with the sky's color,
then the next blue thing the child encounters--a ball, for instance--the child recognizes as blue
only by way of its similarity to the sky.
Furthermore, without this association and a label for the concept of blue the child cannot
possibly convey the concept to another person. Thus looking for similarities between things is
how we make sense of our world, as well as communicate with one another.
To sum up, I agree that finding false similarities and drawing false analogies can be harmful,
especially when reaching conclusions about people. Nevertheless, from a philosophical and
linguistic point of view, humans must look for similarities between things in order to learn and
to communicate.


























Issue 116
"People are mistaken when they assume that the problems they confront are more complex
and challenging than the problems faced by their predecessors. This illusion is eventually
dispelled with increased knowledge and experience."
Is any sense that the problems we face are more complex and challenging than those which
our predecessors faced merely an illusion--one that can be dispelled by way of knowledge and
experience? The speaker believes so, although I disagree. In my view, the speaker unfairly
generalizes about the nature of contemporary problems, some of which have no analog from
earlier times and which in some respects are more complex and challenging than any
problems earlier societies ever confronted. Nevertheless, I agree that many of the other
problems we humans face are by their nature enduring ones that have changed little in
complexity and difficulty over the span of human history; and I agree that through experience
and enlightened reflection on human history we grow to realize this fact.
I turn first to my chief point of contention with the statement. The speaker overlooks certain
societal problems unique to today's world, which are complex and challenging in ways unlike
any problems that earlier societies ever faced. Consider three examples. The first involves the
growing scarcity of the world's natural resources. An ever-increasing human population,
together with over-consumption on the part of developed nations and with global
dependencies on finite natural resources, have created uniquely contemporary environmental
problems that are global in impact and therefore pose political and economic challenges
previously unrivaled in complexity.
A second uniquely contemporary problem has to do with the fact that the nations of the world
are growing increasingly interdependent--politically, militarily, and economically.
Interdependency makes for problems that are far more complex than analogous problems for
individual nations during times when they were more insular, more self-sustaining, and more
autonomous.
A third uniquely contemporary problem is an outgrowth of the inexorable advancement of
scientific knowledge, and one that society voluntarily takes up as a challenge. Through
scientific advancements we've already solved innumerable health problems, harnessed
various forms of physical energy, and so forth. The problems left to address are the ones that
are most complex and challenging--for example, slowing the aging process, replacing human
limbs and organs, and colonizing other worlds in the event ours becomes inhabitable. In short,
as we solve each successive scientific puzzle we move on to more challenging and complex
ones.
I turn next to my points of agreement with the statement. Humans face certain universal and
timeless problems, which are neither more nor less complex and challenging for any
generation than for preceding ones. These sorts of problems are the ones that spring from the
failings and foibles that are part-and-parcel of human nature. Our problems involving
interpersonal relationships with people of the opposite sex stem from basic differences
between the two sexes. The social problems of prejudice and discrimination know no
chronological bounds because it is our nature to fear and mistrust people who are different
from us. War and crime stem from the male aggressive instinct and innate desire for power.
We've never been able to solve social problems such as homelessness and hunger because
we are driven by self-interest.
I agree with the statement also in that certain kinds of intellectual struggles-- to deter mine
the meaning of life, whether God exists, and so forth are timeless ones whose complexities
and mystery know no chronological bounds whatsoever. The fact that we rely on ancient
teachings to try to solve these problems underscores the fact that these problems have not
grown any more complex over the course of human history. And, with respect to all the
timeless problems mentioned above I agree that knowledge and experience hdp us to
understand that these problems are not more complex today than before. In the final analysis,
by studying history, human psychology, theology, and philosophy we come to realize that,
aside from certain uniquely contemporary problems, we face the same fundamental problems
as our predecessors because we face the same human condition as our predecessors
whenever we look in the mirror.
























Issue 117
"The best way to teach---whether as an educator, employer, or parent---is to praise positive
actions and ignore negative ones."
The speaker suggests that the most effective way to teach others is to praise positive
actions while ignoring negative ones. In my view, this statement is too extreme. It overlooks
circumstances under which praise might be inappropriate, as well as ignoring the beneficial
value of constructive criticism, and sometimes even punishment.
The recommendation that parents, teachers, and employers praise positive actions is
generally good advice. For young children positive reinforcement is critical in the development
of healthy self-esteem and self-confidence. For students appropriate positive feedback serves
as a motivating force, which spurs them on to greater academic achievement. For employees,
appropriately administered praise enhances productivity and employee loyalty, and makes for
a more congenial and pleasant work environment overall.
While recommending praise for positive actions is fundamentally sound advice, this advice
should carry with it certain caveats. First, some employees and older students might fred
excessive praise to be patronizing or paternalistic. Secondly, some individuals need and
respond more appropriately to praise than others; those administering the praise should be
sensitive to the individual's need for positive reinforcement in the fzrst place. Thirdly, praise
should be administered fairly and evenhandedly. By issuing more praise to one student than to
others, a teacher might cause one recipient to be labeled by classmates as teacher's pet, even
if the praise is well deserved or badly needed. If the result is to alienate other students, then
the praise might not be justified. Similarly, at the workplace a supervisor must be careful to
issue praise fairly and evenhandedly, or risk accusations of undue favoritism, or even
discrimination.
As for ignoring negative actions, I agree that minor peccadilloes can, and in many cases
should, be overlooked. Mistakes and other negative actions are often part of the natural
learning process. Young children are naturally curious, and parents should not scold their
children for every broken plate or precocious act. Otherwise, children do not develop a healthy
sense of wonder and curiosity, and will not learn what they must in order to make their own
way in the world. Teachers should avoid rebuking or punishing students for faulty reasoning,
incorrect responses to questions, and so forth. Otherwise, students might stop trying to learn
altogether. And employees who know they are being monitored closely for any sign of errant
behavior are likely to be less productive, more resentful of their supervisors, and less loyal to
their employers.
At the same time, some measure of constructive criticism and critique, and sometimes even
punishment, is appropriate. Parents must not turn a blind eye to their child's behavior if it
jeopardizes the child's physical safety or the safety of others. Teachers should not ignore
behavior that unduly disrupts the learning process; and of course teachers should correct and
critique students' class work, homework and tests as needed to help the students learn from
their mistakes and avoid repeating them. Finally, employers must not permit employee
behavior that amounts to harassment or that otherwise undermines the overall productivity at
the workplace. Acquiescence in these sorts of behaviors only serves to sanction them.
To sum up, the speaker's dual recommendation is too extreme. Both praise and criticism
serve useful purposes in promoting a child's development, a student's education, and an
employee's loyalty and productivity. Yet both must be appropriately and evenhandedly
administered; otherwise, they might serve instead to defeat these purposes.
























Issue 118
" 'Moderation in all things' is ill-considered advice. Rather, one should say, 'Moderation in most
things,' since many areas of human concern require or at least profit from intense focus."
Should we strive for moderation in all things, as the adage suggests? I tend to agree with the
speaker that worthwhile endeavors sometimes require, or at least call for, intense focus at the
expense of moderation.
The virtues of moderation are undeniable. Moderation in all things affords us the time and
energy to sample more of what life and the world have to offer. In contrast, lack of moderation
leads to a life out of balance. As a society we are slowly coming to realize what many astute
psychologists and medical practitioners have known all along: we are at our best as humans
only when we strike a proper balance between the mind, body, and spirit. The call for a
balanced life is essentially a call for moderation in all things.
For instance, while moderate exercise improves our health and sense of well-being, over
exercise and intense exercise can cause injury or psychological burnout, either of which defeat
our purpose by requiring us to discontinue exercise altogether. Lack of moderation in diet can
cause obesity at one extreme or anorexia at the other, either of which endangers one's health,
and even life. And when it comes to potentially addictive substances--alcohol, tobacco, and the
like--the deleterious effects of over-consumption are clear enough.
The virtues of moderation apply to work as well. Stress associated with a high-pressure job
increases one's vulnerability to heart disease and other physical disorders. And overwork can
result in psychological burnout, thereby jeopardizing one's job and career. Overwork can even
kill, as demonstrated by the alarmingly high death rate among young Japanese men, many of
whom work 100 or more hours each week.
Having acknowledged the wisdom of the old adage, I nevertheless agree that under some
circumstances, and for some people, abandoning moderation might be well justified. Query
how many of the world's great artistic creations--in the visual arts, music, and even
literature--would have come to fruition without intense, focused efforts on the part of their
creators. Creative work necessarily involves a large measure of intense focus--a
single-minded, obsessive pursuit of aesthetic perfection.
Or, consider athletic performance. Admittedly, intensity can be counterproductive when it
results in burnout or injury. Yet who could disagree that a great athletic performance
necessarily requires great focus and intensity--both in preparation and in the performance
itself?. In short, when it comes to athletics, moderation breeds mediocrity, while intensity
breeds excellence and victory. Finally, consider the increasingly competitive world of business.
An intense, focused company-wide effort is sometimes needed to ensure a company's
competitiveness, and even survival. This is particularly true in today's technology-driven
industries where keeping up with frantic pace of change is essential for almost any high-tech
finn's survival.
In sum, the old adage amounts to sound advice for most people under most circumstances.
Nevertheless, when it comes to creative accomplishment, and to competitive success in areas
such as athletics and business, I agree with the speaker that abandoning or suspending
moderation is often appropriate, and sometimes necessary, in the interest o f achieving
worthwhile goals.
























Issue 119
"Although innovations such as video, computers, and the Internet seem to offer schools
improved methods for instructing students, these technologies all too often distract from real
learning."
The speaker asserts that innovations such as videos, computers, and the Internet too often
distract from "real" learning in the dassroom. I strongly agree that these tools can be
counterproductive in some instances, and ineffectual for certain types of learning.
Nevertheless, the speaker's assertion places too little value on the ways in which these
innovations can facilitate the learning process.
In several respects, I find the statement compelling. First of all, in my observation and
experience, computers and videos are misused most often for education when teachers rely
on them as surrogates, or baby-sitters. Teachers must use the time during which students are
watching videos or are at their computer stations productively--helping other students,
preparing lesson plans, and so forth. Otherwise, these tools can indeed impede the learning
process.
Secondly, passive viewing of videos or of Web pages is no indication that any significant
learning is taking place. Thus teachers must carefully select Internet resources that provide a
true interactive learning experience, or are highly informative otherwise. And, in selecting
videos teachers must be sure to follow up with lively class discussions. Otherwise, the
comparatively passive nature of these media can render them ineffectual in the learning
process.
Thirdly, some types of learning occur best during face-to-face encounters between teacher
and student, and between students. Only by way of a live encounter can a language teacher
recognize and immediately correct subtle problems in pronunciauon and inflection. And, there
is no suitable substitute for a live encounter when it comes to teaching techniques in painting,
sculpture, music performance, and acting. Moreover, certain types of learning are facilitated
when students interact as a group. Many grade school teachers, for example, find that reading
together aloud is the most effective way for students to learn this skill.
Fourth, with technology-based learning tools, especially computers and the Intemet,
learning how to use the technology can rob the teacher of valuable time that could be spent
accomplishing the teacher's ultimate educational objectives. Besides, any technology-based
learning tool carries the risk of technical problems. Students whose teachers fail to plan for
productive use of unexpected down-time can lose opportunities for real learning.
Finally, we must not overlook the non-quantifiable benefit that personal attention can afford.
A human teacher can provide meaningful personal encouragement and support, and can
identify and help to solve a student's social or psychological problems that might be impeding
the learning process. No video, computer program, or Web site can begin to serve these
invaluable functions.
Acknowledging the many ways that technological innovations can impede "real" learning,
these innovations nevertheless can facilitate "real" learning, if employed judicially and for
appropriate purposes. Specifically, when it comes to learning rote facts and figures, personal
interaction with a teacher is unnecessary, and can even result in fatigue and burnout for the
teacher. Computers are an ideal tool for the sorts of learning that occur only through
repetition--typing skills, basic arithmetical calculations, and so forth. Computers also make
possible visual effects that aid uniquely in the learning of spatial concepts. Finally, computers,
videos and the Internet are ideal for imparting basic text-book information to students, thereby
freeing up the teacher's time to give students individualized attention.
In sum, computers and videos can indeed distract from learning--when teachers misuse
them as substitutes for personal attention, or when the technology itself becomes the focus of
attention. Nevertheless, if judicially used as primers, as supplements, and where repetition and
rote learning are appropriate, these tools can serve to liberate teachers to focus on individual
needs of students--needs that only "real" teachers can recognize and meet.

























Issue 120
"Most people prefer restrictions and regulations to absolute freedom of choice, even though
they might deny such a preference."
Do people prefer constraints on absolute freedom of choice, regardless of what they might
claim? I believe so, because in order for any democratic society to thrive it must strike a
balance between freedom and order.
History informs us that attempts to quell basic individual freedoms--of expression, of opinion
and belief, and to come and go as we please invariably fail. People ultimately rise up against
unreasonable constraints on freedom of choice. The desire for freedom seems to spring from
our fundamental nature as human beings. But does this mean that people would prefer
absolute freedom of choice to any constraints whatsoever? No. Reasonable constraints on
freedom are needed to protect freedom--and to prevent a society from devolving into a state of
anarchy where life is short and brutish.
To appreciate our preference for constraining our own freedom of choice, one need look no
further than the neighborhood playground. Even without any adult supervision, a group of
youngsters at play invariably establish mutually agreed-upon rules for conduct-- whether or not
a sport or game is involved. Children learn at an early age that without any rules for behavior
the playground bully usually prevails. And short of beating up on others, bullies enjoy taking
prisoners--i.e., restricting the freedom of choice of others. Thus our preference for constraining
our freedom of choice stems from our desire to protect and preserve that freedom.
Our preference for constraining our own freedom of choice continues into our adult lives. We
freely enter into exclusive pair-bonding relationships; during our teens we agree to "go steady,"
then as adults we voluntarily enter into marriage contracts. Most of us eagerly enter into
exclusive employment relationships--preferring the security of steady income to the "freedom"
of not knowing where our next paycheck will come from. Even people who prefer
self-employment to job security quickly learn that the only way to preserve their "autonomy" is
to constrain themselves in terms of their agreements with clients and customers, and
especially in terms of how they use their time. Admittedly, our self-inflicted job constraints are
born largely of economic necessity. Yet even the wealthiest individuals usually choose to
constrain their freedom by devoting most of their time and attention to a few pet projects.
Our preference for constraining our own freedom of choice is evident on a societal level as
well. Just as children at a playground recognize the need for self-imposed rules and
regulations, as a society we recognize the same need. After all, in a democratic society our
system of laws is an invention of the people. For example, we insist on being bound by rules
for operating motor vehicles, for buying and selling both real and personal property, and for
making public statements about other people. Without these rules, we would live in continual
fear for our physical safety, the security of our property, and our personal reputation and
dignity.
In sum, I agree with the fundamental assertion that people prefer reasonable constraints on
their freedom of choice. In fact, in a democratic society we insist on imposing these constraints
on ourselves in order to preserve that freedom.
























Issue 121
"Most people are taught that loyalty is a virtue. But loyalty---whether to one's friends, to one's
school or place of employment, or to any institution---is all too often a destructive rather than a
positive force."
Is loyalty all too often a destructive force, rather than a virtue, as the speaker contends? To
answer this question it is crucial to draw a distinction between loyalty as an abstract concept
and its application. Apart from its consequences, loyalty is clearly a virtue that all humans
should strive to develop. Loyalty is part of a universal ethos that we commonly refer to as the
golden rule: Do unto others as you would have others do unto you. However, whether loyalty in
its application amounts to virtue depends on its extent and its object.
First consider the ways in which loyalty, if exercised in proper measure and direction, can be
a positive force. Relationships between spouses and other exdusive pairs require some
degree of trust in order to endure; and loyalty is part-and-parcel of that trust. Similarly,
employment relationships depend on some measure of mutual loyalty, without which job
attrition would run so rampant that society's economic productivity would virtually come to a
halt. And, without some mutual loyalty between a sovereign state and its citizenry there can be
no security or safety from either revolt or invasion. The world would quickly devolve into
anarchy or into a despotic state ordered by brute force.
On the other hand, if misguided or overextended loyalty can amount to a divisive and even
destructive force. In school, undue loyalty to popular social cliques often leads to insulting and
abusive language or behavior toward students outside these cliques. Undue loyalty amongst
friends can turn them into an antisocial, even warring, gang of miscreants. And, undue loyalty
to a spouse or other partner can lead to acquiescence in abusive treatment by that partner,
and abuse of oneself by continuing to be loyal despite the abuse.
Misguided loyalty can also occur between people and their institutions. Undue loyalty to
college alma maters often leads to job discrimination--for example, when a job candidate with
the same alma mater as that of the person making the hiring decision is chosen over a more
qualified candidate from a different school. Loyalty to one's employer can also become a
destructive force, ifit leads to deceptive business practices and disregard for regulations
designed to protect public health and safety. By way of undue loyalty to their employers,
employees sometimes harm themselves as well. Specifically, many employees fail to advance
their own careers by moving on to another place of work, or type of work altogether, because
of a misplaced sense of loyalty to one company. Finally, and perhaps foremost in terms of
destructive potential, is misguided loyalty to one's country or political leaders. History shows all
too well that crossing the fine line between patriotism and irrational jingoism can lead to such
atrocities as persecution, genocide, and war.
To sum up, without loyalty there can be no basis for trust between two people, or between
people and their institutions. A world devoid of loyalty would be a paranoid, if not anarchical,
one. Nevertheless, loyalty must be tempered by other virtues, such as fairness, tolerance, and
respect for other people and for oneself. Otherwise, I agree that it can serve to divide, damage,
and even destroy.
























Issue 122
"Conformity almost always leads to a deadening of individual creativity and energy."
This statement about the impact of conformity on individual energy and creativity actually
involves two distinct issues. In my view, the extent to which conformity stifles a person's
energy depends primarily on the temperament of each individual, as well as on the goals
toward which the person's energy is directed. However, I am in full agreement that conformity
stifles creativity; indeed, in my view the two phenomena are mutually exdusive.
Whether conformity stifles individual energy depends on the individual person involved.
Some people are conformists by nature. By this I mean that they function best in an
environment where their role is dearly defined and where teamwork is key in meeting group
objectives. For conformists individual energy comes from sharing a common purpose, or
mission, with a group that must work in lock-step fashion to achieve that mission. In the military
and in team sports, for example, the group's common mission is dearly understood, and group
members conform to the same dress code, drill regimen, and so forth. And rather than quelling
energy, this conformity breeds camaraderie, as well as enthusiasm and even fervor for winning
the battle or the game. Besides, nonconforming behavior in these environments only serves to
undermine success; if game plans or battle strategies were left to each individual team
member, the results would dearly be disastrous.
Conformists find enhanced energy in certain corners of the business world as well,
particularly in traditional service industries such as finance, accounting, insurance, legal
services, and health care. In these businesses it is not the iconodasts who revel and thrive but
rather those who can work most effectively within the constraints of established practices,
policies, and regulations. Of course, a clever idea for structuring a deal, or a creative legal
maneuver, might play a role in winning smaller battles along the way. But such tactics are
those of conformists who are playing by the same ground rules as their peers.
In sharp contrast, other people are nonconformists by nature. These people are motivated
more often by the personal satisfaction that comes with creativity, invention, and innovation.
For these people a highly structured, bureaucratic environment only serves to quell motivation
and energy. Artists and musicians typically find such environments stifling, even noxious.
Entrepreneurial business people who thrive on innovation and differentiation are often driven
to self-employment because they feel stifled and frustrated, even offended, by a bureaucracy
which requires conformity.
As for whether conformity stifles individual creativity, one need only look around at the
individuals whom we consider highly creative to conclude that this is indeed the case. Our
most creative people are highly eccentric in their personal appearance, life-style, and so forth.
In fact, they seem to eschew any sort of established norms and mores. Bee-bop music pioneer
Thelonius Monk was renowned for his eccentric manner of speech, dress, and behavior. Even
as a young student, Frank Lloyd Wright took to carrying a cane and wearing a top hat and a
cape. And who could argue that musicians Prince and Michael Jackson, two of the most
creative forces in popular music, are nothing if not nonconforming in every way. Besides, by
definition creativity requires nonconformity. In other words, any creative act is necessarily in
nonconformance with what already exists.
To sum up, conformists find their energy by conforming, nonconformists by not conforming.
And creativity is the exclusive domain of the nonconformist.
























Issue 123
"Much of the information that people assume is 'factual' actually turns out to be inaccurate.
Thus, any piece of information referred to as a 'fact' should be mistrusted since it may well be
proven false in the future."
The speaker contends that so-called "facts" often turn out to be false, and therefore that we
should distrust whatever we are told is factual. Although the speaker overlooks certain
circumstances in which undue skepticism might be counterproductive, and even harmful, on
balance I agree that we should not passively accept whatever is passed off as fact; otherwise,
human knowledge would never advance.
I turn first to so-called "scientific facts," by which I mean current prevailing notions about the
nature of the physical universe that have withstood the test of rigorous scientific and logical
scrutiny. The very notion of scientific progress is predicated on such scrutiny. Indeed the
history of science is in large measure a history of challenges to so-called "scientific
facts"--challenges which have paved the way for scientific progress. For example, in
challenging the notion that the Earth was in a fixed position at the center of the universe,
Copernicus paved for the way for the corroborating observations of Galileo a century later, and
ultimately for Newton's principles of gravity upon which all modern science depends. The
staggering cumulative impact of Copernicus' rejection of what he had been told was true
provides strong support for the speaker's advice when it comes to scientific facts.
Another example of the value of distrusting what we are told is scientific fact involves the
debate over whether human behavioral traits are a function of internal physical forces ("nature")
or of learning and environment ("nurture"). Throughout human history the prevailing view has
shifted many times. The ancients assumed that our behavior was governed by the whims of
the gods; in medieval times it became accepted fact that human behavior is dictated by bodily
humours, or fluids; this "fact" later yielded to the notion that we are primarily products of our
upbringing and environment. Now researchers are discovering that many behavioral traits are
largely a function of the unique neurological structure of each individual's brain. Thus only by
distrusting facts about human behavior can we advance in our scientific knowledge and, in turn,
learn to deal more effectively with human behavioral issues in such fields as education,
juvenile delinquency, criminal reform, and mental illness.
The value of skepticism about so-called "facts" is not limited to the physical sciences. When
it comes to the social sciences we should always be skeptical about what is presented to us as
historical fact. Textbooks can paint distorted pictures of historical events, and of their causes
and consequences. After all, history in the making is always viewed firsthand through the eyes
of subjective witnesses, then recorded by fallible journalists with their own cultural biases and
agendas, then interpreted by historians with limited, and often tainted, information. And when it
comes to factual assumptions underlying theories in the social science, we should be even
more distrusting and skeptical, because such assumptions inherently defy deductive proof, or
disproof. Skepticism should extend to the law as well. While law students, lawyers, legislators,
and jurists must learn to appreciate traditional legal doctrines and principles, at the same time
they must continually question their correctness----m terms of their fairness and continuing
relevance.
Admittedly, in some cases undue skepticism can be counterproductive, and even harmrial.
For instance, we must accept current notions about the constancy of gravity and other basic
laws of physics; otherwise, we would live in continual fear that the world around us would
literally come crashing down on us. Undue skepticism can also be psychologically unhealthy
when distrust borders on paranoia. Finally, common sense informs me that young people
should first develop a foundation of experiential knowledge before they are encouraged to
think critically about what they are told is fact.
To sum up, a certain measure of distrust of so-called "facts" is the very stuff of which human
knowledge and progress are fashioned, whether in the physical sciences, the social sciences,
or the law. Therefore, with few exceptions I strongly agree that we should strive to look at facts
through skeptical eyes.
























Issue 124
"The true value of a civilization is reflected in its artistic creations rather than in its scientific
accomplishments."
The speaker contends that so-called "facts" often turn out to be false, and therefore that we
should distrust whatever we are told is factual. Although the speaker overlooks certain
circumstances in which undue skepticism might be counterproductive, and even harmful, on
balance I agree that we should not passively accept whatever is passed off as fact; otherwise,
human knowledge would never advance.
I turn first to so-called "scientific facts," by which I mean current prevailing notions about the
nature of the physical universe that have withstood the test of rigorous scientific and logical
scrutiny. The very notion of scientific progress is predicated on such scrutiny. Indeed the
history of science is in large measure a history of challenges to so-called "scientific
facts"--challenges which have paved the way for scientific progress. For example, in
challenging the notion that the Earth was in a fixed position at the center of the universe,
Copernicus paved for the way for the corroborating observations of Galileo a century later, and
ultimately for Newton's principles of gravity upon which all modern science depends. The
staggering cumulative impact of Copernicus' rejection of what he had been told was true
provides strong support for the speaker's advice when it comes to scientific facts.
Another example of the value of distrusting what we are told is scientific fact involves the
debate over whether human behavioral traits are a function of internal physical forces ("nature")
or of learning and environment ("nurture"). Throughout human history the prevailing view has
shifted many times. The ancients assumed that our behavior was governed by the whims of
the gods; in medieval times it became accepted fact that human behavior is dictated by bodily
humours, or fluids; this "fact" later yielded to the notion that we are primarily products of our
upbringing and environment. Now researchers are discovering that many behavioral traits are
largely a function of the unique neurological structure of each individual's brain. Thus only by
distrusting facts about human behavior can we advance in our scientific knowledge and, in turn,
learn to deal more effectively with human behavioral issues in such fields as education,
juvenile delinquency, criminal reform, and mental illness.
The value of skepticism about so-called "facts" is not limited to the physical sciences. When
it comes to the social sciences we should always be skeptical about what is presented to us as
historical fact. Textbooks can paint distorted pictures of historical events, and of their causes
and consequences. After all, history in the making is always viewed firsthand through the eyes
of subjective witnesses, then recorded by fallible journalists with their own cultural biases and
agendas, then interpreted by historians with limited, and often tainted, information. And when it
comes to factual assumptions underlying theories in the social science, we should be even
more distrusting and skeptical, because such assumptions inherently defy deductive proof, or
disproof. Skepticism should extend to the law as well. While law students, lawyers, legislators,
and jurists must learn to appreciate traditional legal doctrines and principles, at the same time
they must continually question their correctness----m terms of their fairness and continuing
relevance.
Admittedly, in some cases undue skepticism can be counterproductive, and even harmrial.
For instance, we must accept current notions about the constancy of gravity and other basic
laws of physics; otherwise, we would live in continual fear that the world around us would
literally come crashing down on us. Undue skepticism can also be psychologically unhealthy
when distrust borders on paranoia. Finally, common sense informs me that young people
should first develop a foundation of experiential knowledge before they are encouraged to
think critically about what they are told is fact.
To sum up, a certain measure of distrust of so-called "facts" is the very stuff of which human
knowledge and progress are fashioned, whether in the physical sciences, the social sciences,
or the law. Therefore, with few exceptions I strongly agree that we should strive to look at facts
through skeptical eyes.

